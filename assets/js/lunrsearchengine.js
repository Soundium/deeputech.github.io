
var documents = [{
    "id": 0,
    "url": "/404.html",
    "title": "404",
    "body": "404 Page does not exist!Please use the search bar at the top or visit our homepage! "
    }, {
    "id": 1,
    "url": "/categories",
    "title": "Categories",
    "body": ""
    }, {
    "id": 2,
    "url": "/comment-policy",
    "title": "Comment policy",
    "body": "Keep it civil aka don’t be a jerk: We’re going to get into the thick of a lot of heated discussions and that’s okay. These discussions often entail topics that we all personally care a lot about and will passionately defend. But in order for discussions to thrive here, we need to remember to criticize ideas, not people.   So, remember to avoid:  name-calling ad hominem attacks Responding to a post’s tone instead of its actual content.  knee-jerk contradictionComments that we find to be hateful, inflammatory, or harassing may be removed. If you don’t have something nice to say about another user, don’t say it. Treat others the way you’d like to be treated. Always strive to add value to every interaction and discussion you participate in: There are a lot of discussions that happen every day on Disqus. Before joining in a discussion, browse through some of the most recent and active discussions happening in the community, especially if you’re new there.   If you are not sure your post adds to the conversation, think over what you want to say and try again later. Keep it tidy: Help make moderators’ lives easier by taking a moment to ensure that what you’re about to post is in the right place. That means:  don’t post off-topic comments or discussions don’t cross-post the same thing multiple times review any specific posting guidelines for the community check if another active discussion on your topic has already been postedIf you see something, say something: Moderators are at the forefront of combatting spam, mediating disputes and enforcing community guidelines and, so are you.   If you see an issue, contact the moderators if possible or flag any comments for review. If you believe someone has violated the Basic Rules, report it to Disqus by flagging the user’s profile. No Self-promotion A discussion or comment that contains only a link to your blog, a product, or your article on another site will almost always be removed. Choose Your (Curse) Words Wisely Comments that contain profanity are automatically held for moderator review before being posted. Depending on the context of the comment, it may be removed. Profanity used to insult, antagonize, or inflame will always be removed. Don’t Be a Jerk Personal attacks and harassment will not be tolerated. Sexist, racist, misogynist, homophobic, and broad, offensive generalizations about groups of people are simply not allowed. Comments or discussions written intentionally to provoke will also be removed. Don’t Copy and Paste If you didn’t write it, or haven’t properly cited the article you’re quoting, don’t post it. English Only We currently only support English-only discussions on Disqus channels. Non-English comments and discussions will be removed. Related: Guide to building community guidelines: "
    }, {
    "id": 3,
    "url": "/",
    "title": "Deepu K Sasidharan",
    "body": "                                             I'm a Software Designer by passion &amp; profession. I'm also the co-lead of JHipster.          My expertise includes solution ideation, visualization, and prototyping.          I code using various Languages like Java, JavaScript, TypeScript, Go, Python and so on.          I'm an open-source software aficionado and a technology advocate by passion.          I'm also passionate about developer experience and user experience.          I also love Astronomy, Quadcopters, and Robotics.          I have authored a book on JHipster and write frequently about Java, JavaScript, Go, CloudNative and so on.                                Book:                       Full Stack Development with JHipster.         Get it on        Packt,        Amazon and        Safari.                                               OSS projects:                                            JHipster Generator:                          A cool generator for Angular/React/VueJS + Spring stack                                                    Angular Clock:                          A beautiful responsive clock face and clock widget for angular JS.          Built in SVG                                                          JHipster Registry:                          Service Registry, based on Spring Cloud Netflix Eureka and Spring         Cloud Config                                                    JHipster Entity Audit Generator:                          A yeoman generator to enable entity audit in JHipster generated apps                                                          JDL Studio:                 An awesome online JDL editor and visualizer                                            JHipster Bootswatch Theme Generator:                          A yeoman generator to enable Bootswatch themes in JHipster generated         apps                                                          Angular Object Diff:                          An AngularJS plugin to generate and view object difference                                                    UML and Sequence Diagram Generator:                                  A sequence diagram generator using angularJS and an UML Diagram         Generator based on PlantUML. Experimental.                                                             Follow me on social media:                                                                                                                                                                              Upcoming talks:                              CodeMotion, Berlin: November 12-13th - Microservices with Istio, JHipster and Kubernetes Devoxx, Kyiv, Ukraine: November 1-2 - Building Native TypeScript applications using Deno runtime                               Featured posts:                                                                                                                                                                                                                                                                                                                                                                       My reflections on Golang                              :               Do I like Go? Yes. Would I use it for every use case I have? Definitely not. :                                                                                                                                                                       Deepu K Sasidharan                                12 Jul 2019 | 20 mins read                                                                                                                                                                                                                                                                                                                                                                                  My beautiful Linux development environment                              :               One of the questions that I get quite often after a conference talk is weirdly not about what I presented but about my Linux desktop. . . :                                                                                                                                                                       Deepu K Sasidharan                                16 Jun 2019 | 7 mins read                                                                                                                                                                                                                   "
    }, {
    "id": 4,
    "url": "/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ “sitemap. xml”   absolute_url }}   "
    }, {
    "id": 5,
    "url": "/blogs/index.html",
    "title": "Blogs",
    "body": "  {{ site. name }}      {{ site. description }}         Featured:       {% for post in site. posts %}    {% if post. featured == true %}            {% include featuredbox. html %}          {% endif %}  {% endfor %}        All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 6,
    "url": "/blogs/page/2/index.html",
    "title": " - page 2",
    "body": "  {{ site. name }}      {{ site. description }}         Featured:       {% for post in site. posts %}    {% if post. featured == true %}            {% include featuredbox. html %}          {% endif %}  {% endfor %}        All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 7,
    "url": "/blogs/page/3/index.html",
    "title": " - page 3",
    "body": "  {{ site. name }}      {{ site. description }}         Featured:       {% for post in site. posts %}    {% if post. featured == true %}            {% include featuredbox. html %}          {% endif %}  {% endfor %}        All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 8,
    "url": "/functional-programming-in-rust/",
    "title": "Easy functional programming techniques in Rust for everyone",
    "body": "2019/11/14 - There is a lot of hype around functional programming(FP) and a lot of cool kids are doing it but it is not a silver bullet. Like other programming paradigms/styles, functional programming also has its pros and cons and one may prefer one paradigm over the other. If you are a Rust developer and wants to venture into functional programming, do not worry, you don’t have to learn functional programming oriented languages like Haskell or Clojure(or even Scala or JavaScript though they are not pure functional programming languages) since Rust has you covered and this post is for you. If you are looking for functional programming in Java, Golang or TypeScript check other posts in the series. I’m not gonna dive into all functional programming concepts in detail, instead, I’m gonna focus on things that you can do in Rust which are in line with functional programming concepts. I’m also not gonna discuss the pros and cons of functional programming in general. Please note that some introductions in this post are repeated from my other posts in the series for your ease of reading. What is functional programming?: As per Wikipedia,  Functional programming is a programming paradigm—a style of building the structure and elements of computer programs—that treats computation as the evaluation of mathematical functions and avoids changing-state and mutable data. Hence in functional programming, there are two very important rules  No Data mutations: It means a data object should not be changed after it is created.  No implicit state: Hidden/Implicit state should be avoided. In functional programming state is not eliminated, instead, its made visible and explicitThis means:  No side effects: A function or operation should not change any state outside of its functional scope. I. e, A function should only return a value to the invoker and should not affect any external state. This means programs are easier to understand.  Pure functions only: Functional code is idempotent. A function should return values only based on the arguments passed and should not affect(side-effect) or depend on the global state. Such functions always produce the same result for the same arguments. Apart from these there are functional programming concepts below that can be applied in Rust, we will touch upon these further down.  Higher-order-functions Closures Currying Recursion Lazy evaluations Referential transparencyUsing functional programming doesn’t mean its all or nothing, you can always use functional programming concepts to complement Object-oriented or imperative concepts in Rust. The benefits of functional programming can be utilized whenever possible regardless of the paradigm or language you use. And that is exactly what we are going to see. Functional programming in Rust: Rust is primarily geared towards procedural/imperative style of programming but it also lets you do a little bit of functional and object-oriented style of programming as well. And that is my favorite kind of mix. So let us see how we can apply some of the functional programming concepts above in Rust using the language features. First-class and higher-order functions: First-class functions(function as a first-class citizen) means you can assign functions to variables, pass a function as an argument to another function or return a function from another. Functions in Rust are a bit more complex than other languages, it’s not as straightforward as in Go or JavaScript. There are different kinds of functions and two different ways of writing them. The first one is a function that cannot memoize its outer context and the second one is closures which can memoize its outer context. Hence concepts like currying and higher-order-functions are possible in Rust but may not be as easy to wrap your head around as in other languages. Also, functions that accept a closure can also accept a pointer to a function depending on the context. In many places, Rust functions and closures can be interchangeable. It would have been nicer if functions were simple and we could do all the below without having to rely on closures. But Rust chose these compromises for better memory safety and performance. A function can be considered as a higher-order-function only if it takes one or more functions as parameters or if it returns another function as a result. In Rust, this is quite easy to do with closures, it might look a bit verbose but if you are familiar with Rust then you should be fine. 123456789101112131415161718192021222324fn main() {  let list = vec![    String::from( Orange ),    String::from( Apple ),    String::from( Banana ),    String::from( Grape ),  ];  // we are passing the array and a closure as arguments to map_for_each method.   let out = map_for_each(list, |it: &amp;String| -&gt; usize {    return it. len();  });  println!( {:?} , out); // [6, 5, 6, 5]}// The higher-order-function takes an array and a closure as argumentsfn map_for_each(list: Vec&lt;String&gt;, fun: fn(&amp;String) -&gt; usize) -&gt; Vec&lt;usize&gt; {  let mut new_array: Vec&lt;usize&gt; = Vec::new();  for it in list. iter() {    // We are executing the closure passed    new_array. push(fun(it));  }  return new_array;}There are also more complex versions that you can write with generics like below for an example 123456789101112131415161718192021fn main() {  let list = vec![2, 5, 8, 10];  // we are passing the array and a closure as arguments to map_for_each method.   let out = map_for_each(list, |it: &amp;usize| -&gt; usize {    return it * it;  });  println!( {:?} , out); // [4, 25, 64, 100]}// The higher-order-function takes an array and a closure as arguments, but uses generic typesfn map_for_each&lt;A, B&gt;(list: Vec&lt;A&gt;, fun: fn(&amp;A) -&gt; B) -&gt; Vec&lt;B&gt; {  let mut new_array: Vec&lt;B&gt; = Vec::new();  for it in list. iter() {    // We are executing the closure passed    new_array. push(fun(it));  }  return new_array;}But then we could also simply do it this way using built-in functional methods like map, fold(reduce) and so on which is much less verbose. Rust provides a lot of useful functional style methods for working on collections like map, fold, for_each, filter and so on. 12345678fn main() {  let list = [ Orange ,  Apple ,  Banana ,  Grape ];  // we are passing a closure as arguments to the built-in map method.   let out: Vec&lt;usize&gt; = list. iter(). map(|x| x. len()). collect();  println!( {:?} , out); // [6, 5, 6, 5]}Closures in Rust can memorize and mutate its outer context but due to the concept of ownership in Rust, you cannot have multiple closures mutating the same variables in the outer context. Currying is also possible in Rust but again due to ownership and lifetime concepts, it might feel a bit more verbose. 1234567891011121314151617fn main() {  // this is a higher-order-function that returns a closure  fn add(x: usize) -&gt; impl Fn(usize) -&gt; usize {    // A closure is returned here    // variable x is obtained from the outer scope of this method and memorized in the closure by moving ownership    return move |y| -&gt; usize { x + y };  };  // we are currying the add method to create more variations  let add10 = add(10);  let add20 = add(20);  let add30 = add(30);  println!( {} , add10(5)); // 15  println!( {} , add20(5)); // 25  println!( {} , add30(5)); // 35}Pure functions: As we saw already a pure function should return values only based on the arguments passed and should not affect or depend on the global state. It is possible to do this in Rust easily. Take the below, this is a pure function. It will always return the same output for the given input and its behavior is highly predictable. We can safely cache the method if needed. 123fn sum(a: usize, b: usize) -&gt; usize {  return a + b;}But since Rust variables are immutable by default, unless specified a function cannot mutate any variables passed to it and cannot capture any variable in its context. So if we try to affect external state like below the compiler will complain “can’t capture dynamic environment in a fn item” 1234567891011use std::collections::HashMap;fn main() {  let mut holder = HashMap::new();  fn sum(a: usize, b: usize) -&gt; usize {    let c = a + b;    holder. insert(String::from(format!( ${a}+${b} , a = a, b = b)), c);    return c;  }}In Rust, in order to capture external state, we would have to use closures, so we can rewrite the above as 12345678910111213use std::collections::HashMap;fn main() {  let mut holder = HashMap::new();  let sum = |a: usize, b: usize| -&gt; usize {    let c = a + b;    holder. insert(String::from(format!( ${a}+${b} , a = a, b = b)), c);    return c;  };  println!( {} , sum(10, 20));}But the compilation will still fail with the message “cannot borrow sum as mutable, as it is not declared as mutable”. So in order to do external state mutation, we would have to explicitly specify the function as mutable like let mut sum = . . . So Rust will help you keep your functions pure and simple by default. Of course, that doesn’t mean you can avoid side effects that don’t involve variable mutations, for those you have to take care of it yourself. Recursion: Functional programming favors recursion over looping. Let us see an example for calculating the factorial of a number. In traditional iterative approach: 123456789101112fn main() {  fn factorial(mut num: usize) -&gt; usize {    let mut result = 1;    while num &gt; 0 {      result *= num;      num = num - 1;    }    return result;  }  println!( {} , factorial(20)); // 2432902008176640000}The same can be done using recursion as below which is favored in functional programming – But recursion is not the solution always, for some cases a simple loop is more readable. 12345678910fn main() {  fn factorial(num: usize) -&gt; usize {    return match num {      0 =&gt; 1,      _ =&gt; num * factorial(num - 1),    };  }  println!( {} , factorial(20)); // 2432902008176640000}The downside of the recursive approach is that it will be slower compared to an iterative approach most of the times(The advantage we are aiming for is code simplicity and readability) and might result in stack overflow errors since every function call needs to be saved as a frame to the stack. To avoid this tail recursion is preferred, especially when the recursion is done too many times. In tail recursion, the recursive call is the last thing executed by the function and hence the functions stack frame need not be saved by the compiler. Most compilers can optimize the tail recursion code the same way iterative code is optimized hence avoiding the performance penalty. But unfortunately, Rust does not support this yet. Consider using recursion when writing Rust code for readability and immutability, but if performance is critical or if the number of iterations will be huge use the standard iterative approach. Lazy evaluation: Lazy evaluation or non-strict evaluation is the process of delaying the evaluation of an expression until it is needed. In general, Rust does strict/eager evaluation. We can utilize higher-order-functions, closures, and memoization techniques to do lazy evaluations. Take this example where Rust eagerly evaluates everything. 123456789101112131415161718192021fn main() {  fn add(x: usize) -&gt; usize {    println!( executing add ); // this is printed since the functions are evaluated first    return x + x;  }  fn multiply(x: usize) -&gt; usize {    println!( executing multiply ); // this is printed since the functions are evaluated first    return x * x;  }  fn add_or_multiply(add: bool, on_add: usize, on_multiply: usize) -&gt; usize {    if add {      on_add    } else {      on_multiply    }  }  println!( {} , add_or_multiply(true, add(4), multiply(4))); // 8  println!( {} , add_or_multiply(false, add(4), multiply(4))); // 16}This will produce the below output and we can see that both functions are executed always 123456executing addexecuting multiply8executing addexecuting multiply16We can use higher-order-functions to rewrite this into a lazily evaluated version 123456789101112131415161718192021222324fn main() {  fn add(x: usize) -&gt; usize {    println!( executing add ); // this is printed since the functions are evaluated first    return x + x;  }  fn multiply(x: usize) -&gt; usize {    println!( executing multiply ); // this is printed since the functions are evaluated first    return x * x;  }  type FnType = fn(t: usize) -&gt; usize;  // This is now a higher-order-function hence evaluation of the functions are delayed in if-else  fn add_or_multiply(add: bool, on_add: FnType, on_multiply: FnType, t: usize) -&gt; usize {    if add {      on_add(t)    } else {      on_multiply(t)    }  }  println!( {} , add_or_multiply(true, add, multiply, 4)); // 8  println!( {} , add_or_multiply(false, add, multiply, 4)); // 16}This outputs the below and we can see that only required functions were executed 1234executing add8executing multiply16You can also use memoization/caching techniques to avoid unwanted evaluations in pure and referentially transparent functions like below 12345678910111213141516171819202122232425262728293031323334353637383940414243use std::collections::HashMap;fn main() {  let mut cached_added = HashMap::new();  let mut add = |x: usize| -&gt; usize {    return match cached_added. get(&amp;x) {      Some(&amp;val) =&gt; val,      _ =&gt; {        println!( {} ,  executing add );        let out = x + x;        cached_added. insert(x, out);        out      }    };  };  let mut cached_multiplied = HashMap::new();  let mut multiply = |x: usize| -&gt; usize {    return match cached_multiplied. get(&amp;x) {      Some(&amp;val) =&gt; val,      _ =&gt; {        println!( executing multiply );        let out = x * x;        cached_multiplied. insert(x, out);        out      }    };  };  fn add_or_multiply(add: bool, on_add: usize, on_multiply: usize) -&gt; usize {    if add {      on_add    } else {      on_multiply    }  }  println!( {} , add_or_multiply(true, add(4), multiply(4))); // 8  println!( {} , add_or_multiply(false, add(4), multiply(4))); // 16}This outputs the below and we can see that functions were executed only once for the same values. 1234executing addexecuting multiply816These may not look that elegant especially to seasoned Rust programmers. Fortunately, most of the functional APIs, like the iterators, provided by Rust do lazy evaluations and there are libraries like rust-lazy and Thunk which can be used to make functions lazy. Also, Rust provides some advanced types with which lazy evaluations can be implemented. Doing Lazy evaluations in Rust might not be worth the code complexity some of the times, but if the functions in question are heavy in terms of processing then it is absolutely worth it to lazy evaluate them. Type system: Rust is a strong statically typed language and also has great type inference. There are also advanced concepts like type aliasing and so on. Referential transparency: From Wikipedia:  Functional programs do not have assignment statements, that is, the value of a variable in a functional program never changes once defined. This eliminates any chances of side effects because any variable can be replaced with its actual value at any point of execution. So, functional programs are referentially transparent. Rust has great ways to ensure referential transparency, variables in Rust are immutable by default and even reference passing is immutable by default. So you would have to explicitly mark variables or references as mutable to do so. So in Rust, it is actually quite easy to avoid mutations. For example, the below will produce an error 12345fn main() {  let list = [ Apple ,  Orange ,  Banana ,  Grape ];  list = [ John ,  Raju ,  Sabi ,  Vicky ];}And so does all of the below 12345678910111213141516fn main() {  let list = vec![    String::from( Orange ),    String::from( Apple ),    String::from( Banana ),    String::from( Grape ),  ];  list. push(String::from( Strawberry )); // This will fail as the reference is immutable  fn mutating_fn(val: String) {    val. push('!'); // this will fail unless the argument is marked mutable reference or value passed is marked mutable reference  }  mutating_fn(String::from( Strawberry )); // this will fail if the reference is not passed as mutable}In order to compile these, we would have to riddle it with mut keywords 1234567891011121314151617fn main() {  let mut list = vec![    String::from( Orange ),    String::from( Apple ),    String::from( Banana ),    String::from( Grape ),  ];  list. push(String::from( Strawberry )); // This will work as the reference is mutable  fn mutating_fn(val: &amp;mut String) {    val. push('!'); // this will work as the argument is marked as a mutable reference  }  mutating_fn(&amp;mut String::from( Strawberry )); // this will work as the reference is passed as mutable}There are even more advanced concepts in Rust when it comes to data mutation and all that makes it easier to write immutable code. Data structures: When using functional programming techniques it is encouraged to use data types such as Stacks, Maps and Queues which have functional implementations as well. Hence Hashmaps are better than arrays or hash sets in functional programming as data stores and Rust provides such data types. Conclusion: This is just an introduction for those who are trying to apply some functional programming techniques in Rust. There are a lot more that can be done in Rust. As I said earlier functional programming is not a silver bullet but it offers a lot of useful techniques for more understandable, maintainable and testable code. It can co-exist perfectly well with imperative and object-oriented programming styles. In fact, we all should be using the best of everything to solve the problem at hand instead of getting too obsessed about a single methodology. I hope you find this useful. If you have any questions or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. "
    }, {
    "id": 9,
    "url": "/first-impression-of-rust/",
    "title": "My first impressions of Rust",
    "body": "2019/11/07 - So I started learning Rust a while ago and since my post about what I thought of Go was popular, I decided to write about what my first impressions of Rust were as well. But unlike Go, I actually didn’t build any real-world application in Rust, so my opinions here are purely personal and some might not be accurate as I might have misunderstood something. So do give me the consideration of a Rust newbie. If you find something I said here is inaccurate please do let me know. Also, my impressions might actually change once I start using the language more. If it does, I’ll make sure to update the post. As I have said in some of my other posts, I consider myself to be more pragmatic than my younger self now. Some of the opinions are also from that pragmatic perspective(or at least I think so). I have weighed practicality, readability, and simplicity over fancy features, syntax sugars, and complexity. Also, some things which I didn’t like but found not such a big deal are put under nitpicks rather than the dislike section as I thought it was fairer that way. One thing that sets Rust apart from languages like Go is that Rust is not garbage collected, and I understand that many of the language features/choices where designed with that in mind. Rust is primarily geared towards procedural/imperative style of programming but it also lets you do a little bit of functional and object-oriented style of programming as well. And that is my favorite kind of mix. So, without any further ado, let’s get into it. What I like about RustThings that I really liked, in no particular order. No Garbage collection: One of the first things you would notice in Rust, especially if you are coming from garbage collected languages like Java or Golang is the lack of garbage collection. Yes, there is no GC in Rust, then how does it ensure my program runs efficiently in the given memory and how does it prevent out of memory errors? Rust has something called ownership, so basically any value in Rust must have a variable as its owner(and only one owner at a time) when the owner goes out of scope the value will be dropped freeing the memory regardless of it being in stack or heap memory. For example, in the below example the value of foo is dropped as soon as the method execution completes and the value of bar is dropped right after the block execution. 1234567891011fn main() {  let foo =  value ; // owner is foo and is valid within this method  {    let bar =  bar value ; // owner is bar and is valid within this block scope    println!( value of bar is {} , bar); // bar is valid here  }  println!( value of foo is {} , foo); // foo is valid here  println!( value of bar is {} , bar); // bar is not valid here as its out of scope}So by scoping variables carefully, we can make sure the memory usage is optimized and that is also why Rust lets you use block scopes almost everywhere. Also, the Rust compiler helps you in dealing with duplicate pointer references and so on. The below is invalid in Rust since foo is now using heap memory rather than stack and assigning a reference to a variable is considered a move. If deep copying(expensive) is required it has to be performed using the clone function which performs a copy instead of move. 1234567891011fn main() {  let foo = String::from( hello ); // owner is foo and is valid within this method  {    let bar = foo; // owner is bar and is valid within this block scope, foo in invalidated now    println!( value of bar is {} , bar); // bar is valid here  }  println!( value of foo is {} , foo); // foo is invalid here as it has moved}The ownership concept can be a bit weird to get used to, especially since passing a variable to a method will also move it(if its not a literal or reference), but given that it saves us from GC I think its worth it and the compiler takes care of helping us when we make mistakes. Immutable by default: Variables are immutable by default. If you want to mutate a variable you have to specifically mark it using the mut keyword. 12let foo =  hello  // immutablelet mut bar =  hello  // mutable Variables are by default passed by value, in order to pass a reference we would have to use the &amp; symbol. Quite similar to Golang. 12345678910111213141516fn main() {  let world = String::from( world );    hello_ref(&amp;world); // pass by reference. Keeps ownership  // prints: Hello world  hello_val(world); // pass by value and hence transfer ownership  // prints: Hello world}fn hello_val(msg: String) {  println!( Hello {} , msg);}fn hello_ref(msg: &amp;String) {  println!( Hello {} , msg);}When you pass a reference it is still immutable so we would have to explicitly mark that mutable as well as below. This makes accidental mutations very difficult. The compiler also ensures that we can only have one mutable reference in a scope. 1234567891011121314151617fn main() {  let mut world = String::from( world );    hello_ref(&amp;mut world); // pass by mutable reference. Keeps ownership  // prints: Hello world!  hello_val(world); // pass by value and hence transfer ownership  // prints: Hello world!}fn hello_val(msg: String) {  println!( Hello {} , msg);}fn hello_ref(msg: &amp;mut String) {  msg. push_str( ! ); // mutate string  println!( Hello {} , msg);}Pattern matching: Rust has first-class support for pattern matching and this can be used for control flow, error handling, variable assignment and so on. pattern matching can also be used in if, while statements, for loops and function parameters. 123456789101112131415fn main() {  let foo = String::from( 200 );  let num: u32 = match foo. parse() {    Ok(num) =&gt; num,    Err(_) =&gt; {      panic!( Cannot parse! );    }  };  match num {    200 =&gt; println!( two hundred ),    _ =&gt; (),  }}Generics: One thing I love in Java and TypeScript is the generics. It makes static typing more practical and DRY. Strongly typed languages(Looking at you Golang) without generics are annoying to work with. Fortunately, Rust has great support for generics. It can be used in types, functions, structs, and enums. The icing on the cake is that Rust converts the Generic code using specific code during compile time thus there is no performance penalty in using them. 1234567891011121314151617struct Point&lt;T&gt; {  x: T,  y: T,}fn hello&lt;T&gt;(val: T) -&gt; T {  return val;}fn main() {  let foo = hello(5);  let foo = hello( 5 );  let integer = Point { x: 5, y: 10 };  let float = Point { x: 1. 0, y: 4. 0 };}Static types and advanced type declarations: Rust is a strictly typed language with a static type system. It also has great type inference which means we don’t have to define types manually for everything. Rust also allows for complex type definitions. 12345type Kilometers = i32;type Thunk = Box&lt;dyn Fn() + Send + 'static&gt;;type Result&lt;T&gt; = std::result::Result&lt;T, std::io::Error&gt;;Nice and simple error handling: Error handling in Rust is quite nice, there are recoverable and unrecoverable errors. For recoverable errors, you can handle them using pattern matching on the Result enum or using the simple expect syntax. There is even a shorthand operator to propagate errors from a function. Take that Go. 1234567891011121314use std::fs::File;fn main() {  let f = File::open( hello. txt ). expect( Failed to open hello. txt );    // or    let f = match File::open( hello. txt ) {    Ok(file) =&gt; file,    Err(error) =&gt; {      panic!( Problem opening the file: {:?} , error)    },  };}Tuples: Rust has built-in support for tuples, and this is highly helpful when you have to return multiple values from a function or when you want to unwrap a value and so on. Block expressions: In Rust, you can have block expressions with their own scope almost anywhere. It also lets you assign a variable value from block expressions, if statement, loops and so on. 12345678fn main() {  let foo = {    println!( Assigning foo );    5  };  let bar = if foo &gt; 5 { 6 } else { 10 };}Beautiful compiler output: Rust simply has the best error output during compilation that I have seen. It can’t get better than this I think. It is so helpful.  Built-in tooling: Like many modern programming languages, Rust also provides a lot of build-in standard tooling and honestly, I think this is one of the best that I have come across. Rust has Cargo which is the built-in package manager and build system. It is an excellent tool. It takes care of all common project needs like compiling, building, testing and so on. It can even create new projects with a skeleton and manage packages globally and locally for the project. That means you don’t have to worry about setting up any tooling to get started in Rust. I love this, it saves so much time and effort. Every programming language should have this. Rust also provides built-in utilities and asserts to write tests which then can be executed using Cargo. In Rust, related functionality is grouped into modules, modules are grouped together into something called crates and crates are grouped into packages. We can refer to items defined in one module from another module. Packages are managed by cargo. You can specify external packages in the Cargo. toml file. Reusable public packages can be published to the crates. io registry. There are even offline built-in docs that you can get by running rustup docs and rustup docs --book which is amazing. Thanks to Mohamed ELIDRISSI for pointing it out to me. Concurrency: Rust has first-class support for memory safe concurrent programming. Rust uses threads for concurrency and has 1:1 threading implementation. i. e, 1 green thread per operating system thread. Rust compiler guarantees memory safety while using the threads. It provides features like waiting for all threads to finish, sharing data with move closures or channels(similar to Go). It also lets you use shared state and sync threads. 12345678910111213141516use std::thread;use std::time::Duration;fn main() {  thread::spawn(|| {    for i in 1. . 10 {      println!( hi number {} from the spawned thread! , i);      thread::sleep(Duration::from_millis(1));    }  });  for i in 1. . 5 {    println!( hi number {} from the main thread! , i);    thread::sleep(Duration::from_millis(1));  }}Macros and meta-programming: While I don’t like all aspects of macros in Rust, there are more things to like here than dislike. The annotation macros, for example, are quite handy. Not a fan of the procedure macros though. For advanced users, you can write your own macro rules and do metaprogramming. Traits: Traits are synonymous to interfaces in Java, it is used to define shared behaviors that can be implemented on structs. Traits can even specify default methods. The only thing I dislike here is the indirect implementation. 123456789101112131415161718192021222324252627282930pub trait Summary {  fn summarize_author(&amp;self) -&gt; String;  fn summarize(&amp;self) -&gt; String {    format!( (Read more from {}. . . ) , self. summarize_author())  }}pub struct NewsArticle {  pub author: String,  pub content: String,}impl Summary for NewsArticle {  fn summarize_author(&amp;self) -&gt; String {    format!( @{} , self. author)  }}fn main() {  let article = NewsArticle {    author: String::from( Iceburgh ),    content: String::from(       The Pittsburgh Penguins once again are the best hockey team in the NHL.  ,    ),  };  println!( New article available! {} , article. summarize());}Ability to use unsafe features if required:  Useful in advanced use-cases where you know what you are doing. A necessary evil IMO. I like it since its doable only within an unsafe { } block making it very explicit. I would have moved this to the dislike section if that was not the case.  When you use these, the Rust compiler cannot guarantee memory and runtime safety and you are on your own to get this right. So definitely for advanced and experienced users. What I don’t like about RustThings that I didn’t like very much, in no particular order. Complexity: I don’t like it when a language offers multiples ways to do the same things. This is one think Golang does pretty well, there are no two ways to do the same thing and hence it is easier for people to work on larger codebases and to review code. Also, you don’t have to always think of the best possible way to do something. Unfortunately, Rust does this and I’m not a fan of it. IMO it makes the language more complex.  Too many ways for iterations -&gt; loops, while, for, iterators.  Too many ways for creating procedures -&gt; Functions, closures, macrosEdit: Based on discussions here and on Reddit, I say my perception of complexity only have increased. It seems like once you get past all the niceties there are a lot of things that would take some time to wrap your head around. I’m pretty sure if you are experienced in Rust, it would be a cakewalk for you but the language indeed is quite complex, especially the ways functions and closures behave in different contexts, lifetimes in structs and stuff. Shadowing of variables in the same context: So Rust lets you do this 123456{  let foo =  hello ;  println!( {} , foo);  let foo =  world ;  println!( {} , foo);} Kind of beats being immutable by default(I understand the reasoning of being able to perform transformations on an immutable variable, especially when passing references to a function and getting it back) IMO lets people practice bad practices unintentionally, I would have rather marked the variable mutable as I consider the above mutation as well.  You can as easily accidentally shadow a variable as you would accidentally mutate one in Languages like JavaScript Gives people a gun to shoot in the footEdit: I saw a lot of comments here and on Reddit explaining why this is good. While I agree that it is useful in many scenarios, so is the ability of mutation. I think it would have been perfectly fine not to have this and people would have still loved Rust and all of them would have defended the decision not have this. So my opinion on this hasn’t changed. Functions are not first-class citizens: While it is possible to pass a function to another they are not exactly first-class citizens like in JavaScript or Golang. You cannot create closures from functions and you cannot assign functions to variables. Closures are separate from functions in Rust, they are quite similar to Java lambdas from what I see. While closures would be sufficient to perform some of the functional style programming patterns it would have been much nicer if it was possible using just functions thus making language a bit more simple. Edit: Oh by! this opinion triggered a lot of discussions here and on Reddit. So seems like Functions and closures are similar and different based on context, It also seems like Functions are almost like first-class citizens, but if you are used to languages like Go or JavaScript where functions are much more straight forward then you are in for a crazy ride. Functions in Rust seems much much more complex. A lot of people who commented seemed to miss the fact that my primary complaint was that having two constructs(closures and functions) that look and act quite similar in most of the scenarios makes things more complex. At least in Java and JS where there are multiple constructs(arrow functions, lambdas) those where due to the fact that they were added much later to the language and those are still something I don’t like in those languages. The best explanation was from Yufan Lou and another from zesterer. I’m not gonna remove this from stuff I don’t like since I still don’t like the complexity here. Implicit implementation of traits: I’m not a fan of implicit stuff as its easier to abuse this and harder to read. You could define a struct in one file and you could implement a trait for that struct in another file which makes it less obvious. I prefer when the implementation is done by intent like in Java which makes it more obvious and easier to follow. While the way in Rust is not ideal, it is definitely better than Golang which is even more indirect. NitpicksFinally some stuff I still don’t like but I don’t consider them a big deal.  I don’t see the point of having the const keyword when let is immutable by default. It seems more like syntax sugar for the old school constants concept. Diane pointed out the difference const provides and that makes sense.  The block expression and implicit return style are a bit error-prone and confusing to get used to, I would have preferred explicit return. Also, it’s not that readable IMO.  If you have read my other post about Go, you might know that I’m not a fan of structs. Structs in Rust is very similar to structs in Golang. So like in Go, it would be easy to achieve unreadable struct structures. But fortunately, the structs in Rust seem much nicer than Go as you have functions, can use spread operator, shorthand syntax and so on here. Also, you can make structs which are Tuples. The structs in Rust are more like Java POJOs. I would have moved this to the liked section if having optional fields in structs where easier. Currently, you would have to wrap stuff in an Optional enum to do this. Also lifetimes :( Given strings are the most used data types, it would have been nice to have a simpler way of working with strings(like in Golang) rather than working with the Vector types for mutable strings or slice types for immutable string literals. This makes code more verbose than it needs to be. This is more likely a compromise due to the fact that Rust is not garbage collected and has a concept of ownership to manage memory. https://doc. rust-lang. org/rust-by-example/std/str. html - Edit: I have moved this point to nitpicks rather than dislikes after a discussion on the comments with robertorojasrConclusionI like programming languages that focus more on simplicity rather than fancy syntax sugars and complex features. In my post “My reflections on Golang”, I explain why I consider Golang to be too simple for my taste. Rust, on the other hand, is leaning towards the other side of the spectrum. While it is not as complex as Scala it is not as simple as Go as well. So its somewhere in between, not exactly the sweet spot but almost near that quite close to where JavaScript is maybe. So overall I can say that there are more things in Rust for me to like than to dislike which is what I would expect from a nice programming language. Also, bear in mind that I’m not saying Rust should do anything differently or that there are better ways to do things that I complained about. I’m just saying that I don’t like those things but I can live with it given the overall advantages. Also, I fully understand why some of those concepts are the way they are, those are mostly tradeoffs to focus on memory safety and performance. But don’t be fooled by what you see over the hood, Rust is definitely not something you should start with as your first programming language IMO, as it has a quite a lot of complex concepts and constructs underneath but if you are already familiar with programming then it shouldn’t be an issue after banging your head on the doors a few times :P So far I can say that I like Rust more than Golang even without implementing a real project with it and might choose Rust over Go for system programming use cases and for high-performance requirements. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Cover image credit: Image from Link Clark, The Rust team under Creative Commons Attribution Share-Alike License v3. 0. "
    }, {
    "id": 10,
    "url": "/microservices-the-good-bad-and-the-ugly/",
    "title": "Microservices - the good, bad, and the ugly",
    "body": "2019/10/29 - So you are attending this awesome conference where speaker after speaker talks about how awesome microservices are. You hear a speaker from a Tech giant presenting how they scaled up and solved their issues using microservices running on containers or something, and you wonder shouldn’t we do the same as well? The reality is that there is no silver bullet in software engineering. Microservices doesn’t magically solve every scaling issues, some times they introduce more problems then they solve. Well, this is not a microservice bashing post, as someone who likes microservice architectures(sometimes for their sheer complexity and sometimes for the ingenuity), I think it’s important to know the cost of doing microservice architectures in real-world use cases. I talked briefly about this in my book as well. Microservice architecturesIn a microservice architecture, you generally split your domain model into individual loosely coupled services that can be deployed and scaled individually. Each of the services is in itself a small application with its own architecture and even runtime sometimes. The services might offer REST endpoints that can be aggregated by an application acting as a gateway or the services could be communicating with each other using a messaging system. Some services might have Web GUI some are headless services offering just an API. In microservice architectures, each service is responsible for handling its data and ideally do not share database schema with other services. Such architectures make it easy to provide different clients for Mobile and Desktop experience which can be scaled independently based on demand.  There are different architecture patterns for building microservices. The patterns used also decides the way services communicate and the way they are aggregated. This article details some of these patterns quite nicely. So let’s break down the benefits and issues of microservice architecture and see when it makes sense to adopt one and when to avoid one. General benefits of Microservice architecturesIn general, Microservices provide(As it depends on how you actually implement it) or at least promise the below benefits, which can be grouped into three major categories Loose coupling: Microservice components are more loosely coupled than traditional architectures. Such systems employ event-driven or message-driven architectures to achieve communication between loosely coupled components. This results in better isolation of components and makes it easy to unit test them and faster to startup. Such systems also provide other benefits like, for example, a memory leak in one of the services, are isolated and hence will not bring down the entire application. Hence overall single point of failures are reduced Loosely coupled individual components will start up much faster than a big monolith making it possible to parallelize and improve overall start-up for large systems. It also makes it easy to refactor existing features as you can gradually refactor things rather than having to refactor an entire system in one go. Because of such loose coupling, each service can choose to use a database/datastore that is more appropriate whereas in a monolith you might compromise with a single database type. For example, a service dealing with a lot of unstructured data can choose a NoSQL database while a service that is handling transactions or structured data can opt for a SQL database. Faster development &amp; release cycle: In a well-implemented microservice architecture, development turnaround is faster and hence you get a better time to market for new features and easier refactoring of existing features. A complex problem domain can be easily tackled by splitting it into separately manageable services making it easier to understand and maintain in the long run. Technology adoption is easier, components can be independently upgraded in incremental migration making it possible to have a different stack for each component. It is also possible to have different microservices in a system use different implementation languages and just communicate using a common messaging format like gRPC or a message queue or pub/sub, thus making it possible to have teams with different language skills hence less dependency on a single language or stack. Teams will be less dependent on each other as communication between systems is governed by a public API or contract letting you change internals without having to worry about breaking someone else’s code. Best suited for agile teams. Such teams can have better focus as they only need to worry about a single service. Fine-grained scaling: One of the most important benefits of a microservice architecture is the ability to scale individual components based on load. If implemented properly this will result in ideal load distribution and reduced overall infrastructure cost. Services with more demand can be scaled up while the ones with less demand can be scaled down utilizing infrastructure more efficiently. Deploying services independently also makes the application more reliable and makes patching easier as you do not have to upgrade the entire application to fix an issue in a single service. More complex and efficient scaling models can be established. Critical services can be scaled more effectively. Infrastructure is used more efficiently. Continuous delivery of such complex applications also would be easier than its equivalent monolith as components are smaller and any issue in deployment can be investigated easily and rectified on a per-component basis General issues with microservice architecturesWell with any architectures, there are disadvantages of Microservice architectures as well. Complexity: Complexity is one of the biggest side effects of this architecture. While microservices can reduce the domain complexity by breaking the problem into smaller services,there could be complexities of a distributed system in terms of;    Overall stack as different components might have different technology stacks forcing the team to invest more time in keeping up with them.     Scaling is more efficient but it would require advanced features such as service discovery, DNS routing, and so on.     Communication between components might require a messaging system(Queue, PubSub, Event store).     Business transactions on a distributed system might involve updating multiple databases making rollbacks more complex and error-prone.     The entire application is more complex to deploy as there are complexities with containers, orchestration, and virtualization involved.     Requires a complex infrastructure. Most often will require containers (Docker), Orchestration(Kubernetes) and multiple JVM or app containers to run on.  Integration testing: End-to-end tests and integration tests become harder to perform there are more moving parts in the stack and more complex communication between components. The testing infrastructure required also becomes more difficult to set up and maintain. Team size and experience: The technical stack for microservices is more complex and most of the time harder to learn and hence it would demand a more experienced team with more senior-level skillset than that would be required for a similar monolithic application. It will also require a bigger team to maintain the application as there are more components and more technologies involved. Implementing requirements that span multiple services would require more upfront time to agree on contracts and APIs. Team members share varying skill sets based on the component they work on but might not be having a birds-eye view of the entire application making business requirements harder to visualize and cross-cutting issues harder to fix. Overhead: Complex microservices will have the additional overhead of running monitoring setup, messaging services, orchestration, service registry and so on. Initial development time will be higher due to the complexity making time to market slower. The overall cost of the initial infrastructure might be much higher than that of a similar monolith. In microservice architectures, there is always code duplication between services which also can be considered overhead. When you should not be considering Microservice architecturesYou should not be using microservice architecture unless you absolutely have to, remember not every application has the same scale requirements as Netflix, Google, Amazon or Spotify. Many of the benefits that microservices provide to these kinds of applications are due to their sheer scale which might not be applicable to you. So here are some reasons not to choose microservices and maybe stick to monoliths.  When your application’s scope is small and you know that it’s not going to grow and turn into something like Facebook. For well defined simple usecases a monolith is always the best fit. Examples are     A CRUD application for an internal use case in a company.    A small application with a very niche user base. Like a shopping site for some specialty items.     When the time to market is critical for a new application. The initial time to market would be higher for microservices.  When the size of your team is small or the average experience of the team is less. Its best to start with a monolith when you are a small or inexperienced team.  When your infrastructure budget is limited. Though on long-run microservice might help to save money, in the beginning, it is going to cost you more. Most importantly do not choose microservices because it is the hype or because it is used by a popular company or because it was suggested by a popular person. For most use cases monoliths are still a great solution and even if you start with a monolith you can always split away into microservices if required. When you could consider Microservice architecturesIn general, Microservices tend to be beneficial if you have one of the below scenarios.  When your use case domain is complex, you have a large team with experience and splitting it up would make it easier to implement.  When you are expecting to become the next Facebook, Netflix or Twitter in terms of user load. So ideally when you are expecting an exponential user base.  If your application is going to be an API provider for other applications with a large userbase. Like a payment gateway or inventory service that will be used by a social media application When you have a popular e-commerce application with a large userbase with an uneven load on different services in the application. Its time to split them into microservices. So in conclusion, don’t choose an architecture pattern because it works for someone else, choose a pattern that is appropriate for your use case, scale and requirements. Not everyone needs to handle millions of concurrent users or stream terabytes of data. If you like this article, please leave a like or a comment. If you do decide to build microservices checkout JHipster and my below articles don’t forget to give it a star on Github.  Create full Microservice stack using JHipster Domain Language under 30 minutes Deploying JHipster Microservices on Azure Kubernetes Service (AKS) JHipster microservices with Istio service mesh on KubernetesYou can follow me on Twitter and LinkedIn. Cover image photo by Sergei Akulich on Unsplash "
    }, {
    "id": 11,
    "url": "/functional-programming-in-typescript/",
    "title": "Easy functional programming techniques in TypeScript for everyone",
    "body": "2019/08/14 - There is a lot of hype around functional programming(FP) and a lot of cool kids are doing it but it is not a silver bullet. Like other programming paradigms/styles, functional programming also has its pros and cons and one may prefer one paradigm over the other. If you are a TypeScript/JavaScript developer and wants to venture into functional programming, do not worry, you don’t have to learn functional programming oriented languages like Haskell or Clojure since JavaScript and hence TypeScript has you covered and this post is for you. If you are looking for functional programming in Java or Golang check other posts in the series. I’m not gonna dive into all functional programming concepts in detail, instead, I’m gonna focus on things that you can do in TypeScript which are in line with functional programming concepts. I’m also not gonna discuss the pros and cons of functional programming in general. Please keep in mind, though this post is about TypeScript, you can easily do the same in JavaScript as well since TypeScript is just a typed superset of JavaScript. What is functional programming?: As per Wikipedia,  Functional programming is a programming paradigm—a style of building the structure and elements of computer programs—that treats computation as the evaluation of mathematical functions and avoids changing-state and mutable data. Hence in functional programming, there are two very important rules  No Data mutations: It means a data object should not be changed after it is created.  No implicit state: Hidden/Implicit state should be avoided. In functional programming state is not eliminated, instead, its made visible and explicitThis means:  No side effects: A function or operation should not change any state outside of its functional scope. I. e, A function should only return a value to the invoker and should not affect any external state. This means programs are easier to understand.  Pure functions only: Functional code is idempotent. A function should return values only based on the arguments passed and should not affect(side-effect) or depend on global state. Such functions always produce the same result for the same arguments. Apart from these there are functional programming concepts below that can be applied in TypeScript, we will touch upon these further down.  Higher-order-functions Closures Currying Recursion Lazy evaluations Referential transparencyUsing functional programming doesn’t mean its all or nothing, you can always use functional programming concepts to complement Object-oriented concepts in TypeScript. The benefits of functional programming can be utilized whenever possible regardless of the paradigm or language you use. And that is exactly what we are going to see. Functional programming in TypeScript: TypeScript is not a purely functional language but offers a lot of concepts which are in line with functional languages, so let us see how we can apply some of the functional programming concepts above in TypeScript. First-class and higher-order functions: First-class functions(function as a first-class citizen) means you can assign functions to variables, pass a function as an argument to another function or return a function from another. TypeScript supports this and hence makes concepts like closures, currying, and higher-order-functions easy to write. A function can be considered as a higher-order-function only if it takes one or more functions as parameters or if it returns another function as a result. In TypeScript, this is quite easy to do 123456789101112131415161718type mapFn = (it: string) =&gt; number;// The higher-order-function takes an array and a function as argumentsfunction mapForEach(arr: string[], fn: mapFn): number[] {  const newArray: number[] = [];  arr. forEach(it =&gt; {    // We are executing the method passed    newArray. push(fn(it));  });  return newArray;}const list = [ Orange ,  Apple ,  Banana ,  Grape ];// we are passing the array and a function as arguments to mapForEach method. const out = mapForEach(list, (it: string): number =&gt; it. length);console. log(out); // [6, 5, 6, 5]But then in JavaScript/TypeScript we could also simply do it this way using built-in functional methods like map, reduce and so on. 123456const list = [ Orange ,  Apple ,  Banana ,  Grape ];// we are passing a function as arguments to the built-in map method. const out = list. map(it =&gt; it. length);console. log(out); // [6, 5, 6, 5]Closures and currying are also possible in TypeScript 123456789101112131415// this is a higher-order-function that returns a functionfunction add(x: number): (y: number) =&gt; number {  // A function is returned here as closure  // variable x is obtained from the outer scope of this method and memorized in the closure  return (y: number): number =&gt; x + y;}// we are currying the add method to create more variationsvar add10 = add(10);var add20 = add(20);var add30 = add(30);console. log(add10(5)); // 15console. log(add20(5)); // 25console. log(add30(5)); // 35There are also many built-in declarative higher-order-functions in TypeScript/JavaScript like map, reduce, forEach, filter and so on. There are also many libraries that provide functional interfaces to be used in TypeScript/JavaScript. Pure functions: As we saw already a pure function should return values only based on the arguments passed and should not affect or depend on global state. It is possible to do this in TypeScript easily. This is quite simple, take the below this is a pure function. It will always return the same output for the given input and its behavior is highly predictable. We can safely cache the method if needed. 123function sum(a: number, b: number): number {  return a + b;}If we add an extra line in this function, the behavior becomes unpredictable as it now has a side effect that affects an external state. 1234567const holder = {};function sum(a: number, b: number): number {  let c = a + b;  holder[`${a}+${b}`] = c;  return c;}So try to keep your functions pure and simple. Using tools like ESLint and typescript-eslint it is possible to enforce these. Recursion: Functional programming favors recursion over looping. Let us see an example for calculating the factorial of a number. In traditional iterative approach: 123456789function factorial(num: number): number {  let result = 1;  for (; num &gt; 0; num--) {    result *= num;  }  return result;}console. log(factorial(20)); // 2432902008176640000The same can be done using recursion as below which is favored in functional programming. 1234const factorial = (num: number): number =&gt;  num == 0 ? 1 : num * factorial3(num - 1);console. log(factorial(20)); // 2432902008176640000The downside of the recursive approach is that it will be slower compared to an iterative approach most of the times(The advantage we are aiming for is code simplicity and readability) and might result in stack overflow errors since every function call needs to be saved as a frame to the stack. To avoid this tail recursion is preferred, especially when the recursion is done too many times. In tail recursion, the recursive call is the last thing executed by the function and hence the functions stack frame need not be saved by the compiler. Most compilers can optimize the tail recursion code the same way iterative code is optimized hence avoiding the performance penalty. Tail call optimization is part of the ECMAScript specs but unfortunately, most JavaScript engines do not support this yet. Now using tail recursion the same function can be written as below, but depending on the engine this might not be optimized, though there are workarounds, still it performed better in benchmarks. 123456const factorialTailRec = (num: number): number =&gt; factorial(1, num);const factorial = (accumulator: number, val: number): number =&gt;  val == 1 ? accumulator : factorial(accumulator * val, val - 1);console. log(factorialTailRec(20)); // 2432902008176640000Consider using recursion when writing TypeScript code for readability and immutability, but if performance is critical or if the number of iterations will be huge use standard loops. Lazy evaluation: Lazy evaluation or non-strict evaluation is the process of delaying evaluation of an expression until it is needed. In general, TypeScript does strict/eager evaluation but for operands like &amp;&amp;, || and ?: it does a lazy evaluation. We can utilize short-circuiting, higher-order-functions, closures, and memoization techniques to do lazy evaluations. Take this example where TypeScript eagerly evaluates everything. 1234567891011121314151617181920function add(x: number): number {  console. log( executing add ); // this is printed since the functions are evaluated first  return x + x;}function multiply(x: number): number {  console. log( executing multiply ); // this is printed since the functions are evaluated first  return x * x;}function addOrMultiply(  add: boolean,  onAdd: number,  onMultiply: number): number {  return add ? onAdd : onMultiply;}console. log(addOrMultiply(true, add(4), multiply(4))); // 8console. log(addOrMultiply(false, add(4), multiply(4))); // 16This will produce the below output and we can see that both functions are executed always 123456executing addexecuting multiply8executing addexecuting multiply16We can use higher-order-functions to rewrite this into a lazily evaluated version 12345678910111213141516171819202122function add(x: number): number {  console. log( executing add );  return x + x;}function multiply(x: number): number {  console. log( executing multiply );  return x * x;}type fnType = (t: number) =&gt; number;// This is now a higher-order-function hence evaluation of the functions are delayed in if-elsefunction addOrMultiply(  add: boolean,  onAdd: fnType,  onMultiply: fnType,  t: number): number {  return add ? onAdd(t) : onMultiply(t);}console. log(addOrMultiply(true, add, multiply, 4));console. log(addOrMultiply(false, add, multiply, 4));This outputs the below and we can see that only required functions were executed 1234executing add8executing multiply16Or by memoization like this 1234567891011121314151617181920212223242526272829303132const cachedAdded = {};function add(x: number): number {  if (cachedAdded[x]) {    return cachedAdded[x];  }  console. log( executing add );  const out = x + x;  cachedAdded[x] = out;  return out;}const cachedMultiplied = {};function multiply(x: number): number {  if (cachedMultiplied[x]) {    return cachedMultiplied[x];  }  console. log( executing multiply );  const out = x * x;  cachedMultiplied[x] = out;  return out;}function addOrMultiply(  add: boolean,  onAdd: number,  onMultiply: number): number {  return add ? onAdd : onMultiply;}console. log(addOrMultiply(true, add(4), multiply(4))); // 8console. log(addOrMultiply(false, add(4), multiply(4))); // 16This outputs the below and we can see that functions were executed only once for the same values 1234executing addexecuting multiply816Please note that memoization techniques will work only when your functions are pure and referentially transparent. There are also other ways of doing Lazy evaluations like this. Doing Lazy evaluations in TypeScript might not be worth the code complexity some of the times, but if the functions in question are heavy in terms of processing then its is absolutely worth it to lazy evaluate them. Type system: TypeScript has a strong type system and also has great type inference. While the underlying JavaScript itself is weakly typed, TypeScript along with a compatible IDE can bridge that gap. Referential transparency: From Wikipedia:  Functional programs do not have assignment statements, that is, the value of a variable in a functional program never changes once defined. This eliminates any chances of side effects because any variable can be replaced with its actual value at any point of execution. So, functional programs are referentially transparent. Unfortunately, there are not many ways to strictly limit data mutation in JavaScript, however by using pure functions and by explicitly avoiding data mutations and reassignment using other concepts we saw earlier this can be achieved. JavaScript by default passes primitive variables by value and objects by reference so we need to take care not to mutate data inside functions. Libraries like Immutable JS could also be considered. Use const as much as possible to avoid reassignments. For example, the below will produce an error 123const list = [ Apple ,  Orange ,  Banana ,  Grape ];list = [ Earth ,  Saturn ];But this will not help when variables are holding references to other objects, for example, the below mutation will work irrespective of the const keyword. 1234const list = [ Apple ,  Orange ,  Banana ,  Grape ];list. push( Earth ); // will mutate the listlist. push( Saturn ); // will mutate the listconst keyword allows the internal state of referenced variables to be mutated and hence from a functional programming perspective const keyword is useful only for primitive constants and to catch reassignments. However, with TypeScript, we can use special mapped types to make objects read-only and hence avoiding accidental data mutations which are caught during compile time. Thanks to @stereobooster and @juliang for pointing it out. Read my post about mapped and conditional types here to learn more. 123const list: Readonly&lt;string[]&gt; = [ Apple ,  Orange ,  Banana ,  Grape ];list. push( Earth ); // will cause compilation erroror 123const list: ReadonlyArray&lt;string&gt; = [ Apple ,  Orange ,  Banana ,  Grape ];list. push( Earth ); // will cause compilation errorOther techniques to follow are using Object. freeze or built-in methods like map, reduce, filter and so on as they do not mutate the data. We can also use this ESlint plugin to restrict mutations. Data structures: When using functional programming techniques it is encouraged to use data types such as Stacks, Maps and Queues which have functional implementations as well. Hence maps are better than arrays or hash sets in functional programming as data stores. Conclusion: This is just an introduction for those who are trying to apply some functional programming techniques in TypeScript. There are a lot more that can be done in TypeScript and with the ever-evolving ECMAScript underneath, this should be even easier. As I said earlier functional programming is not a silver bullet but it offers a lot of useful techniques for more understandable, maintainable and testable code. It can co-exist perfectly well with imperative and object-oriented programming styles. In fact, we all should be using the best of everything. I hope you find this useful. If you have any question or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. "
    }, {
    "id": 12,
    "url": "/functional-programming-in-go/",
    "title": "7 Easy functional programming techniques in Go",
    "body": "2019/08/14 - There is a lot of hype around functional programming(FP) and a lot of cool kids are doing it but it is not a silver bullet. Like other programming paradigms/styles, functional programming also has its pros and cons and one may prefer one paradigm over the other. If you are a Go developer and wants to venture into functional programming, do not worry, you don’t have to learn functional programming oriented languages like Haskell or Clojure(or even Scala or JavaScript though they are not pure functional programming languages) since Go has you covered and this post is for you. If you are looking for functional programming in Java then check this out https://dev. to/deepu105/functional-programming-in-java-a-primer-13nb I’m not gonna dive into all functional programming concepts in detail, instead, I’m gonna focus on things that you can do in Go which are in line with functional programming concepts. I’m also not gonna discuss the pros and cons of functional programming in general. What is functional programming?: As per Wikipedia,  Functional programming is a programming paradigm—a style of building the structure and elements of computer programs—that treats computation as the evaluation of mathematical functions and avoids changing-state and mutable data. Hence in functional programming, there are two very important rules  No Data mutations: It means a data object should not be changed after it is created.  No implicit state: Hidden/Implicit state should be avoided. In functional programming state is not eliminated, instead, its made visible and explicitThis means:  No side effects: A function or operation should not change any state outside of its functional scope. I. e, A function should only return a value to the invoker and should not affect any external state. This means programs are easier to understand.  Pure functions only: Functional code is idempotent. A function should return values only based on the arguments passed and should not affect(side-effect) or depend on global state. Such functions always produce the same result for the same arguments. Apart from these there are functional programming concepts below that can be applied in Go, we will touch upon these further down.  Higher-order-functions Closures Currying Recursion Lazy evaluations Referential transparencyUsing functional programming doesn’t mean its all or nothing, you can always use functional programming concepts to complement Object-oriented or imperative concepts in Go. The benefits of functional programming can be utilized whenever possible regardless of the paradigm or language you use. And that is exactly what we are going to see. Functional programming in Go: Golang is a multi-paradigm language so let us see how we can apply some of the functional programming concepts above in Go. First-class and higher-order functions: First-class functions(function as a first-class citizen) means you can assign functions to variables, pass a function as an argument to another function or return a function from another. Go supports this and hence makes concepts like closures, currying, and higher-order-functions easy to write. A function can be considered as a higher-order-function only if it takes one or more functions as parameters or if it returns another function as a result. In Go, this is quite easy to do 12345678910111213141516171819func main() {	var list = []string{ Orange ,  Apple ,  Banana ,  Grape }	// we are passing the array and a function as arguments to mapForEach method. 	var out = mapForEach(list, func(it string) int {		return len(it)	})	fmt. Println(out) // [6, 5, 6, 5]}// The higher-order-function takes an array and a function as argumentsfunc mapForEach(arr []string, fn func(it string) int) []int {	var newArray = []int{}	for _, it := range arr {		// We are executing the method passed		newArray = append(newArray, fn(it))	}	return newArray}Closures and currying are also possible in Go 1234567891011121314151617181920// this is a higher-order-function that returns a functionfunc add(x int) func(y int) int {	// A function is returned here as closure	// variable x is obtained from the outer scope of this method and memorized in the closure	return func(y int) int {		return x + y	}}func main() {	// we are currying the add method to create more variations	var add10 = add(10)	var add20 = add(20)	var add30 = add(30)	fmt. Println(add10(5)) // 15	fmt. Println(add20(5)) // 25	fmt. Println(add30(5)) // 35}There are also many built-in higher-order-functions in Go standard libraries. There are also some functional style libraries like this and this offering map-reduce like functional methods in Go. Pure functions: As we saw already a pure function should return values only based on the arguments passed and should not affect or depend on global state. It is possible to do this in Go easily. This is quite simple, take the below this is a pure function. It will always return the same output for the given input and its behavior is highly predictable. We can safely cache the method if needed. 123func sum(a, b int) int {	return a + b}If we add an extra line in this function, the behavior becomes unpredictable as it now has a side effect that affects an external state. 1234567var holder = map[string]int{}func sum(a, b int) int {	c := a + b	holder[fmt. Sprintf( %d+%d , a, b)] = c	return c}So try to keep your functions pure and simple. Recursion: Functional programming favors recursion over looping. Let us see an example for calculating the factorial of a number. In traditional iterative approach: 1234567891011func factorial(num int) int {	result := 1	for ; num &gt; 0; num-- {		result *= num	}	return result}func main() {	fmt. Println(factorial(20)) // 2432902008176640000}The same can be done using recursion as below which is favored in functional programming. 123456789func factorial(num int) int {	if num == 0 {		return 1	}	return num * factorial(num-1)}func main() {	fmt. Println(factorial(20)) // 2432902008176640000}The downside of the recursive approach is that it will be slower compared to an iterative approach most of the times(The advantage we are aiming for is code simplicity and readability) and might result in stack overflow errors since every function call needs to be saved as a frame to the stack. To avoid this tail recursion is preferred, especially when the recursion is done too many times. In tail recursion, the recursive call is the last thing executed by the function and hence the functions stack frame need not be saved by the compiler. Most compilers can optimize the tail recursion code the same way iterative code is optimized hence avoiding the performance penalty. Go compiler, unfortunately, does not do this optimization. Now using tail recursion the same function can be written as below, but Go doesn’t optimize this, though there are workarounds, still it performed better in benchmarks. 1234567891011121314func factorialTailRec(num int) int {	return factorial(1, num)}func factorial(accumulator, val int) int {	if val == 1 {		return accumulator	}	return factorial(accumulator*val, val-1)}func main() {	fmt. Println(factorialTailRec(20)) // 2432902008176640000}I ran some benchmarks with all 3 approaches and here is the result, as you can see looping is still the most performing followed by the tail recursion. 12345678goos: linuxgoarch: amd64BenchmarkFactorialLoop-12    	100000000	    11. 7 ns/op	    0 B/op	    0 allocs/opBenchmarkFactorialRec-12    	30000000	    52. 9 ns/op	    0 B/op	    0 allocs/opBenchmarkFactorialTailRec-12  	50000000	    44. 2 ns/op	    0 B/op	    0 allocs/opPASSok 	_/home/deepu/workspace/deepu105. github. io/temp	5. 072sSuccess: Benchmarks passed. Consider using recursion when writing Go code for readability and immutability, but if performance is critical or if the number of iterations will be huge use standard loops. Lazy evaluation: Lazy evaluation or non-strict evaluation is the process of delaying evaluation of an expression until it is needed. In general, Go does strict/eager evaluation but for operands like &amp;&amp; and || it does a lazy evaluation. We can utilize higher-order-functions, closures, goroutines, and channels to emulate lazy evaluations. Take this example where Go eagerly evaluates everything. 123456789101112131415161718192021func main() {	fmt. Println(addOrMultiply(true, add(4), multiply(4))) // 8	fmt. Println(addOrMultiply(false, add(4), multiply(4))) // 16}func add(x int) int {	fmt. Println( executing add ) // this is printed since the functions are evaluated first	return x + x}func multiply(x int) int {	fmt. Println( executing multiply ) // this is printed since the functions are evaluated first	return x * x}func addOrMultiply(add bool, onAdd, onMultiply int) int {	if add {		return onAdd	}	return onMultiply}This will produce the below output and we can see that both functions are executed always 123456executing addexecuting multiply8executing addexecuting multiply16We can use higher-order-functions to rewrite this into a lazily evaluated version 12345678910111213141516171819202122func add(x int) int {	fmt. Println( executing add )	return x + x}func multiply(x int) int {	fmt. Println( executing multiply )	return x * x}func main() {	fmt. Println(addOrMultiply(true, add, multiply, 4))	fmt. Println(addOrMultiply(false, add, multiply, 4))}// This is now a higher-order-function hence evaluation of the functions are delayed in if-elsefunc addOrMultiply(add bool, onAdd, onMultiply func(t int) int, t int) int {	if add {		return onAdd(t)	}	return onMultiply(t)}This outputs the below and we can see that only required functions were executed 1234executing add8executing multiply16There are also other ways of doing it using Sync &amp; Futures like this and using channels and goroutines like this. Doing Lazy evaluations in Go might not be worth the code complexity most of the times, but if the functions in question are heavy in terms of processing then its is absolutely worth it to lazy evaluate them. Type system: Go has a strong type system and also has pretty decent type inference. The only thing missing compared to other functional programming languages are something like case classes and pattern matching. Referential transparency: From Wikipedia:  Functional programs do not have assignment statements, that is, the value of a variable in a functional program never changes once defined. This eliminates any chances of side effects because any variable can be replaced with its actual value at any point of execution. So, functional programs are referentially transparent. Unfortunately, there are not many ways to strictly limit data mutation in Go, however by using pure functions and by explicitly avoiding data mutations and reassignment using other concepts we saw earlier this can be achieved. Go by default passes variables by value, except for slices and maps. So, avoid passing them by reference(using pointers) as much as possible. For example, the below will mutate external state as we are passing a parameter by reference and hence doesn’t ensure referential transparency 12345678910111213141516171819func main() {	type Person struct {		firstName string		lastName string		fullName string		age    int	}	var getFullName = func(in *Person) string {		in. fullName = in. firstName + in. lastName // data mutation		return in. fullName	}	john := Person{		 john ,  doe ,   , 30,	}	fmt. Println(getFullName(&amp;john)) // johndoe	fmt. Println(john) // {john doe johndoe 30}}If we pass parameters by the value we can ensure referential transparency even if there is an accidental mutation of passed data within the function 12345678910111213141516171819func main() {	type Person struct {		firstName string		lastName string		fullName string		age    int	}	var getFullName = func(in Person) string {		in. fullName = in. firstName + in. lastName		return in. fullName	}	john := Person{		 john ,  doe ,   , 30,	}	fmt. Println(getFullName(john))	fmt. Println(john)}We cannot rely on this when passed parameters are maps or slices. Data structures: When using functional programming techniques it is encouraged to use functional data types such as Stacks, Maps and Queues. Hence maps are better than arrays or hash sets in functional programming as data stores. Conclusion: This is just an introduction for those who are trying to apply some functional programming techniques in Go. There are a lot more that can be done in Go and with the addition of generics in the next major version, this should be even easier. As I said earlier functional programming is not a silver bullet but it offers a lot of useful techniques for more understandable, maintainable and testable code. It can co-exist perfectly well with imperative and object-oriented programming styles. In fact, we all should be using the best of everything. I hope you find this useful. If you have any question or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. "
    }, {
    "id": 13,
    "url": "/static-site-generators-rundown-how-i-set-up-my-own-blog-with-jekyll/",
    "title": "Static Site Generators rundown - How I set up my own blog with Jekyll",
    "body": "2019/08/01 - Last month I decided to move my blogs from Medium to Dev. to, I have detailed the reasons in the below post. https://dev. to/deepu105/why-i-m-moving-away-from-medium-13ki A lot of people suggested in the comments to set up my own blog and cross-post to Dev. to instead of relying only on one platform and I completely agree with them. I was procrastinating setting up my own blog for quite some time now. Finally, I decided to do it and set up my own blog at https://deepu. tech/blogs/ in the process I also updated my personal website to use the same platform. So when I decided to do this finally I had to choose a blogging platform and there were few requirements I was keen about which influenced my decision. Requirements:  The platform should support writing posts using Markdown with code syntax highlights I love the Dev community and hence wanted to cross-post everything to Dev. to as well without having to make any changes to the post. Means I would author once and publish to both my blog and Dev. This means some constraints/requirements     It should support customizable front matter so that I can align it with Dev   It should support the custom liquid tags used by Dev or I should be able to easily add those    I should be able to have custom pages for my personal website Should be open source and have a good stable community Should be theme-able, have plugins for SEO, search and so on Should be statically generated and reasonably fast Should be able to host using GitHub pages - This was an optional requirementThe options rundown: With these in mind, I started evaluating some of the popular options below. Jekyll: Pros:  I have experience with Jekyll since I built the new JHipster website using it Supports Markdown, Liquid tags and Front Matter Supports custom pages, themes, plugins and is statically generated Is OSS and has a vibrant community Can be hosted on GitHubCons:  I would have to build or find replacements for the custom Liquid tags used by Dev I don’t have much experience with Ruby and I’m not very familiar with the Ruby ecosystem Not the fastest among the options. Becomes slower as site size increasesHugo: Pros:  Is very fast I have extensive experience with Go and Go templates which would be helpful Supports Markdown and Front Matter Supports custom pages, themes and is statically generated Is OSS and has a vibrant community Can be hosted on GitHubCons:  Doesn’t support Liquid tags Doesn’t have plugins. The built-in options are enough for my requirements at the moment thoughVuePress: Pros:  Built with VueJS and I have good experience with JavaScript and quite familiar with Vue Supports Markdown and Front Matter Supports custom pages, themes, SEO, search and is statically generated Is OSS and has a vibrant community Can be hosted on GitHubCons:  Doesn’t support Liquid tags Doesn’t have plugins. The built-in options are enough for my requirements at the moment though Not geared towards blogging, but it’s possible to do it easily with some hackingGatsby: Pros:  Built with React and I have good experience with React Supports Markdown and Front Matter Supports custom pages, themes, plugins and is statically generated Is OSS and has a vibrant community Can be hosted on GitHubCons:  Doesn’t support Liquid tagsWordPress: Pros:  Have used it in the past and is a battle-tested solution Supports Markdown using plugins Supports custom pages, themes, plugins and can be statically generated using plugins Is OSS and has a vibrant community Can be hosted on GitHub with some workaroundsCons:  Doesn’t support Front Matter and Liquid tags Since most of my core requirements can only be achieved using plugins and workarounds it feels too clumsyThough I personally liked Hugo because of its speed, based on the above the most logical choice for me was Jekyll. Building a personal website and blog with Jekyll: Getting started: Setting up Jekyll is super easy, I followed the official guide and had a site up and running in minutes. The steps in order were as below  Install a full Ruby development environment Install Jekyll and bundler gems for my user - gem install jekyll bundler --user-install Create a new site - jekyll new DeepuKSasidharan --skip-bundle, skipped the bundle install as I want to install to a vendor folder Cd into the folder DeepuKSasidharan and install gems to a vendor folder - bundle install --path vendor/bundle --full-index Start server - bundle exec jekyll serve and go to http://localhost:4000Using a Theme: Up next was setting up a custom theme, since I really like the minimal design of Medium, I decided to use Mediumish Jekyll Theme so I did the below steps to switch to this. Steps 3-5 above can be skipped and instead step 2 from the below can be done directly as well.  Delete the folder DeepuKSasidharan we created above Clone the theme to this folder - git clone https://github. com/wowthemesnet/mediumish-theme-jekyll. git DeepuKSasidharan Cd into the folder DeepuKSasidharan and install gems to a vendor folder - bundle install --path vendor/bundle --full-index Customize the _config. yaml file with my own user details, Google Analytics, Disqus ID and so on     I had to update the exclude section to add vendor/ to it and to . gitignore as well   Updated the jekyll-paginate plugin to jekyll-paginate-v2 in the plugins section   Commented out the baseurl section    Start server - bundle exec jekyll serve and go to http://localhost:4000Customizations: So now I had a good looking website with an about page and blog up and running. I customized the look and feel a bit and changed the default page from blogs to about. You can check the source code at deepu105/deepu105. github. io Now the next challenge was to make sure I can author once and post to both my blog and Dev. to, this means I have to make sure the front matter supported by Dev. to also works on my blog and any custom Liquid tags from Dev I use in the blog needs to work on my site as well. The first part was easy, I just had to customize my sites includes and layouts to use cover_image instead of image and use the tag: [] syntax for tags. I also added support for Dev. to like series and read time with a custom ruby plugin. Adding custom liquid tags: In order to use Dev. to tags, first I tried if I can reuse them from Dev since its OSS, but it seems like they are heavily coupled with Rails and internal models to be extracted into Gems. I created a ticket asking for it as well. So decided to write my own Liquid tags in Ruby. I reused available OSS Liquid tags and customized them to work like the Dev. to ones in syntax and feature. I ended up creating the codesandbox, twitter, gist, link, speakerdeck and youtube tags. You can find them here. Probably will add more as I use them. This is not scalable and I would love to see the Dev. to tags published as Ruby gems. For example, here is a simple stub for the youtube tag. 123456789101112131415161718192021module Jekyll   # A simple stub for the Dev. to youtube tag  class YoutubeTag &lt; Liquid::Tag   def initialize(name, id, tokens)    super    @id = id   end   def render(context)    %(&lt;p&gt;      &lt;div class= embed-video-container &gt;        &lt;iframe width= 710  height= 399  src= https://www. youtube. com/embed/#{@id}  allowfullscreen&gt;&lt;/iframe&gt;      &lt;/div&gt;    &lt;/p&gt;)   end  end end Liquid::Template. register_tag('youtube', Jekyll::YoutubeTag)Publishing to GitHub: Now that I have a site up and running with markdown posts that work in both my blog and Dev. to without having to make any adjustments, I decided to publish this to my Github accounts Github pages. But there was an issue here. Github doesn’t allow running any custom Ruby code on GitHub pages, so I can’t just push to GitHub and get the site built and published so I decided to write a simple script to do the site generation on my machine from the source branch and push it to the master branch on GitHub. 12345678910111213141516171819202122232425262728293031323334353637#!/bin/bashrm -rf _siteif [ -z  $(git status --porcelain)  ]; then  echo  &gt;&gt;&gt; Working directory clean   TMP_LOC=/tmp/deepu. github. io  /bin/rm -rf _site  /bin/rm -rf $TMP_LOC  echo  &gt;&gt; Building site   bundle update listen  bundle exec jekyll build  echo  &gt;&gt; Move site to temp folder   mkdir --parents $TMP_LOC  mv _site/* $TMP_LOC  echo  &gt;&gt; Checkout and clean master   git checkout master  find -mindepth 1 -depth -print0 | grep -vEzZ '(temp(/|$)|vendor(/|$)|\. git(/|$)|/\. gitignore$)' | xargs -0 rm -rvf  echo  &gt;&gt; Move site form temp &amp; publish to GitHub   mv $TMP_LOC/* .   now=$(date)  git add --all  git commit -am  Updated site on $now   git push origin master --force  echo  $now: Published changes to GitHub   git checkout site_srcelse  echo  Working directory is not clean. Commit changes!   exitfiMy current workflow: So now that I have things in place, I author posts as markdown with a full front matter like below and publish on my blog first. Then I publish the same to Dev. to 12345678---title:  Static Site Generators rundown - How I set up my own blog with Jekyll published: falsedescription: Static Site Generators comparisontags: [showdev, ruby, Jekyll, blogging]cover_image:canonical_url: https://deepu. tech/setting-up-a-blog-with-jekyll/---I’m not using the RSS import option in Dev as it uses the rendered blog and hence might need adjustments. I also set the canonical_url to my blog site. Future plans: There are some things that can be improved.  Use the Dev. to API to publish this direct from my publish script when I author a new post or make updates to an existing one.  Improve the link tag and add some more tags for GitHub.  Use local assets image for my own blog and generate the image URL for Dev. to when publishing.  Currently, all links point to Dev. to, make the link tag smart enough to point to my blog when published to my site(I don’t want my readers to switch between sites). This might be a bit hard since Dev. to links have a random suffix. So what do you think? If you have any suggestions on improvements or questions leave a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Cover image credit: Photo by Patrick Fore on Unsplash "
    }, {
    "id": 14,
    "url": "/functional-programming-in-java-for-beginners/",
    "title": "7 Functional programming techniques in Java - A primer",
    "body": "2019/07/30 - There is a lot of hype around functional programming(FP) and a lot of cool kids are doing it but it is not a silver bullet. Like other programming paradigms/styles, functional programming also has its pros and cons and one may prefer one paradigm over the other. If you are a Java developer and wants to venture into functional programming, do not worry, you don’t have to learn functional programming oriented languages like Haskell or Clojure(or even Scala or JavaScript though they are not pure functional programming languages) since Java has you covered and this post is for you. I’m not gonna dive into all functional programming concepts in detail, instead, I’m gonna focus on things that you can do in Java which are in line with functional programming concepts. I’m also not gonna discuss the pros and cons of functional programming in general. What is functional programming?: As per Wikipedia,  Functional programming is a programming paradigm—a style of building the structure and elements of computer programs—that treats computation as the evaluation of mathematical functions and avoids changing-state and mutable data. Hence in functional programming, there are two very important rules  No Data mutations: It means a data object should not be changed after it is created.  No implicit state: Hidden/Implicit state should be avoided. In functional programming state is not eliminated, instead, its made visible and explicitThis means:  No side effects: A function or operation should not change any state outside of its functional scope. I. e, A function should only return a value to the invoker and should not affect any external state. This means programs are easier to understand.  Pure functions only: Functional code is idempotent. A function should return values only based on the arguments passed and should not affect(side-effect) or depend on global state. Such functions always produce the same result for the same arguments. Apart from these there are functional programming concepts below that can be applied in Java, we will touch upon these further down.  Higher-order-functions Closures Currying Recursion Lazy evaluations Referential transparencyUsing functional programming doesn’t mean its all or nothing, you can always use functional programming concepts to complement Object-oriented concepts, especially in Java. The benefits of functional programming can be utilized whenever possible regardless of the paradigm or language you use. And that is exactly what we are going to see. Functional programming in Java: So let us see how we can apply some of the functional programming concepts above in Java. We will be using Java 11 as it is the LTS version currently. First-class and higher-order functions: First-class functions(function as a first-class citizen) means you can assign functions to variables, pass a function as an argument to another function or return a function from another. Unfortunately, Java doesn’t support this and hence makes concepts like closures, currying and higher-order-functions less convenient to write. The closest to first-class functions in Java is Lambda expressions. There are also some built-in functional interfaces like Function, Consumer, Predicate, Supplier and so on under the java. util. function package which can be used for functional programming. A function can be considered as a higher-order-function only if it takes one or more functions as parameters or if it returns another function as a result. The closest to higher-order-functions we can get in Java is using Lambda expressions and built-in Functional interfaces. This is not the nicest looking way of doing higher-order-functions, but this is how it is in Java and its not that bad IMO. 12345678910111213141516171819202122232425262728public class HocSample {  public static void main(String[] args) {    var list = Arrays. asList( Orange ,  Apple ,  Banana ,  Grape );    // we are passing an array and an anonymous inner class instance of FnFactory as arguments to mapForEach method.     var out = mapForEach(list, new FnFactory&lt;String, Object&gt;() {      @Override      public Object execute(final String it) {        return it. length();      }    });    System. out. println(out); // [6, 5, 6, 5]  }  // The method takes an array and an instance of FnFactory as arguments  static &lt;T, S&gt; ArrayList&lt;S&gt; mapForEach(List&lt;T&gt; arr, FnFactory&lt;T, S&gt; fn) {    var newArray = new ArrayList&lt;S&gt;();    // We are executing the method from the FnFactory instance    arr. forEach(t -&gt; newArray. add(fn. execute(t)));    return newArray;  }  @FunctionalInterface // this doesn't do anything it is just informative.   public interface FnFactory&lt;T, S&gt; {    // The interface defines the contract for the anonymous class    S execute(T it);  }}Fortunately, can actually simplify the above example further using the built-in Function interface and using the lambda expression syntax. 1234567891011121314151617public class HocSample {  public static void main(String[] args) {    var list = Arrays. asList( Orange ,  Apple ,  Banana ,  Grape );    // we are passing the array and a lambda expression as arguments to mapForEach method.     var out = mapForEach(list, it -&gt; it. length());     // This can be further simplified to  mapForEach(list, String::length); , I'm writing the expanded version for readability    System. out. println(out); // [6, 5, 6, 5]  }  // The method takes an array and an instance of Function as arguments (we have replaced the custom interface with the built-in one)  static &lt;T, S&gt; ArrayList&lt;S&gt; mapForEach(List&lt;T&gt; arr, Function&lt;T, S&gt; fn) {    var newArray = new ArrayList&lt;S&gt;();    // We are executing the method from the Function instance    arr. forEach(t -&gt; newArray. add(fn. apply(t)));    return newArray;  }}Using these concepts along with lambda expressions we can write closures and currying like below 1234567891011121314151617181920212223242526272829public class ClosureSample {  // this is a higher-order-function that returns an instance of Function interface  Function&lt;Integer, Integer&gt; add(final int x) {    // this is a closure, i. e, a variable holding an anonymous inner class instance of the Function interface    // which uses variables from the outer scope    Function&lt;Integer, Integer&gt; partial = new Function&lt;Integer, Integer&gt;() {      @Override      public Integer apply(Integer y) {        // variable x is obtained from the outer scope of this method which is declared as final        return x + y;      }    };    // The closure function instance is returned here    return partial;  }  public static void main(String[] args) {    ClosureSample sample = new ClosureSample();    // we are currying the add method to create more variations    Function&lt;Integer, Integer&gt; add10 = sample. add(10);    Function&lt;Integer, Integer&gt; add20 = sample. add(20);    Function&lt;Integer, Integer&gt; add30 = sample. add(30);    System. out. println(add10. apply(5)); // 15    System. out. println(add20. apply(5)); // 25    System. out. println(add30. apply(5)); // 35  }}We can simplify this further with lambda expressions like below 123456789101112131415161718192021public class ClosureSample {  // this is a higher-order-function that returns an instance of Function interface  Function&lt;Integer, Integer&gt; add(final int x) {    // The lambda expression is returned here as closure    // variable x is obtained from the outer scope of this method which is declared as final    return y -&gt; x + y;  }  public static void main(String[] args) {    ClosureSample sample = new ClosureSample();    // we are currying the add method to create more variations    Function&lt;Integer, Integer&gt; add10 = sample. add(10);    Function&lt;Integer, Integer&gt; add20 = sample. add(20);    Function&lt;Integer, Integer&gt; add30 = sample. add(30);    System. out. println(add10. apply(5));    System. out. println(add20. apply(5));    System. out. println(add30. apply(5));  }}There are also many built-in higher-order-functions in Java for example here is the sort method from java. util. Collections 12345678List&lt;String&gt; list = Arrays. asList( Apple ,  Orange ,  Banana ,  Grape );// This can be simplified as  Collections. sort(list, Comparator. naturalOrder()); , I'm writing the expanded version for readabilityCollections. sort(list, (String a, String b) -&gt; {  return a. compareTo(b);});System. out. println(list); // [Apple, Banana, Grape, Orange]The Java stream API also provides many interesting higher-order-functions like forEach, map and so on. Pure functions: As we saw already a pure function should return values only based on the arguments passed and should not affect or depend on global state. It is possible to do this in Java except for some cases when there are checked exceptions involved. This is quite simple, take the below this is a pure function. It will always return the same output for the given input and its behavior is highly predictable. We can safely cache the method if needed. 123public static int sum(int a, int b) {  return a + b;}If we add an extra line in this function, the behavior becomes unpredictable as it now has a side effect that affects an external state. 1234567static Map map = new HashMap&lt;String, Integer&gt;();public static int sum(int a, int b) {  var c = a + b;  map. put(a +  +  + b, c);  return c;}So try to keep your functions pure and simple. Recursion: Functional programming favors recursion over looping. In Java, this can be achieved either by using the stream API or by writing recursive functions. Let us see an example for calculating the factorial of a number. I also ran a benchmark on these using JMH and mentioned the nanoseconds/operation below In traditional iterative approach: 1234567891011121314public class FactorialSample {  // benchmark 9. 645 ns/op  static long factorial(long num) {    long result = 1;    for (; num &gt; 0; num--) {      result *= num;    }    return result;  }  public static void main(String[] args) {    System. out. println(factorial(20)); // 2432902008176640000  }}The same can be done using recursion as below which is favored in functional programming. 12345678910public class FactorialSample {  // benchmark 19. 567 ns/op  static long factorialRec(long num) {    return num == 1 ? 1 : num * factorialRec(num - 1);  }  public static void main(String[] args) {    System. out. println(factorialRec(20)); // 2432902008176640000  }}The downside of the recursive approach is that it will be slower compared to an iterative approach most of the times(The advantage we are aiming for is code simplicity and readability) and might result in stack overflow errors since every function call needs to be saved as a frame to the stack. To avoid this tail recursion is preferred, especially when the recursion is done too many times. In tail recursion, the recursive call is the last thing executed by the function and hence the functions stack frame need not be saved by the compiler. Most compilers can optimize the tail recursion code the same way iterative code is optimized hence avoiding the performance penalty. Java compiler, unfortunately, does not do this optimization :( Now using tail recursion the same function can be written as below, but Java doesn’t optimize this, though there are workarounds, still it performed better in benchmarks. 1234567891011121314public class FactorialSample {  // benchmark 16. 701 ns/op  static long factorialTailRec(long num) {    return factorial(1, num);  }  static long factorial(long accumulator, long val) {    return val == 1 ? accumulator : factorial(accumulator * val, val - 1);  }  public static void main(String[] args) {    System. out. println(factorialTailRec(20)); // 2432902008176640000  }}We can also use the Java stream library for recursion but its slower than normal recursion at the moment. 1234567891011public class FactorialSample {  // benchmark 59. 565 ns/op  static long factorialStream(long num) {    return LongStream. rangeClosed(1, num)        . reduce(1, (n1, n2) -&gt; n1 * n2);  }  public static void main(String[] args) {    System. out. println(factorialStream(20)); // 2432902008176640000  }}Consider using stream API or recursion when writing Java code for readability and immutability, but if performance is critical or if the number of iterations will be huge use standard loops. Lazy evaluation: Lazy evaluation or non-strict evaluation is the process of delaying evaluation of an expression until it is needed. In general, Java does strict evaluation but for operands like &amp;&amp;, || and ?: it does a lazy evaluation. We can utilize this to do lazy evaluations when writing java code. Take this example where Java eagerly evaluates everything. 1234567891011121314151617181920public class EagerSample {  public static void main(String[] args) {    System. out. println(addOrMultiply(true, add(4), multiply(4))); // 8    System. out. println(addOrMultiply(false, add(4), multiply(4))); // 16  }  static int add(int x) {    System. out. println( executing add ); // this is printed since the functions are evaluated first    return x + x;  }  static int multiply(int x) {    System. out. println( executing multiply ); // this is printed since the functions are evaluated first    return x * x;  }  static int addOrMultiply(boolean add, int onAdd, int onMultiply) {    return (add) ? onAdd : onMultiply;  }}This will produce the below output and we can see that both functions are executed always 123456executing addexecuting multiply8executing addexecuting multiply16We can use lambda expressions and higher-order-functions to rewrite this into a lazily evaluated version 1234567891011121314151617181920212223242526public class LazySample {  public static void main(String[] args) {    // This is a lambda expression behaving as a closure    Function&lt;Integer, Integer&gt; add = t -&gt; {      System. out. println( executing add );      return t + t;    };    // This is a lambda expression behaving as a closure    Function&lt;Integer, Integer&gt; multiply = t -&gt; {      System. out. println( executing multiply );      return t * t;    };    // Lambda closures are passed instead of plain functions    System. out. println(addOrMultiply(true, add, multiply, 4));    System. out. println(addOrMultiply(false, add, multiply, 4));  }  // This is a higher-order-function  static &lt;T, R&gt; R addOrMultiply(      boolean add, Function&lt;T, R&gt; onAdd,      Function&lt;T, R&gt; onMultiply, T t  ) {    // Java evaluates expressions on ?: lazily hence only the required method is executed    return (add ? onAdd. apply(t) : onMultiply. apply(t));  }}This outputs the below and we can see that only required functions were executed 1234executing add8executing multiply16Type system: Java has a strong type system and with the introduction of the var keyword it now also has pretty decent type inference. The only thing missing compared to other functional programming languages are case classes. There are proposals for value classes and case classes for future Java versions. Let’s hope they make it. Referential transparency: From Wikipedia:  Functional programs do not have assignment statements, that is, the value of a variable in a functional program never changes once defined. This eliminates any chances of side effects because any variable can be replaced with its actual value at any point of execution. So, functional programs are referentially transparent. Unfortunately, there are not many ways to limit data mutation in Java, however by using pure functions and by explicitly avoiding data mutations and reassignment using other concepts we saw earlier this can be achieved. For variables, we can use the final keyword which is a non-access modifier to avoid mutations by reassignments. For example, the below will produce an error at compilation 123final var list = Arrays. asList( Apple ,  Orange ,  Banana ,  Grape );list = Arrays. asList( Earth ,  Saturn );But this will not help when variables are holding references to other objects, for example, the below mutation will work irrespective of the final keyword. 1234final var list = new ArrayList&lt;&gt;();list. add( Test );list. add( Test 2 );final keyword allows the internal state of referenced variables to be mutated and hence from a functional programming perspective final keyword is useful only for constants and to catch reassignments. Data structures: When using functional programming techniques it is encouraged to use functional data types such as Stacks, Maps and Queues. Hence maps are better than arrays or hash sets in functional programming as data stores. Conclusion: This is just an introduction for those who are trying to apply some functional programming techniques in Java. There are lot more that can be done in Java and Java 8 added a lot of API to make it easy to do functional programming in Java, like the stream API, Optional interface, functional interfaces and so on. As I said earlier functional programming is not a silver bullet but it offers a lot of useful techniques for more understandable, maintainable and testable code. It can co-exist perfectly well with imperative and object-oriented programming styles. In fact, we all should be using the best of everything. This video from Venkat Subramaniam is a great resource to dive deep into functional programming in Java                         I hope you find this useful. If you have any question or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. "
    }, {
    "id": 15,
    "url": "/jhipster-microservices-with-istio-service-mesh-on-kubernetes/",
    "title": "How to set up Java microservices with Istio service mesh on Kubernetes",
    "body": "2019/07/23 - Originally published at Medium on 17-Nov-2018. This post has been updated since to work with the latest version of JHipster(6. 3. 0) and Istio(1. 3. 0). Istio is the coolest kid on the DevOps and Cloud block now. For those of you who aren’t following close enough — Istio is a service mesh for distributed application architectures, especially the ones that you run on the cloud with Kubernetes. Istio plays extremely nice with Kubernetes, so nice that you might think that it’s part of the Kubernetes platform. If you are still wondering, what the heck is a service mesh or Istio? then let’s have an overview of Istio. Istio: Istio provides the following functionality in a distributed application architecture:    Service discovery — Traditionally provided by platforms like Netflix Eureka or Consul.     Automatic load balancing — You might have used Netflix Zuul for this.     Routing, circuit breaking, retries, fail-overs, fault injection — Think of Netflix Ribbon, Hytrix and so on.     Policy enforcement for access control, rate limiting, A/B testing, traffic splits, and quotas — Again you might have used Zuul to do some of these.     Metrics, logs, and traces — Think of ELK or Stack driver     Secure service-to-service communication  Below is the architecture of Istio. Istio architecture It can be classified into 2 distinct planes. Data plane: Is made of Envoy proxies deployed as sidecars to the application containers. They control all the incoming and outgoing traffic to the container. Control plane: It uses Pilot to manages and configure the proxies to route traffic. It also configures Mixer to enforce policies and to collect telemetry. It also has other components like Citadel, to manage security, and Galley, to manage configurations. Istio can also configure an instance of Grafana, Prometheus, Jaeger, and Kiali for Monitoring and Observability. You can use this or use your existing monitoring stack as well if you wish to do so. I hope this provides an overview of Istio, now let’s focus on the goal of this article. Preparing the Kubernetes cluster: First, let us prepare a Kubernetes cluster to deploy Istio and our application containers. Follow the instructions for any one of the platforms you prefer. Prerequisites: We will be using Helm to install Istio on the Kubernetes cluster and kubectl for deploying the applications. Helm: The Kubernetes package manager. Install it. kubectl: The command-line tool to interact with Kubernetes. Install and configure it. Create a cluster on Azure Kubernetes Service(AKS): If you are going to use Azure, then install Azure CLI to interact with Azure. Install and login with your Azure account (you can create a free account if you don’t have one already). If not skip this section. First, let us create a resource group. You can use any region you like here instead of East-US. 1$ az group create --name eCommerceCluster --location eastusCreate the Kubernetes cluster: 1234567$ az aks create \ --resource-group eCommerceCluster \ --name eCommerceCluster \ --node-count 4 \ --kubernetes-version 1. 13. 7 \ --enable-addons monitoring \ --generate-ssh-keysThe node-count flag is important as the setup requires at least four nodes with the default CPU to run everything. You can try to use a higher kubernetes-version if it is supported, else stick to 1. 13 The cluster creation could take while so sit back and relax. 🍹 Once the cluster is created, fetch its credentials to be used from kubectl by running the below command. It automatically injects the credentials to your kubectl configuration under ~/. kube/config 123$ az aks get-credentials \ --resource-group eCommerceCluster \ --name eCommerceClusterYou can view the created cluster in the Azure portal: Kubernetes cluster in AKS Run kubectl get nodes to see it in the command line and to verify that kubectl can connect to your cluster. Cluster Nodes Proceed to the Install and setup Istio section. Create a cluster on Google Kubernetes Engine(GKE): If you are going to use Google Cloud Platform(GCP) then install Gcloud CLI to interact with GCP. Install and login with your GCP account (you can create a free account if you don’t have one already). You can set a region and zone using below commands or you can pass the zone option while executing each command. 12$ gcloud config set compute/region europe-west1$ gcloud config set compute/zone europe-west1-bFirst, we need a GCP project, you can either use an existing project that you have or create a new one using GCloud CLI with below command: 1$ gcloud projects create jhipster-demo-deepuSet the project you want to use as the default project: 1$ gcloud config set project jhipster-demo-deepuNow let us create a cluster for our application with the below command: 1234$ gcloud container clusters create hello-hipster \  --cluster-version 1. 13 \  --num-nodes 4 \  --machine-type n1-standard-2The num-nodes and machine-type flags are important as the setup requires at least four nodes with a bigger CPU to run everything. You can try to use a higher cluster-version if it is supported, else stick to 1. 13. The cluster creation could take while so sit back and relax. 🍹 Once the cluster is created, fetch its credentials to be used from kubectl by running the below command. It automatically injects the credentials to your kubectl configuration under ~/. kube/config 1$ gcloud container clusters get-credentials hello-hipsterYou can view the created cluster in the GCP GUI. Kubernetes cluster on GKE Run kubectl get nodes to see it in the command line and to verify that kubectl can connect to your cluster. Cluster Nodes Install and setup Istio: Install Istio on your local machine by following these steps: 123456789$ cd ~/$ export ISTIO_VERSION=1. 3. 0$ curl -L https://git. io/getLatestIstio | sh -$ ln -sf istio-$ISTIO_VERSION istio$ export PATH=~/istio/bin:$PATHFirst, create a role binding on the Kubernetes cluster for Istio. 1234$ kubectl create clusterrolebinding cluster-admin-binding \ --clusterrole=cluster-admin \ --user= $(gcloud config get-value core/account) Let us create a namespace for Istio. 1$ kubectl create namespace istio-systemNow let us install Istio on our Kubernetes cluster using the provided helm charts from Istio. 123456789101112$ cd ~/istio-$ISTIO_VERSION# Install the Istio CRDs$ helm template install/kubernetes/helm/istio-init --name istio-init --namespace istio-system | kubectl apply -f -# Run this to verify all CRDs are installed. It should output 23 for this version of Istio. $ kubectl get crds | grep 'istio. io\|certmanager. k8s. io' | wc -l# Install the Istio demo set up so that we get Grafana, Jaeger &amp; Kiali set up as well. # For production, use the Istio default setup. Refer https://istio. io/docs/setup/kubernetes/install/helm/$ helm template install/kubernetes/helm/istio --name istio --namespace istio-system \  --values install/kubernetes/helm/istio/values-istio-demo. yaml | kubectl apply -f -Wait for the pods to run, these will be deployed to the istio-system namespace. 1$ watch kubectl get pods -n istio-systemOnce the pods are in running status, exit the watch loop and run the below to get the Ingress gateway service details. This is the only service that is exposed to an external IP. 1234$ kubectl get svc istio-ingressgateway -n istio-systemNAME          TYPE      CLUSTER-IP   EXTERNAL-IPistio-ingressgateway  LoadBalancer  10. 27. 249. 83  35. 195. 81. 130If the istio-ingressgateway shows external IP as , wait a few minutes until an IP address has been assigned. The external IP is very important here, let us save this to an environment variable so that we can use it in further commands. 1234$ export \ INGRESS_IP=$(kubectl -n istio-system get svc \ istio-ingressgateway \ -o jsonpath='{. status. loadBalancer. ingress[0]. ip}')Now our Kubernetes cluster is ready for Istio. 🎉 For advanced Istio setup options refer to https://istio. io/docs/setup/kubernetes/ Creating the microservice application stack: In one of my previous posts, I showcased how to create a full-stack microservice architecture using JHipster and JDL. You can read the post here if you want to learn more details about it. For this exercise, we will use the same application but we will not use the Eureka service discovery option we used earlier. Also, note that the store application is further split into Gateway and Product applications. Architecture: Here is the architecture of the microservice that we are going to create and deploy today. Microservice architecture with Istio It has a gateway application and three microservice applications. Each of them has its own database. You can see that each application has an Envoy proxy attached to the pod as a sidecar. Istio control plane components are also deployed to the same cluster along with Prometheus, Grafana, and Jaeger. The Ingress gateway from Istio is the only entry point for traffic and it routes traffic to all microservices accordingly. Telemetry is collected from all the containers running in the cluster, including the applications, databases, and Istio components. Compared to the architecture of the original application here, you can clearly see that we replaced the JHipster registry and Netflix OSS components with Istio. The ELK monitoring stack is replaced with Prometheus, Grafana and Jaeger configured by Istio. Here is the original architecture diagram without Istio for a quick visual comparison. Microservice architecture with Netflix OSS Application JDL: Let’s take a look at the modified JDL declaration. You can see that we have declared serviceDiscoveryType no here since we will be using Istio for that. 400: Invalid requestDeployment JDL: JHipster version 5. 7. 0 introduced support for deployment declaration straight in the JDL Towards the future of #JHipster, #ScaffoldingAsCodeCheck this out. Soon you will be able to define apps, entities and deployment options with a single JDL file and generate everything with a single command. Hopefully, we can demo this for @Devoxx https://t. co/u28cwaymfc &mdash; Deepu K Sasidharan ( ദീപു, தீபு, दीपू ) (@deepu105) October 28, 2018We have the below in our JDL which declares our Kubernetes deployment: 12345678910deployment { deploymentType kubernetes appsFolders [store, invoice, notification, product] dockerRepositoryName  deepu105  serviceDiscoveryType no istio true kubernetesServiceType Ingress kubernetesNamespace jhipster ingressDomain  35. 195. 81. 130. nip. io }The serviceDiscoveryType is disabled and we have enabled Istio support — the Envoy sidecars are injected automatically for the selected applications. Istio routes are also generated for the applications automatically. The kubernetesServiceType is set as Ingress, which is very important as Istio can only work with an Ingress controller service type. For Ingress, we need to set the domain DNS and this is where the Istio ingress gateway IP is needed. Now we need a DNS for our IP. For real use-cases, you should map a DNS for the IP, but for testing and demo purposes we can use a wildcard DNS service like nip. io to resolve our IP. Just append nip. io to our IP and use that as the ingressDomain. Note: I was switching between multiple clusters while writing this article as I didn’t want to keep them running and hence my istio-ingressgateway IP might be different between samples and screenshots. Use the IP based on your own setup if you are running these samples. Generate the applications and deployment manifests: Now that our JDL is ready, let us scaffold our applications and Kubernetes manifests. Create a new directory and save the above JDL in the directory. Let us name it app-istio. jdl and then run the import-jdl command. 12$ mkdir istio-demo &amp;&amp; cd istio-demo$ jhipster import-jdl app-istio. jdlThis will generate all the applications and install the required NPM dependencies in each of them. Once the applications are generated the deployment manifests will be generated and some useful instruction will be printed to the console. Generation output Open the generated code in your favorite IDE/Editor and explore the code. Interim issues with generated code: There was a bug in the latest JHipster version which creates some incorrect URLs for Istio, it has been fixed as of JHipster version 6. 3. 0 here is the PR for the issue. Deploy to Kubernetes cluster using Kubectl: Now let us build and deploy our applications. Run the . /gradlew bootJar -Pprod jibDockerBuild command in the store, product, invoice, and notification folders to build the docker images. Once the images are built, push them to your docker repo with these commands. Note to change the Docker hub id from deepu105 to your id. 1234567891011$ docker image tag store deepu105/store$ docker push deepu105/store$ docker image tag invoice deepu105/invoice$ docker push deepu105/invoice$ docker image tag notification deepu105/notification$ docker push deepu105/notification$ docker image tag product deepu105/product$ docker push deepu105/productOnce the images are pushed, navigate into the generated Kubernetes directory and run the provided startup script. (If you are on windows you can run the steps in kubectl-apply. sh manually one by one. ) 12$ cd kubernetes$ . /kubectl-apply. shRun watch kubectl get pods -n jhipster to monitor the status. Deployed applications: Once all the pods are in running status we can explore the deployed applications Application gateway: The store gateway application is the entry point for our microservices. Get the URL for the store app by running echo store. jhipster. $INGRESS_IP. nip. io, we already stored the INGRESS_IP to environment variables while creating the Istio setup. The URLs are also printed on console by the kubectl-apply. sh script. Visit the URL in your favorite browser and explore the application. Try creating some entities for the microservices: Store gateway application Monitoring: Istio setup includes Grafana and Prometheus configured to collect and show metrics from our containers. Let’s take a look. Let us look at Grafana by visiting the provided URL. Get it by running echo grafana. istio-system. $INGRESS_IP. nip. io: Grafana dashboard for the Store application Grafana uses the metrics scraped by Prometheus. By default, only Grafana is exposed to external IP and hence we will use kubectl port forwarding to set up a secure tunnel to Prometheus available on localhost:9090: 123$ kubectl -n istio-system \  port-forward $(kubectl -n istio-system get pod -l \  app=prometheus -o jsonpath='{. items[0]. metadata. name}') 9090:9090Prometheus dashboard Observability: Istio configures Jaeger for distributed tracing and Kiali for service observability. Let us take a look at them. Get the Jaeger URL by running echo jaeger. istio-system. $INGRESS_IP. nip. io: Jaeger tracing dashboard You can make some requests in the application and find it in the tracing dashboard by querying for the service. Click on any request to see tracing details. Let us now look at Kiali. Get the URL by running echo kiali. istio-system. $INGRESS_IP. nip. io, use the credentials user: admin, password: admin to log in: Kiali service graph Conclusion: Istio provides building blocks to build distributed microservices in a more Kubernetes-native way and takes the complexity and responsibility of maintaining those blocks away from you. This means you do not have to worry about maintaining the code or deployments for service discovery, tracing and so on. Istio documentation says  Deploying a microservice-based application in an Istio service mesh allows one to externally control service monitoring and tracing, request (version) routing, resiliency testing, security and policy enforcement, etc. , in a consistent way across the services, for the application as a whole. Werner Vogels (CTO of AWS) quoted at AWS Re:Invent  “In the future, all the code you ever write will be business logic. ” Istio Service mesh helps to make that reality closer. This lets you worry only about the applications that you are developing and with JHipster that future is truly here and you just need to worry about writing your business logic. While this is great, it is not a silver bullet. Keep in mind that Istio is fairly new compared to other stable and battle-tested solutions like JHipster Registry (Eureka) or Consul and overall such architectures are suitable only for complex distributed applications. Also, another thing to keep in mind is the resource requirements. The same microservices with JHipster Registry or Consul can be deployed to a 2 node cluster with 1 vCPU and 3. 75 GB of memory per node in GCP while you need a 4 node cluster with 2 vCPUs and 7. 5 GB of memory per node for Istio enabled deployments. The demo profile from Istio, we used, doesn’t apply any request limits for resources, and by adding and tuning those, the minimum requirement could be reduced. But still, I don’t think you can get it as low as that is needed for the JHipster registry option. In a real-world use case, the advantages of not having to maintain the complex parts of your infra vs having to pay for more resources might be a decision that has to be taken based on your priorities and goals. A huge shout out to Ray Tsang for helping me figure out an optimal cluster size for this application originally. Also a huge thank you from myself and the community to both Ray and Srinivasa Vasu for adding the Istio support to JHipster. JHipster provides a great Kubernetes setup to start with which you can further tweak as per your needs and platform. The Istio support will improve further over time, but it’s still a great starting point especially to learn. To learn more about JHipster and Full stack development, check out my book “Full Stack Development with JHipster” on Amazon and Packt. There is a great Istio tutorial from Ray Tsang here. Devoxx 2018: I did a talk at Devoxx 2018 along with Julien Dubois doing the same demo and promised that I’d write a detailed blog about it. This blog was originally based on that. Had a wonderful time at #devoxx2018, sad that I had to leave early due to work commitments. Had 3 talks and 1 of them with my friend and the real hipster @juliendubois, all the talks were well received and I&#39;m grateful for all the positive feedback. Will write blogs about it soon &mdash; Deepu K Sasidharan ( ദീപു, தீபு, दीपू ) (@deepu105) November 15, 2018You can watch this video to see JHipster + Istio in action.                          Here are the slides on Speaker Deck.                                                 If you like JHipster don’t forget to give it a star on Github. If you like this article, please leave likes/comments. I hope to write more about Istio soon. You can follow me on Twitter and LinkedIn. "
    }, {
    "id": 16,
    "url": "/make-the-most-out-of-vscode/",
    "title": "My VS Code setup - Making the most out of VS Code",
    "body": "2019/07/17 - Visual Studio Code(I like the sound of VS Code better), I just love it. It is my primary IDE. I always loved lightweight editors over IDEs. Many years ago I was using Eclipse for development and Notepad++ with some plugins for all other lightweight stuff. Then I discovered sublime text and was using it for a while. I still was finding Eclipse too heavyweight when I was doing web development. Then came Brackets from Adobe. It was a fairly nice editor especially for web development and I started using it heavily for web development. But Brackets was bit slow back then on a large codebase. Then came Atom which revolutionized the NodeJS desktop application landscape by introducing the Atom shell which ultimately became Electron. So I switched to Atom and loved its slick interface and nice pluggable features. It became my primary editor for all web development. So Electron paved the way for VS Code and though at first, I was skeptical dues to the association with Visual Studio, I tried it out and was amazed by its speed and user experience. There was no turning back now. I slowly started using VS Code for most of my day to day development, except for Java which I was using IntelliJ by now. Fast forward now below are the editor/IDE I use for development.  VS Code: JavaScript, TypeScript, EJS, HTML, CSS, Golang, Python, Ruby, Shell, Docker, Kubernetes, Terraform and everything in between including writing this blog post.  IntelliJ Idea: Java, Scala, Kotlin (Though I use VS Code for minor edits and to read the code, etc) VIM: For quick edits from the command line. PluginsOf course VS Code makes all this possible by allowing the use of plugins and there is a lot to choose from. Here are the plugins that I personally use to work on the above-said languages. You can use the code --install-extension command to install them from the terminal. Language support: Based on the Languages you work with you can add syntax, utility and language support plugins for those. I use the below JavaScript/TypeScript/Web:  EJS language support - Adds EJS template support.      code --install-extension DigitalBrainstem. javascript-ejs-support     Close HTML/XML tag - Auto close HTML/XML tags.      code --install-extension Compulim. compulim-vscode-closetag     ESLint - Adds support for ESLint rules.      code --install-extension dbaeumer. vscode-eslint     TSLint - Adds support for TSLint rules.      code --install-extension ms-vscode. vscode-typescript-tslint-plugin     Prettier - Adds support for Prettier formatter.      code --install-extension esbenp. prettier-vscode     es-beautifier - Formats JS according to Eslint rules.      code --install-extension dai-shi. vscode-es-beautifier    Go:  Go - Adds rich language support for Golang.      code --install-extension ms-vscode. Go    JVM:  Language Support for Java - Adds Java language support.      code --install-extension redhat. java     Debugger for Java - Adds lightweight Java debugging support.      code --install-extension vscjava. vscode-java-debug     JHipster JDL - Adds syntax support for JHipster JDL files.      code --install-extension jhipster-ide. jdl    The Java support indeed is getting better and better, so I hope one day I can completely switch to VS Code. Announcing the Visual Studio Code Installer for #Java https://t. co/u6lyKW0xFS &mdash; Markus Eisele (@myfear) June 16, 2019Python:  Language Support for Python - Adds Python language support, linting and debugging support.      code --install-extension ms-python. python    Cloud, Container &amp; others:  Docker - Adds Docker support(view and manage containers) and support for Docker, docker-compose files.      code --install-extension ms-azuretools. vscode-docker     Jenkinsfile Support - Adds syntax highlighting support for Jenkinsfile’s.      code --install-extension secanis. jenkinsfile-support     Terraform - Adds support for Terraform files.      code --install-extension mauve. terraform     Markdown all in one - Full markdown support with live preview, keyboard shortcuts, etc.      code --install-extension yzhang. markdown-all-in-one     PlantUML - Rich PlantUML support with live preview.      code --install-extension jebbs. plantuml     Visual Studio IntelliCode - Adds AI assisted intellisense support for multiple languages.      code --install-extension VisualStudioExptTeam. vscodeintellicode     YAML - Adds YAML support.      code --install-extension redhat. vscode-yaml    Theme: Dark++ Italic: My default theme. Similar to VS Code default dark theme but has support for FiraCode and Operator Mono fonts. I personally use FiraCode.  code --install-extension idbartosz. darkpp-italic Material icon theme: A nice icon theme based on material icons.  code --install-extension PKief. material-icon-theme Peacock: Subtly changes the workspace color of your workspace. Helpful to identify when you have many windows open.  code --install-extension johnpapa. vscode-peacock Tools: Auto rename tag: Automatically rename paired HTML/XML tags  code --install-extension formulahendry. auto-rename-tag Bracket pair colorizer 2: Marks matching bracket pairs with unique colors. This really makes reading code nicer  code --install-extension CoenraadS. bracket-pair-colorizer-2 Change case: Convert between different case. Trust me this is so handy  code --install-extension wmaurer. change-case Code spell checker: Fairly useful for spell checking within code. Takes cameCase etc into account  code --install-extension streetsidesoftware. code-spell-checker Easy snippet maker: Useful to store re usable snippets.  code --install-extension tariky. easy-snippet-maker EditorConfig for VS Code: Add support for EditorConfig.  code --install-extension EditorConfig. EditorConfig Git History: Enable viewing Git history within VS Code.  code --install-extension donjayamanne. githistory Gitignore: Makes it easy to work with . gitignore files.  code --install-extension codezombiech. gitignore Hide gitignored: Hides patterns defined in . gitignore from the editors explorer.  code --install-extension npxms. hide-gitignored Mark as excluded: Exclude stuff right from the explorer tree.  code --install-extension jcmordan. mark-as-excluded Toggle Excluded Files: Easily toggle between showing and hiding excluded files/folders.  code --install-extension eamodio. toggle-excluded-files IntelliJ IDEA Keybindings: I have bad muscle memory so wanted to use the same keyboard shortcuts as IntelliJ. There are mappings available for Sublime, Atom and so on.  code --install-extension k--kato. intellij-idea-keybindings Sort JSON: Sorts JSON object keys.  code --install-extension richie5um2. vscode-sort-json Test Explorer UI: Adds an explorer panel for running tests. Supports multiple languages and testing frameworks.  code --install-extension hbenl. vscode-test-explorer Todo Tree: Aggregate TODO, FIXME, etc in a tree view in explorer.  code --install-extension Gruntfuggly. todo-tree Terminal setupIf you are using Zsh shell with Oh-my-zsh like me as explained here, you might want to do the below to get the same terminal experience in the integrated VSCode terminal as well.  Follow these steps  Download and install a patched font.  On Linux, run fc-cache -f -v to refresh font cache.  On VSCode, open Preferences → Settings and click on the {} icon to open JSON mode and set the below  123456  terminal. integrated. shell. linux :  /usr/bin/zsh ,  terminal. integrated. fontFamily :  'SauceCodePro Nerd Font Mono','Source Code Pro' ,  terminal. integrated. rightClickCopyPaste : true,  terminal. integrated. fontSize : 14,  terminal. integrated. cursorStyle :  underline ,  terminal. integrated. cursorBlinking : true    Replace linux with osx if you are on a Mac.  ConclusionThis might seem like too many plugins but on my configuration VS Code is lightning fast and loads up immediately and is faster then IntelliJ to load and work with. The beauty of VS Code is that you don’t need all the plugin all the time, you can disable the ones not required per workspace to make it even faster. Many people ask me why I use VS Code when I have IntelliJ and my answer have been always the same. IntelliJ is great but its also quite heavy. While all those advanced features are needed for Java, Scala or Kotlin development, VS Code is perfectly capable of giving a nice developer experience for lightweight languages like JS, TS, Go, Python, Rust, Ruby, etc. As a regular user of both IntelliJ and VS Code, I prefer VS Code as much as possible. The user experience is much nicer for my taste. In fact, I like the developer experience in VS Code better for JavaScript, TypeScript, Web, Python, and Golang. Also switching between them for JVM projects and others don’t feel weird for me as I have same keyboard mappings for both. The only time I fire up IntelliJ these days are when I want to do full-fledged Java development. For everything else, I use VS Code. I hope you find this useful. If you have any question or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. "
    }, {
    "id": 17,
    "url": "/reflection-on-golang/",
    "title": "My reflections on Golang",
    "body": "2019/07/12 - Do I like Go? Yes. Would I use it for every use case I have? Definitely not. Having worked on most of these said languages I won&#39;t choose Go for general purpose atleast not current version of Go, may be 2. 0 has more potential. &mdash; Deepu K Sasidharan ( ദീപു, தீபு, दीपू ) (@deepu105) March 7, 2019Don’t get me wrong, I like Go for what it is but like every other programming language, it is always a love-hate relationship. No programming language is perfect and all of them have their own merits and use cases. I hate it when I see people overusing something and I see that pattern with Go these days. To be fair, I have done my fair share of overusing in my career as well (mostly with JavaScript) and I can see why people do it. This is not gonna be a blog bashing Go or praising Go, it is just what I think of it after using it for over 9 months. Before I start a rant on the good and bad of Go, here is some background. After being in the tech industry for over 10 years, I would like to think of myself as a pragmatic programmer or at least as someone getting closer to that - that should be a programmer’s Nirvana. I didn’t even plan to be a programmer, if you ask the 18-year-old self of me, he would say that he wanted to be an astrophysicist or a robotics engineer(Yes building space robots was my dream). Like most teenage dreams, it didn’t happen and I ended up in tech instead. Though landing an IT Job was an accident, programming wasn’t alien to me. I did learn some C/C++ when I was in high school to help my girlfriend with her project and did dabble in some PHP, JavaScript, HTML and Flash(ActionScript) during my early college years for personal projects and blogs. So when I got a real IT job without having an IT background, I did what many in that situation did, I started learning the language that I stumbled upon first based on the task I was given, which happened to be Java. Being a quick learner and having some idea of programming concepts from C/C++ Java wasn’t that hard to learn and I was a pretty decent Java programmer in a few months. Then I was tasked with building some Web UI and I dived deep into the world of HTML, CSS, and JavaScript and honestly fell in love with JavaScript due to its flexibility and ease. I mastered JQuery and soon become the go-to guy for front end stuff in the office. I was anything but pragmatic back then, I was preaching JavaScript to everyone and would vehemently debate anyone who thought JS was a bad language. Fast forward to now and if I look back I have done projects in C/C++, PHP, JavaScript, TypeScript, HTML, CSS, Java, Groovy, Scala, Python and recently Go. I think this exposure probably helped me become more pragmatic as I have started to look at programming languages as tools and each of them has their own strengths and weaknesses. Well, there is more to this story but that’s for another time, the point is to set a baseline for the below reflections so that I don’t sound like someone just trying Go and going on a rant. Go is the latest language I learned and worked with, I have worked on a CLI project built with Go for over 9 months now, building a powerful scaffolding engine with my team(Yes, pretty much like JHipster) that uses Go templates where you could create what we call blueprints at XebiaLabs. So yes I have done much more than a hello world app with Go. Without wasting more time on unrelated things here is what I like about Go and what I don’t like. What I like about Go: Simplicity: I like the fact that Go is a simple language(Going through the entire language features on the tour page literally takes 15 minutes unless you do the exercises) and unlike Scala, Rust or even JavaScript Go doesn’t have many ways of doing the same thing which is extremely valuable for people working in teams and companies wanting to write maintainable code where even a newly joined employee can read and understand the code without needing much help. I think this is one of the biggest reason that is driving Go adoption. If you have worked on large scale projects you know how difficult it is when the code is unreadable and every new team member have to spend so much time trying to understand what a piece of code does. So I was really happy when I saw that Go doesn’t have features that rely heavily on implicit and such. The language features and concepts are easy to grasp and you can start being productive in Go quite soon. The only concepts that might seem bit complex are the concurrency part and even that is simpler compared to other languages. Language provided code style and vetting: This is such a time saver. IMO every language should just do this so that you don’t waste time debating code style and setting up lint rules. Go provides opinionated formatting, linting &amp; vet tool as part of the package and the Go compiler even enforces things like unused variable and stuff. Most of the IDE/Editor plugins also use these tools for formatting and linting and hence helps to keep consistent code style across Go projects which again adds to readability and maintenance. Goroutines &amp; Channels: This is one of the biggest strength of Go. The native support for concurrency and parallelism. This makes Go an ideal candidate for applications that require heavy concurrent and/or parallel processing, networking and so on. Goroutines makes it so easy to start lightweight threads and channels provide a way to communicate between these threads acting like a message bus. 1234567891011func main() {	messages := make(chan string)	collected := make([]string, 2)	go func() { messages &lt;-  ping  }()	go func() { messages &lt;-  pong  }()	collected = append(collected, &lt;-messages)	collected = append(collected, &lt;-messages)	fmt. Println(collected) // [ pong ping ]}Closures &amp; callbacks: If you have used JavaScript you would know how useful closures and callbacks are. Go like JavaScript treats functions as objects and hence can be assigned to variables, stored in maps, passed as function parameters and returned from functions. It also supports creating nested closures and anonymous functions which helps to encapsulate context. The behavior is pretty much similar to JavaScript. So you can apply some functional programming concepts in Go as well. 123456789101112131415161718192021222324func main() {	// an unnecessarily complicated example	type fnType = func(a int, b int) int	fnMap := map[string]fnType{		 ADD : func(a int, b int) int {			return a + b		},		 SUB : func(a int, b int) int {			return a - b		},	}	// this is a closure	localFn := func(method string) fnType {		return fnMap[method] // returns a function	}	printer := func(fn func(method string) fnType, method string) {		fmt. Println(fn(method)(10, 5)) // callback	}	// function passed as parameter	printer(localFn,  ADD )	printer(localFn,  SUB )}Type assertion and switches: Go provides a nice way of asserting types and can be used with a switch statement which makes it easier to do reflection and such. Multiple returns: This is quite a handy feature like in Python, we are used to deconstructing objects/arrays to achieve this in JavaScript and using Tuples and such in some languages. The returns can also be named which is nice for readability. Tooling: The in-code test coverage highlight in VsCode for @golang is slick. This is the best way to ensure you have good coverage@code pic. twitter. com/nk8iMwenCz &mdash; Deepu K Sasidharan ( ദീപു, தீபு, दीपू ) (@deepu105) February 14, 2019As mentioned earlier Go provides standard tooling for formatting, linting and so on and the language design makes it easy to build tooling for Go and hence editors/IDE has nice features like test generation, code coverage and so on. For example, the VSCode integration for Go provides the below options which helps with consistency and less boilerplate to write by hand.  Doesn’t need a runtime: Go doesn’t need a runtime like JVM or NodeJS, Go applications can be compiled into an executable cross-platform binary using the standard Go tooling. This makes Go applications portable and platform-independent. What I don’t like about Go: Simplicity: This is where the love-hate relationship starts, Go is a simple language which is nice but at times it feels too simple &amp; verbose and coming from Java/JavaScript ecosystem you are spoiled with some nice features &amp; syntax sugars which IMO makes the code more expressive and helps to keep it DRY. The things that I miss the most are  Generics: This is currently being considered in the next major iteration of Go, but until then this just makes you repeat code unnecessarily. I have lost count of the number of times I had to repeat the same block of code for different types where Generics would have kept it nice and simple. This is also one reason you don’t see libraries like Lodash for Go.  Standard error handling: This also seems to be coming in the next major iteration of Go but until it lands I can complain. Anyone writing Go will remember doing if err != nil uncountable times in your code. Removing those might cut the codebase in size by at least 20% Default values: Would love to see this in Go, this is quite useful. Maybe I’m just spoiled by JS. Too much boilerplate(not suitable for DRY): Go being too simple means you would have to write a lot of code as the language doesn’t offer constructs like map, reduce, and so on, and add the lack of generic on top means you would end up writing a lot of utility code and a lot of that will be repeated to accommodate different types. Imagine writing a map function in Go, you would have to write one for every combination of Map that can be used. These factors don’t make it easy to do DRY programming in Go. Dependency management: The dependency management in the Go ecosystem feels immature and too basic compared to other mainstream languages. Importing packages from Git is nice but it also makes it more fragile. What can go wrong when you are depending on a Git branch on your production application right! There is no way to use relative dependencies(Can’t beat NPM link!). These problems are similar to the issues with dependency range in Node package managers. Glide seems to be a popular choice but still is not as mature as solutions in other languages. In the project, I work on we used Gradle along with Gogradle and though it works fine the developer experience is not as good as using Gradle/Maven for Java project or using NPM on a NodeJS project. Source code in GOPATH: Go recommends you to create your Go projects under the GOPATH. Maybe it is just me, but I hate this as I would normally like to organize my code. For example, I have a ~/workspace/ folder where I organize my projects by the organization. If I follow the Go recommendation I have to put the project under /home/deepu/go/src along with all the library source code that is downloaded. If you don’t follow this then most of the Go tooling just doesn’t work. Currently, I have a specific Gradle task that copies over all the vendor libs to my local Gopath inside ~/workspace/XL/&lt;project&gt; to workaround this. Confusing pointer behaviors: Go has pretty good pointer support and the default behavior is to pass an object by value. If you want to pass something by reference you have to mark it specifically. But this behavior is not very consistent as Maps and Slices by default are passed by reference and hence this could be a bit surprising to beginners. Struct hell: This is more of a nitpick. Structs are what you would use to create data structures in Go. It might look like an object but they are not exactly objects. While structs are fine functionally, in many cases you will end up with structs that look like the ugly brother of JSON. In real-world projects, you always will end up creating complex structs, especially if the application is doing some generic json or yaml parsing and soon your code will start to look like this. This is not that big of a concern but it just hurts my eyes every time I debug something or write tests. 123456789101112131415161718192021222324252627282930313233343536373839	func main() {	type MyYamlDoc struct {		foo []map[interface{}][]map[interface{}]interface{}		bar interface{}	}	ohno := MyYamlDoc{		[]map[interface{}][]map[interface{}]interface{}{			{				 Foo : {					{ Bar : map[interface{}][]map[interface{}]interface{}{						 Foo : {							{ Bar : map[interface{}][]map[interface{}]interface{}{								 Foo : {									{ Bar : map[interface{}][]map[interface{}]interface{}{										 Foo : {											{ Bar : map[interface{}][]map[interface{}]interface{}{}},										},									}},								},							}},						},					}},				},			},			map[interface{}][]map[interface{}]interface{}{				 Foo : {					{ Bar : map[interface{}][]map[interface{}]interface{}{}},				},			},		},		map[interface{}][]map[interface{}]interface{}{			 Foo : {				{ Bar : map[interface{}][]map[interface{}]interface{}{}},			},		},	}	fmt. Println(ohno)}Weird interface construct: The interface concept in Go is weird. These are the only implicit construct in Go. If you come from other languages that have interfaces then this will feel weird. The fact that they are implicit means its really easy to mess things up. Refactoring is messy unless you have a smart IDE, and you can accidentally implement someone’s interface by just naming your method a certain way. While implicit interfaces certainly help with polymorphism and decoupling code I personally would still prefer interfaces that are explicit. Another interface Gotcha is nil value checks, in Go, an interface is made up of two parts a type and a value, so an interface is nil only when both type and value are nil, this means you can’t just simply do nil checks on interfaces. This is so confusing the Go has a specific FAQ for this. Below article explains this in more detail https://dev. to/pauljlucas/go-tcha-when-nil–nil-hic Single GC algorithm: Go implements a concurrent tri-color mark-sweep collector as its garbage collector. This specific GC implementation is optimized for better pause times while ignoring program throughput, pause frequency and many other parameters that are considered during GC. Some people in the Go community claims this as the best ever GC. Having some Java background I would have to disagree as most JVM implementations provide multiple GC algorithms you can choose from which includes a concurrent mark-sweep collector as well and most of these are balanced to take care of many more parameters than just pause times. This articles analyses this in detail. So some use cases that produce a high amount of garbage might actually be slower in Go compared to another language due to frequent GC. Developer experience: This is purely based on personal experience and hence will vary from others. Being a polyglot developer who has worked with many languages, the developer experience from Go is not the best I have experienced. The DX of the JavaScript ecosystem is the best I have experienced so far. It feels like there are things missing in the Go ecosystem. Dependency management and toolchains need improvement. A bit more sensible language features and some syntax sugar wouldn’t hurt as well. Conclusion: Having worked with many major languages I can’t just use Go for every use case but I can see why people would use Go for every use-case out there if they haven’t worked with other languages. So where would I use Go?:  I would definitely use Go when the use case requires a lot of parallel processing and/or concurrency(both are not the same thing but are closer to each other) as you can make use of Goroutines for this and is much simpler and efficient than managing threads like in a Java application or working around it in JavaScript using callback hell since JS is actually single-threaded. Here is a nice article explaining the advantage of Goroutines.  Simple microservices where boilerplate is not a concern Networking applications or web servers, especially with async workloads, can greatly benefit from Go. But to be fair you can do these in Java, Python, JS, etc as well but Go in the end will provide better efficiency and would be easier to implement.  System programming. While Rust or C is a much better choice for this but if those are not in your arsenal then Go is the next best thing. With decent support for pointers and its standard library its easier for system programs than other mainstream languages. Many popular system tools like Docker, Kubernetes, etc are indeed written in Go. Where I wouldn’t use Go?:  Complex web application: I would choose Java with a framework like Spring or Micronaut as its much more maintainable and battle-tested and you would focus more on business logic than writing boilerplate infrastructure code. One common argument against this stack is its memory footprint but it is possible to get lower memory footprint with Spring and frameworks like Micronaut and Quarkus actually promises that OOB.  After writing a high-level CLI tool in Go, I hate the experience, I kept thinking that doing it in JavaScript would have been 10 times more productive and a nicer experience. SO I would choose JavaScript or TypeScript running on NodeJS for CLI tool any day. Mainly due to the ecosystem and the sheer joy and speed of getting things done without spending all your time writing boilerplate code. But this wouldn’t be applicable if the CLI in question a system tool or a networking tool, in those cases Go could be a good option. I do hope Go evolves into a general-purpose language over time and many of these concerns are solved. In the meantime, I’ll try to follow this mantra. Remember this manthra &quot;right tools for the right job, right pattern for the use-case&quot; #engineering #development #architecture #microservices https://t. co/SA42jQ5TLH &mdash; Deepu K Sasidharan ( ദീപു, தீபு, दीपू ) (@deepu105) July 2, 2019But then you can always choose to fasten a screw using a hammer. Using the wrong tool for the job. #programming pic. twitter. com/5RdVqGuZoj &mdash; Rory Preddy🥑 (@rorypreddy) June 24, 2019If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Cover image credit: Image from Gophercises created by @joncalhoun, Marcus Olsson (@marcusolsson), and Jon Calhoun. "
    }, {
    "id": 18,
    "url": "/configure-a-beautiful-terminal-on-unix/",
    "title": "Configure a beautiful terminal on Unix with Zsh",
    "body": "2019/07/01 - I was a long-time Windows user, a fairly happy one, but as a developer, there were a lot of things that were missing for me and one of the main was the terminal experience. I’m not a fan of the closed ecosystem of Apple so Linux was an easy choice for me and I switched to Linux almost 3 years ago. I did start out with Ubuntu and later switched to Fedora which is my primary OS now. You can read about my setup here As a senior developer and open source community lead, I spent a lot of time on the terminal and a terminal with a nice developer experience instantly makes you happier and more productive. The default bash terminal is good for beginners but if you really want a powerful terminal you need something more than bash. Let’s see how to configure a powerful and productive terminal experience. The setup is based on what I have configured on my Fedora machine. The same setup can be recreated on any other Linux distribution, BSD or Mac as well. You just need to use the installation instruction from the tools for the given platform.  Below are the tools we would need for this. Zsh: Zsh is one of the most feature-rich shells for Unix. It works on Linux, Mac, WSL, and BSD. There are alternatives like Fish which also offers similar features but I personally like Zsh.  Check if Zsh is already installed by running zsh --version on your terminal. If not found, install it using your package manager.      Fedora: sudo dnf install zsh   Mac: brew install zsh zsh-completions   RHEL/CentOS: sudo yum update &amp;&amp; sudo yum -y install zsh   Ubuntu/Debian: sudo apt install zsh   For other platform refer this    Now make Zsh your default shell by running chsh -s $(which zsh).  Log out and log in back again to use your new default shell.  Test that it worked with echo $SHELL. Expected result: /bin/zsh or similar.  Test with $SHELL --version. Expected result: zsh 5. 6. 2 or similarNote: If you have installed Zsh for the first time and launch the shell it would prompt you to configure some settings. You can choose to ignore that by hitting q as we will configure it later on. Oh-My-Zsh: Oh-My-Zsh gives the Zsh shell superpowers. Its a framework to manage Zsh configuration. It has plugins and themes for Zsh(A lot of them). From their Github page:  Once installed, your terminal shell will become the talk of the town or your money back! With each keystroke in your command prompt, you’ll take advantage of the hundreds of powerful plugins and beautiful themes. Strangers will come up to you in cafés and ask you, “that is amazing! are you some sort of genius?” Just install it. You need it :) 1sh -c  $(curl -fsSL https://raw. githubusercontent. com/robbyrussell/oh-my-zsh/master/tools/install. sh) Terminal emulator/multiplexer: Optionally you can use a Terminal emulator that can manage windows and panes for you. For Linux I would recommend using Tilix, I have been using it for 3 years and its just amazing. For Mac, you can use iTerm2 which is very popular. Alternatively, you can also use tmux if you want something lighter on your existing Terminal app on Linux, BSD or Mac. Configuring Zsh: This is the fun part. Let us make the terminal awesome. Install plugins: First, let us install some additional plugins that are not bundled with Oh-My-Zsh. zsh-autosuggestions: Provides auto completion for shell commands. Run git clone https://github. com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/plugins/zsh-autosuggestions to install zsh-syntax-highlighting: Provides syntax highlighting on the shell. Run git clone https://github. com/zsh-users/zsh-syntax-highlighting. git ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/plugins/zsh-syntax-highlighting to install autojump: Provides a smarter directory navigation system. Install autojump for your OS following instructions here. Now let us configure the ~/. zshrc file with some settings. Here is my full . zshrc file. Your mileage may vary. Add exports: We will start with some exports. 1234567891011121314export TERM= xterm-256color  # This sets up colors properly# set shellexport SHELL=/usr/bin/zsh# If you come from bash you might have to change your $PATH. export NODE_PATH=$NODE_PATH:$HOME/. npm-global/lib/node_modulesexport JAVA_HOME=/usr/java/latestexport PATH=$JAVA_HOME/bin:~/. npm-global/bin:$HOME/bin:/usr/local/bin:$PATH# Add exports from your profilesource ~/. profile# Path to your oh-my-zsh installation. export ZSH=$HOME/. oh-my-zshZsh settings: Now we can configure some Zsh specific settings 1234DISABLE_MAGIC_FUNCTIONS=trueZSH_AUTOSUGGEST_MANUAL_REBIND=1COMPLETION_WAITING_DOTS=trueDISABLE_UNTRACKED_FILES_DIRTY=trueZsh theme: Now, Let’s set up a nice theme. I’m using powerlevel10k as my current theme and it’s fast and looks great. You can use the default or you can choose any theme you like from the list here. If you like my theme then follow these instructions. Thanks to Roman Perepelitsa for some cool tips Run git clone https://github. com/romkatv/powerlevel10k. git ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/themes/powerlevel10k to install the theme. Install a Powerline font. I use Adobe Source Code Pro Add the below configuration to the ~/. zshrc file. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182# Set name of the theme to load. Optionally, if you set this to  random # it'll load a random theme each time that oh-my-zsh is loaded. # See https://github. com/robbyrussell/oh-my-zsh/wiki/ThemesZSH_THEME= powerlevel10k/powerlevel10k ############ POWERLEVEL THEME SETTINGS ##############POWERLEVEL9K_MODE='awesome-fontconfig'POWERLEVEL9K_LEFT_PROMPT_ELEMENTS=(dir vcs nvm)POWERLEVEL9K_RIGHT_PROMPT_ELEMENTS=(disk_usage time)POWERLEVEL9K_PROMPT_ADD_NEWLINE=truePOWERLEVEL9K_PROMPT_ON_NEWLINE=truePOWERLEVEL9K_SHOW_RULER=truePOWERLEVEL9K_RULER_CHAR='─'POWERLEVEL9K_RULER_BACKGROUND=nonePOWERLEVEL9K_RULER_FOREGROUND=237POWERLEVEL9K_LEFT_SEGMENT_END_SEPARATOR=POWERLEVEL9K_LEFT_SEGMENT_SEPARATOR=POWERLEVEL9K_LEFT_SUBSEGMENT_SEPARATOR=' 'POWERLEVEL9K_RIGHT_SEGMENT_END_SEPARATOR=POWERLEVEL9K_RIGHT_SEGMENT_SEPARATOR=POWERLEVEL9K_RIGHT_SUBSEGMENT_SEPARATOR=POWERLEVEL9K_WHITESPACE_BETWEEN_LEFT_SEGMENTS=POWERLEVEL9K_SHORTEN_DIR_LENGTH=2POWERLEVEL9K_SHORTEN_STRATEGY= truncate_middle POWERLEVEL9K_DIR_SHOW_WRITABLE=truePOWERLEVEL9K_DISK_USAGE_NORMAL_BACKGROUND=nonePOWERLEVEL9K_DISK_USAGE_WARNING_BACKGROUND=magentaPOWERLEVEL9K_DISK_USAGE_CRITICAL_BACKGROUND=redPOWERLEVEL9K_TIME_BACKGROUND=nonePOWERLEVEL9K_TIME_FOREGROUND=whitePOWERLEVEL9K_DIR_HOME_BACKGROUND=nonePOWERLEVEL9K_DIR_HOME_SUBFOLDER_BACKGROUND=nonePOWERLEVEL9K_DIR_ETC_BACKGROUND=nonePOWERLEVEL9K_DIR_DEFAULT_BACKGROUND=nonePOWERLEVEL9K_DIR_NOT_WRITABLE_BACKGROUND=nonePOWERLEVEL9K_DIR_HOME_FOREGROUND=bluePOWERLEVEL9K_DIR_HOME_SUBFOLDER_FOREGROUND=bluePOWERLEVEL9K_DIR_ETC_FOREGROUND=bluePOWERLEVEL9K_DIR_DEFAULT_FOREGROUND=bluePOWERLEVEL9K_DIR_NOT_WRITABLE_FOREGROUND=redPOWERLEVEL9K_OS_ICON_BACKGROUND= white POWERLEVEL9K_OS_ICON_FOREGROUND= blue POWERLEVEL9K_VCS_GIT_ICON='%fon %F{040}\uf1d3 'POWERLEVEL9K_VCS_GIT_GITHUB_ICON='%fon %F{040}\uf09b 'POWERLEVEL9K_VCS_GIT_BITBUCKET_ICON='%fon %F{040}\uf171 'POWERLEVEL9K_VCS_GIT_GIT_GITLAB_ICON='%fon %F{040}\uf296 'POWERLEVEL9K_VCS_CLEAN_BACKGROUND=nonePOWERLEVEL9K_VCS_UNTRACKED_BACKGROUND=nonePOWERLEVEL9K_VCS_MODIFIED_BACKGROUND=nonePOWERLEVEL9K_VCS_LOADING_BACKGROUND=nonePOWERLEVEL9K_VCS_CLEAN_FOREGROUND= 040 POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND= red POWERLEVEL9K_VCS_MODIFIED_FOREGROUND= yellow POWERLEVEL9K_VCS_LOADING_FOREGROUND= grey POWERLEVEL9K_VCS_UNTRACKED_ICON=$'%{\b?%}'POWERLEVEL9K_VCS_UNSTAGED_ICON=$'%{\b!%}'POWERLEVEL9K_VCS_STAGED_ICON=$'%{\b+%}'POWERLEVEL9K_DIR_NOT_WRITABLE_VISUAL_IDENTIFIER_COLOR=redPOWERLEVEL9K_LOCK_ICON=$'\uf023'POWERLEVEL9K_MULTILINE_FIRST_PROMPT_PREFIX=''local p='%F{%(?. green. red)}${${${KEYMAP:-0}:#vicmd}:+❯}${${$((!${#${KEYMAP:-0}:#vicmd})):#0}:+❮}%f 'POWERLEVEL9K_MULTILINE_LAST_PROMPT_PREFIX= $p POWERLEVEL9K_NVM_BACKGROUND=nonePOWERLEVEL9K_NVM_FOREGROUND=greenPOWERLEVEL9K_NODE_ICON='%fvia %F{green}⬢'############ END- POWERLEVEL THEME SETTINGS ##############Enable plugins: We can finish off by enabling the plugins and some tweaks 1234plugins=(zsh-autosuggestions git docker docker-compose autojump zsh-syntax-highlighting dnf npm)source $ZSH/oh-my-zsh. shAnd that’s it we are ready. Start a new terminal session and enjoy. Issues &amp; workarounds: If you use Tilix as your terminal emulator, then this might be required for proper pane splitting. Add this to your ~/. zshrc 123if [[ $TILIX_ID ]]; then    source /etc/profile. d/vte. shfiIf you are getting errors from the zsh-completion plugin, you might want to add this to the beginning of your ~/. zshrc 1234# workaround as per https://superuser. com/questions/1222867/zsh-completion-functions-brokenFPATH=$HOME/. oh-my-zsh/plugins/git:$HOME/. oh-my-zsh/functions:$HOME/. oh-my-zsh/completions:/usr/share/zsh/site-functions:/usr/share/zsh/$ZSH_VERSION/functionsexport FPATHIf you encounter an error from Oh-My-Zsh saying [oh-my-zsh] Insecure completion-dependent directories detected, set ZSH_DISABLE_COMPFIX=true right before the line source $ZSH/oh-my-zsh. sh in your ~/. zshrc file and restart your session or run exec zsh Dockerized playground. : If you have Docker installed then you can use the below snippet to try this setup in a sandbox without installing anything or affecting your existing setup. 123456789docker run -e LANG=C. UTF-8 -e LC_ALL=C. UTF-8 -e TERM=$TERM -it --rm ubuntu bash -uexc ' apt update &amp;&amp; apt install -y git curl zsh autojump &amp;&amp; cd /root sh -c  $(curl -fsSL https://raw. githubusercontent. com/robbyrussell/oh-my-zsh/master/tools/install. sh)  --skip-chsh --unattended git clone https://github. com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/plugins/zsh-autosuggestions git clone https://github. com/zsh-users/zsh-syntax-highlighting. git ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/plugins/zsh-syntax-highlighting git clone https://github. com/romkatv/powerlevel10k. git ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/themes/powerlevel10k curl -fsSLO http://bit. ly/Spaceship10kTheme echo  source ~/Spaceship10kTheme  &gt;~/. zshrc exec zsh'VSCode Tip: If you are using VSCode like me, you might want to do the below to get the same terminal experience in the integrated VSCode terminal as well.  Follow these steps  Download and install a patched font.  On Linux, run fc-cache -f -v to refresh font cache.  On VSCode, open Preferences → Settings and click on the {} icon to open JSON mode and set the below  123456  terminal. integrated. shell. linux :  /usr/bin/zsh ,  terminal. integrated. fontFamily :  'SauceCodePro Nerd Font Mono','Source Code Pro' ,  terminal. integrated. rightClickCopyPaste : true,  terminal. integrated. fontSize : 14,  terminal. integrated. cursorStyle :  underline ,  terminal. integrated. cursorBlinking : true    Replace linux with osx if you are on a Mac.  I hope you like it. If you have any question or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. "
    }, {
    "id": 19,
    "url": "/must-have-gnome-plugins/",
    "title": "Must have GNOME extensions",
    "body": "2019/06/24 - I’m a sucker for nice polished UI and great UX. While there are a lot of Linux Desktop environments out there providing great UX and UI, I found GNOME to be the perfect one for my liking. Yes, I have seen/tried a few others. I also found some which are more polished and providing a better default UX out of the box than GNOME like Deepin and Elementary. But below plugins bridge that gap and hence I choose to stick with GNOME which is the default in Fedora, hence quite stable, unless I had a compelling reason to switch. So if you like me are a GNOME fan then below are some of the GNOME plugins you must try if you haven’t already. I have listed the plugins I use in my earlier post in the series. here I detail the ones that are a must-have. GNOME Tweaks: This nifty tool lets you tweak/configure a lot of GNOME configuration and should have been included by default in every distro shipping with GNOME. You can customize the appearance, install extensions, configure mouse &amp; keyboard and so on. It can be found in the software center of your distro. Search for “Tweaks”.  Gnome extensions: You can install below extensions by visiting the link in the title of the extension below and by clicking on the on switch on the top right corner. On Chrome, you would need the GNOME Shell integration plugin to enable the switch. On Firefox, it will prompt you to install the plugin if it doesn’t exist. Dash to Dock: GNOME without this plugin almost feels annoying. IMO this plugin also should be the default GNOME setting. This one moves your GNOME dash into a highly configurable dock which can be placed on the sides or top/bottom of the screen. I find it perfect on the left side of the screen in GNOME. It can be a floating dock or fixed to look like those on Mint or KDE.  Always Zoom Workspaces: By default, the GNOME launcher does not show the workspaces, you have to hover over the right edge to see it. I find it unnecessary given you have enough real estate on the full-screen launcher and the workspace view takes only a little bit. This plugin keeps it zoomed by default.  Steal My Focus/NoAnnoyance: This is another default in GNOME that is annoying. When something needs focus these plugins brings the window up instead of the default notification. You can use any one of the plugins as both do the same thing. AlternateTab: This replaces the default Alt+Tab with a more classical window-based switcher which IMO is more user-friendly as the default requires more keyboard navigation using the arrow keys.  Window List: This is a classic plugin that adds the window list to the bottom of the screen and is a must if you use multiple monitors as the windows are grouped and placed in the right monitor screen. Caffeine: This one adds the ability to temporarily disable screensaver/auto-suspend and automatically activates when you go full-screen. A must-have if you are using your computer for watching videos, presentations, screencast and so on. Clipboard Indicator: This is one my favorite. It adds a nifty clipboard manager to the top bar and provides shortcuts to cycle through clipboard entries. A real time saver.  Gistnotes: As a developer using GitHub gist a lot, this one is a very useful plugin. It lets you manage your Gists right from the desktop and you can use it like a notes app.  System-monitor: A nice system monitor plugin that sits on the top bar with a detailed view as a popup.  TopIcons Plus: This moves legacy icons form applications to the top bar for consistent UX. I hope you find this useful. If you have any question or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Cover image photo by Brigitta Schneiter on Unsplash "
    }, {
    "id": 20,
    "url": "/my-beautiful-linux-development-environment/",
    "title": "My beautiful Linux development environment",
    "body": "2019/06/16 - One of the questions that I get quite often after a conference talk is weirdly not about what I presented but about my Linux desktop environment. People are more curious about that beautiful distro rather than the awesome presentation I just did 😂 Not that I’m complaining, I love my desktop setup. I love it so much that I was afraid of getting a new PC when I was due for one. I was afraid that I would mess things up(I have done that many times in the past, I think Linux users can relate to me) So I decided to capture the most important aspects of my distro for anyone interested in using Linux as their primary OS for development.  This is not just my work laptop, it’s my primary machine which I use for all of the below  Java, JS, TS, Go, Python &amp; web development JHipster development Running multiple web applications locally Running Docker containers VirtualBox for Windows testing &amp; other VM stuff Kubernetes, Terraform, CloudFormation development and deployments Azure, AWS &amp; GCP deployments using required CLI tools Heavy browser usage Email, chat &amp; video conferencing Plex media server Blogging Youtube &amp; Social mediaMachine configuration: The configuration of the machine is also quite important for any development setup. So my laptop is a Dell Precision 5530 Mobile Workstation. I had the exact same setup with my old Dell 5510 as well, which is quite a similar configuration to 5530. I still have it as a backup Laptop, its 2 years old now but can still give most of the top end laptops today a run for its money. I used the custom configuration option from Dell to get the best possible setup at that time. it’s not cheap but my company, XebiaLabs, provided a handsome budget and I think it is worth every penny. This, in my opinion, is one of the best Laptop for developers. So here is what I have. Processor: Intel® Core™ i9-8950HK CPU @ 2. 90GHz × 12 Memory: 32GB, DDR4-2666MHz SDRAM, 2 DIMMS, Non-ECC HDD: M. 2 1TB NVMe PCIe SED class 40 SSD Graphics: NVIDIA Quadro P2000 with 4 GB GDDR5 memory &amp; Intel® UHD Graphics 630 (Coffeelake 3x8 GT2) Wireless: Intel Wifi Link 9260 2x2 802. 11AC + BT 4. 2 vPro wireless card Keyboard: English QWERTY US, backlit Display: 15. 6” FHD 1920x1080 Anti-Glare LED-backlit Non-touch IPS UltraSharp™ Battery: 6-cell (97Wh) Lithium Ion battery with ExpressCharge™ Operating system and desktop environment: The most important of course is the operating system, I’m running Fedora 30 at the moment with GNOME 3. 32. 2 as the Desktop and I’m very happy with it. I find Fedora more suitable for development machines than other distros as it has a short release cycle and is fairly stable so you get latest &amp; stable software all the time.  What good is a desktop without a nice theme right? GNOME is great when it comes to themes and I went with Arc-Flatabulous theme and never looked back. For icons, I use Paper as I like the material icon theme.  Of course, it won’t be complete without some nice GNOME plugins. Below are the plugins that I use.  Dash to Dock Always Zoom Workspaces Auto Move Windows Native Window Placement Launch new instance Steal My Focus AlternateTab Window List Applications Menu Caffeine Clipboard Indicator Gistnotes OpenWeather Places Status Indicator System-monitor Todo. txt TopIcons Plus User ThemesDevelopment tools: Now, these are mostly objective choices and really doesn’t matter as long as you are comfortable with the tools you choose. Below are my choices for some of the important categories for development. I’m not including obvious things like Vim, Git, NodeJS, Docker, Kubernetes, etc. Shell: This is one of the most important for a developer. I use ZSH along with the awesome Oh My ZSH as my shell. Now, this won’t be complete without some nice plugins and theme. I use powerlevel9k theme with some customizations. I also use zsh-autosuggestions, git, docker, docker-compose, autojump, zsh-syntax-highlighting, dnf, and npm plugins for Oh My ZSH. Here is my . zshrc with all the customizations. Update: A comment on this post suggested powerlevel10k as an alternative theme and I tried it and turns out it is really way faster than powerlevel9k. So I think I’m gonna use powerlevel10k as my shell theme. Terminal: What good is a nice shell without a good terminal. Fortunately, we have Tilix one of the best terminal application out there. It has workspaces, tabs, split windows, Quake mode and so on.  Integrated development environment(IDE): IntelliJ IDEA ultimate - I use this only for Java &amp; other JVM language Development Code Editors: Visual Studio Code - My go-to editor. I love it. I use VSCode for web development, Go, Python, JS development, DevOps and everything other than JVM languages. A VSCode setup is never complete without some good plugins. Here are the plugins that I’m using. You can run the script to install those. Other notable development tools I use are GitKraken for Git repo management, Beyond Compare for code comparisons, VirtualBox, NVM for NodeJS version management and SDKMan for JDK version management. Productivity tools: Productivity tools are also quite important and below are my choices. Browser: Google Chrome is my primary browser. I also use Firefox &amp; Opera sometimes. I do love Opera in terms of its UX, I would love to use it as my primary browser but I miss everything I have synchronized with my Google account in Chrome. Email: I use Mailspring as my e-mail client. Its a fairly decent mail client with nice themes and a simple UI. Office suite: I mostly use Google Docs &amp; Microsoft office online but when I have to work on something on my Desktop I use LibreOffice which is a good office suite and even handles Microsoft Office &amp; Keynote formats. Communication: Of course I use Slack and for video conference I use BlueJeans. Screen capture: I use this nifty tool called Peek for screen recording and Shutter for screenshots. Conclusion: There are many other small and nifty utilities that I use, most are command line utilities. There are some notable mentions like Timeshift which is nice for backing up your machine. Of course, not everything is perfect in the Linux world, but it is the same with every OS. I was a long time Windows user before switching to Linux. So like every Linux users I have from time to time messed things up(With great power comes great responsibility, Peter). There are many quirks in the Linux world but there is nothing that bothers me much. Some of the most annoying issues I had in the past are below and for now, I don’t have any noticeable issues.  Scroll position jumping when switching apps - Fixed after upgrading to Fedora 30 Hibernation was broken - Fixed after upgrading to Fedora 30 Audio output selection was broken when plugging in headphones- Fixed after Fedora 28 for meThis has been a good day, upgraded to #Fedora 30 and hibernate started to work again. Sweet. I was putting off tinkering that for a long time. #Linux &mdash; Deepu K Sasidharan ( ദീപു, தீபு, दीपू ) (@deepu105) June 14, 2019I hope you find this useful. If you have any question or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. "
    }, {
    "id": 21,
    "url": "/why-im-moving-away-from-medium/",
    "title": "Why I’m moving away from Medium",
    "body": "2019/06/13 - After much deliberation, I have decided to move my blogs away from Medium. I was considering setting up my own blog with Hugo but then decided to go with Dev. to. Below are the reasons why I decided to leave Medium and why I chose Dev. to. All considerations were purely from a technical writing perspective as I was using Medium for publishing technical content. The love-hate relationship with Medium: I loved Medium when I started writing here, reasons being;    A simple minimal &amp; clean UI — It still is one of the best     Ease of authoring and publishing     Community and visibility     Publications     Ease of customization  But there were also things I didn’t like much which slowly become quite annoying  The weird commenting mechanism(Every comment is a post, and they literally mess up your stories listing page)    Medium had a weird WYSIWYG editor interface which is great for normal content creation but not so great for technical content creation. It had some markdown like shortcuts, but it could never match the ease of using proper markdown editors.     Export only in HTML (Duh!!)  But these annoyances were not the main reason I decided to switch platforms. Below are the main reasons why I decided Medium isn’t a good fit for me. Medium has been aggressively pushing for content to be put behind a paywall and they have made it clear that content not opting in will not get any push inside the platform. This means the community and visibility part is applicable only if you opt-in for the paywall. I understand why Medium does and I think its a great monetary source for established authors but it doesn’t work for mere mortals like me.  As a result of the above, the traffic you get from Medium itself is very low compared to external sources. See one of my stories below for an example. For newer stories, it is even lower.  So writing in Medium seems to have no benefit over other platforms as I could get similar views from external sources and might get better writing experience elsewhere. UpdateSo after a week of moving to the Dev community below are my stats and its incredible, I have ~50k views, ~1k reactions and ~300 followers and one of my post was featured in top 7 of the week and all this in just 1 week. I didn’t get anything remotely close to this from Medium in a year.  Enter Dev. to: When I was trying to find a different platform, some of the most important aspects I considered were below    Community: A community without paywall and a community were your blogs get visibility and get traffic.     Ease of authoring: Authoring experience was important, hence at minimum Markdown support was a must. This way I can author posts in my favorite IDE(VsCode in this case) and doesn’t have to be restricted with the platform’s capability. Also, this ensures that I can easily move my posts to another platform in the future if needed.  Dev. to satisfied these needs and provided a nice and clean UI and descent publishing experience on top. Conclusion: I think Medium is still perfect for normal blogging and for content creators who have subscribers willing to pay even if they put articles behind a paywall. But for technical content creators who do not want their content behind a paywall, there are better platforms. I might still crosspost between Dev. to and Medium from time to time but Dev. to will be my primary blogging platform. Originally published in Medium on June 13, 2019 Cover image credit: Photo by MILKOVÍ on Unsplash "
    }, {
    "id": 22,
    "url": "/deploy-a-web-app-to-azure-app-service-using-terraform/",
    "title": "Deploy a web app to Azure App Service using Terraform",
    "body": "2019/06/12 - Deploying Java web applications to Azure is easy and has been tried, tested and explained many times by many people. My friend Julien Dubois has a nice series on it here. Azure makes it really easy to use its App Service as it provides many different ways of deploying a web app. If you are a modern full-stack Java developer there is a high chance that you are deploying your application as a Docker image. Hence today let’s see how we can deploy a Java web application to Azure App Service using Docker and Terraform in the true spirit of infrastructure as code. The approach is pretty much the same for any web application that is built as a docker image and not necessarily tied down to just Java. To try this out you would need to have Java, NodeJS, Terraform, Docker and Azure CLI installed. Follow the links to install them if needed. As one of the lead developer of JHipster (A handy development platform to generate, develop and deploy Spring Boot + Angular/React/Vue Web applications and Spring microservices), I would use a JHipster web application as the example here. So let’s get started. Let’s build a very simple web application using JHipster. We will use the JDL feature to scaffold our application. We will use the below JDL for our application. Save it to a file named app. jdl in a directory where you want to create the application. application {  config {    baseName helloJHipster,    applicationType monolith,    packageName tech. jhipster. demo,    authenticationType jwt,    buildTool gradle,    clientFramework react,    databaseType sql,    prodDatabaseType mysql,    languages [en, nl]  }}Now let us scaffold this using JHipster. Open your favorite console/terminal and run the below command in the directory where you saved the above JDL file, make sure it’s an empty directory. 1$ npx generator-jhipster import-jdl app. jdlIf you already have JHipster installed you can just run 1$ jhipster import-jdl app. jdlThis will scaffold the application and install the required client-side dependencies. It might take a few minutes(NPM!) so maybe its time for that coffee. You can see the application in action by running . /gradlew on the same terminal once the scaffolding is done. You can refer to the generated Readme. md for more instructions regarding the application. Now let’s move on to the focus of this post, deploying this to Azure App Service with Terraform. Let us first build and publish the docker image for our application. JHipster conveniently provides everything that is required to build docker images. Let us use the provided docker integration using JIB to build the images. Run the below Gradle command. 1$ . /gradlew bootJar -Pprod jibDockerBuildNow let us tag and push this to our docker registry, make sure you have logged into docker and run these commands. Use your own docker hub account name. 123$ docker tag hellojhipster:latest deepu105/hellojhipster:latest$ docker push deepu105/hellojhipster:latestYou can also push to Azure Container registry instead of Docker Hub if you like. Now that our application and Docker images are ready, let’s prepare the Terraform infrastructure for App Service and MySQL database. For other ways of deploying a JHipster web app to Azure check this out. First, create a folder for our terraform files. Let’s name the folder terraform. Now create three files called main. tf, outputs. tf, and variables. tf in this folder. Let us define the variables we will use. Save the below in variables. tf. 12345678910111213141516171819202122232425variable  prefix  { description =  The prefix used for all resources in this example  default   =  xl }variable  location  { description =  The Azure location where all resources in this example should be created }variable  subscription_id  { description =  Azure Subscription ID to be used for billing }variable  my_sql_master_password  { description =  MySql master password }variable  docker_image  { description =  Docker image name }variable  docker_image_tag  { description =  Docker image tag }Now let us define our main. tf First, let us add a configuration for Azure resource manager and create an Azure resource group to hold our resources. 123456789provider  azurerm  { version     =  =1. 24. 0  subscription_id =  ${var. subscription_id} }resource  azurerm_resource_group   main  { name   =  ${var. prefix}-resources  location =  ${var. location} }Now let us add the configuration to create a MySQL database server along with the required firewall rules to let App Service access the DB. If you want to add local access from your machine add a firewall rule block for your IP as well. 12345678910111213141516171819202122232425262728293031323334353637383940414243# This creates a MySQL serverresource  azurerm_mysql_server   main  { name        =  ${var. prefix}-mysql-server  location      =  ${azurerm_resource_group. main. location}  resource_group_name =  ${azurerm_resource_group. main. name}  sku {  name   =  B_Gen5_2   capacity = 2  tier   =  Basic   family  =  Gen5  } storage_profile {  storage_mb      = 5120  backup_retention_days = 7  geo_redundant_backup =  Disabled  } administrator_login     =  mysqladminun  administrator_login_password =  ${var. my_sql_master_password}  version           =  5. 7  ssl_enforcement       =  Disabled }# This is the database that our application will useresource  azurerm_mysql_database   main  { name        =  ${var. prefix}_mysql_db  resource_group_name =  ${azurerm_resource_group. main. name}  server_name     =  ${azurerm_mysql_server. main. name}  charset       =  utf8  collation      =  utf8_unicode_ci }# This rule is to enable the 'Allow access to Azure services' checkboxresource  azurerm_mysql_firewall_rule   main  { name        =  ${var. prefix}-mysql-firewall  resource_group_name =  ${azurerm_resource_group. main. name}  server_name     =  ${azurerm_mysql_server. main. name}  start_ip_address  =  0. 0. 0. 0  end_ip_address   =  0. 0. 0. 0 }This will create a MySQL server, a database for our app on the server and enable access from App Service. Now let us configure the App Service itself along with a service plan. 123456789101112131415161718192021222324252627282930313233343536373839# This creates the plan that the service useresource  azurerm_app_service_plan   main  { name        =  ${var. prefix}-asp  location      =  ${azurerm_resource_group. main. location}  resource_group_name =  ${azurerm_resource_group. main. name}  kind        =  Linux  reserved      = true sku {  tier =  Standard   size =  S1  }}# This creates the service definitionresource  azurerm_app_service   main  { name        =  ${var. prefix}-appservice  location      =  ${azurerm_resource_group. main. location}  resource_group_name =  ${azurerm_resource_group. main. name}  app_service_plan_id =  ${azurerm_app_service_plan. main. id}  site_config {  app_command_line =     linux_fx_version =  DOCKER|${var. docker_image}:${var. docker_image_tag}   always_on    = true } app_settings = {   WEBSITES_ENABLE_APP_SERVICE_STORAGE  =  false    DOCKER_REGISTRY_SERVER_URL      =  https://index. docker. io   # These are app specific environment variables   SPRING_PROFILES_ACTIVE    =  prod,swagger    SPRING_DATASOURCE_URL    =  jdbc:mysql://${azurerm_mysql_server. main. fqdn}:3306/${azurerm_mysql_database. main. name}?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false&amp;useLegacyDatetimeCode=false&amp;serverTimezone=UTC    SPRING_DATASOURCE_USERNAME  =  ${azurerm_mysql_server. main. administrator_login}@${azurerm_mysql_server. main. name}    SPRING_DATASOURCE_PASSWORD  =  ${var. my_sql_master_password}  }}In this configuration, under site_config we use linux_fx_version to declare our docker image and set always_on to true so that the application is not shut down when there is inactivity for some time. In the app_settings section we need to disable storage using the flag WEBSITES_ENABLE_APP_SERVICE_STORAGE and also specify DOCKER_REGISTRY_SERVER_URL. Everything else is specific to our app. The flags passed to the MySQL connection URL is important. Now that our main. tf is ready let us define some output properties that are handy. In the outputs. tf file add the below 1234567output  app_service_name  { value =  ${azurerm_app_service. main. name} }output  app_service_default_hostname  { value =  https://${azurerm_app_service. main. default_site_hostname} }Now we are ready to rock and roll! let us deploy the app. Make sure you have set up your Azure CLI and have logged in using az login. Now in a terminal/console navigate to the terraform folder we created and execute these commands. Please change the values for prefix, location &amp; docker_image accordingly. 1234567$ terraform init$ terraform apply \-var prefix=myAwesomeApp \-var location=northeurope \-var docker_image=deepu105/hellojhipster \-var docker_image_tag=latestThis will prompt you to enter a master password for MySQL server and your Azure subscription ID(You can find this from Azure portal or by running az account list- the id field is the subscription ID). Once you provide the values and confirm, Terraform will get to work and will start creating the resources. this could take a while since we are provisioning a Database server. Wait for it or go have that second coffee ;) Once the deployment is complete, Terraform will print out the outputs which include the app_service_default_hostname. Copy the URL and open it in your favorite browser. The first time could take a while since the app will be started(cold start) only during the first request.  I hope you found this useful. This is my first post in dev. to, I hope to migrate my blogs from Medium to dev. to soon. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. My other related posts:  Create full Microservice stack using JHipster Domain Language under 30 minutes Deploying JHipster Microservices on Azure Kubernetes Service (AKS) How to set up JHipster microservices with Istio service mesh on Kubernetes Continuous delivery of Microservices with XebiaLabs — a. k. a DevOps as Code"
    }, {
    "id": 23,
    "url": "/react-done-right-with-typescript/",
    "title": "React components done right with TypeScript mapped and conditional types",
    "body": "2018/11/19 - You’ve probably heard about TypeScript, If not you should check it out. You may have heard someone claiming how great type safety is. TypeScript is great. As someone who hates to transpile his code, I would definitely do it with TypeScript if I had to. So much has been said about TypeScript, and there isn’t really anything new that I can add. But I do believe that type safety is not all about making your code ugly with type definitions everywhere. So how can we write type-safe code without having to litter type declarations everywhere? Type inference and advanced features like derived and dynamic types are the answer. Editors and IDEs we use are smart enough to handle code with inferred type gracefully without us having to see the types all the time visually. (Of course, they all usually show you the type when you hover over an inferred type. ) TypeScript has very good type inference. As a rule of thumb, you can always start without declaring the type for any variable and see if the compiler infers it. With modern editors like VSCode, you can see this immediately. So set your tsconfig to the strict mode. Then start declaring types when the compiler complains. Additionally, TypeScript 2. 1 and 2. 8 introduced a bunch of cool lookup types. Now you can dynamically infer types using different techniques like Intersection types, Union types, Index types, mapped types and conditional types. Index types: Index types enable us to check properties and types of an interface or type dynamically using the keyof T (index type query operator) and T[K] (indexed access operator). Let’s take the below interface for example. 123456  interface Person {   name: string;   age: number;   address: string;   sayHi: (msg: string) =&gt; string;  }The keyof T operator gets a union type of all the key names of the type T and hence keyof Person will give us 'name' | 'age' | 'address' | sayHi' as result. The T[K] operator gets the type for the provided key. Person['name'] will result in string and Person[*keyof* Person] will result in string | number | ((msg: string) =&gt; string). Mapped types: Let us see what mapped types are. Let us say we have the below interface for a Person. 123456  interface Person {   name: string;   age: number;   address: string;   sayHi: (msg: string) =&gt; string;  }Now in every project, it is almost always a common requirement to have variations of a certain interface. For example, let’s say we need a read-only version of the person as below. 123456  interface ReadonlyPerson {   readonly name: string;   readonly age: number;   readonly address: string;   readonly sayHi: (msg: string) =&gt; string;  }In this case, we would have to replicate the Person interface and we have to keep them in sync manually. This is where mapped types will come in handy, so let us use the builtin mapped type, Readonly, for this. 1  type ReadonlyPerson = Readonly&lt;Person&gt;If you hover over the ReadonlyPerson type you can see the inferred type as below. Inferred type view in VsCode That is cool, right? Now we can create types from existing types and don’t have to worry about keeping them in sync. How does it work, what does Readonly&lt;Person&gt; do? Let’s take a look at the mapped type. 123  type Readonly&lt;T&gt; = {    readonly [K in keyof T]: T[K];  }The in operator from TypeScript does the trick here. It maps all the declarations of the existing type into the new type. The keyof operator provides the keys from our type for the mapping. Let us build our own mapped type. Let us say we need a read-only Person interface where all the fields are nullable as well. We can build a mapped type as below for that. 123  type ReadonlyNullablePerson = {    readonly [P in keyof Person]: Person[P] | null;  }And it is inferred as below Let’s make it generic so that it can be used with any interface. 12345  type ReadonlyNullable&lt;T&gt; = {    readonly [K in keyof T]: T[K] | null;  }  type ReadonlyNullablePerson = ReadonlyNullable&lt;Person&gt;TypeScript includes Readonly&lt;T&gt;, Partial&lt;T&gt;, Pick&lt;T, K extends keyof T&gt; and Record&lt;K extends string, T&gt; as built-in mapped types. Pick and Record can be used as below, check them in your editor to see what types they produce. 123  type PersonMinimal = Pick&lt;Person, 'name' | 'age'&gt;  type RecordedPerson = Record&lt;'name' | 'address', string&gt;For every other use case, you can build your own mapped types. Conditional types:  A conditional type selects one of two possible types based on a condition expressed as a type relationship test. Let us look at an example. 1234567  type Foo&lt;T, U&gt; = T extends U ? string : boolean  interface Me {}  interface You extends Person {}  type FooBool = Foo&lt;Me, Person&gt; // will result in boolean  type FooString = Foo&lt;You, Person&gt; // will result in stringThe type dynamically inferred from Foo&lt;T, U&gt; will be either string or boolean depending on what the first generic is extended from. Let us see how we can mix conditional types with mapped types to infer a new type from Person which only includes the non-function properties. 123456789101112131415  type NonFunctionPropNames&lt;T&gt; = {   [K in keyof T]: T[K] extends Function ? never : K  }[keyof T];  type NonFunctionProps&lt;T&gt; = Pick&lt;T, NonFunctionPropNames&lt;T&gt;&gt;  type PersonProps = NonFunctionProps&lt;Person&gt;  /* Produces the below type  type PersonProps = {    name: string;    age: number;    address: string;  }  */We first get all the non-function property names from the interface. Then use the Pick mapped type to pick those from the interface to form the new interface. TypeScript provides the following inbuilt conditional types:    Exclude&lt;T, U&gt; – Exclude from T those types that are assignable to U.     Extract&lt;T, U&gt; – Extract from T those types that are assignable to U.     NonNullable&lt;T&gt; – Exclude null and undefined from T.     ReturnType&lt;T&gt; – Obtain the return type of a function type.     InstanceType&lt;T&gt; – Obtain the instance type of a constructor function type.  Let us put it into use: These advanced types become even more powerful when you combine them together. Let’s see some practical uses of this in React. React component and Redux reducer in ES6: Let see a simple React component with a reducer written in ES6. Take a look at index. jsx in the below code sandbox:                         As you can see, we use the prop-types library to define the component props. It is not the most efficient way, as it includes considerable overhead during development. It doesn’t provide full type safety anyway. React component and Redux reducer in TypeScript: Now let us convert this simple example to TypeScript so that it is type safe. Take a look at index. tsx in the below code sandbox:                         As you can see, the code is more type-safe now. It is also much more verbose even without PropTypes library and all the type inference. React component and Redux reducer in TypeScript with advanced types: Now let us apply the advanced types that we learned to make this example less verbose and even more type safe. Take a look at index. tsx in the below code sandbox:                         As you can see, we used Readonly and ReturnType mapping along with some other type inference techniques to write a more type-safe but less verbose version of the component. Conclusion: If you are using React with TypeScript, then these are some of the techniques you must apply. If you are considering a type system for React, then look no further than TypeScript. It has great features, great tooling, excellent IDE/Editor support and an awesome community. I gave a talk on TypeScript for Devoxx 2018, and you can see the video and slides if you like here.                                                                         Check out my book “Full Stack Development with JHipster” on Amazon and Packt if you like to learn about Full stack development with an awesome stack that includes TypeScript and React. If you like JHipster don’t forget to give it a star on Github. If you like this article, please like or comment. You can follow me on Twitter and LinkedIn. Originally published in Medium on November 19, 2018 "
    }, {
    "id": 24,
    "url": "/deploying-jhipster-microservices-on-azure-kubernetes-service-aks/",
    "title": "Deploying JHipster Microservices on Azure Kubernetes Service (AKS)",
    "body": "2018/10/01 - If you are developing and deploying applications to production, especially cloud, you would have heard about Kubernetes. Kubernetes(k8s) is a container orchestration platform originally developed by Google and makes deploying containerized/dockerized applications to production more manageable and scalable. Kubernetes has been crowned as the undeniable champion of container orchestration for a while now and every other K*S offering that we see sprouting up are testimonials for that. The K obviously stands for Kubernetes and S/E stands for Service/Engine and the first letter stands for the product offering it. So far we have AKS(Azure), GKE(Google), and EKS(Amazon ECS) and PKS(Pivotal) and also some flavors from Oracle and RedHat(read Openshift) One of my colleagues have written a nice article about it, I highly recommend you read it as well. In this article, we will see how we can deploy a microservice architecture created by JHipster to Azure Kubernetes Service. Azure Kubernetes Service(AKS) is the managed Kubernetes platform offering from Microsoft to host your containerized applications. Creating the microservice application: In one of my previous posts, I showcased how to create a full stack microservice architecture using JHipster and JDL, read the post here if you want to learn more details about it. For this exercise, we will use the same application. Let us recap the steps required. Create a JDL file, let’s say app. jdl, and copy the below content into it. 400: Invalid requestNow create a directory called ecommerce and navigate into it. Run the JHipster import-jdl command. It could take a few minutes, especially the NPM install step. 12$ mkdir ecommerce &amp;&amp; cd ecommerce$ jhipster import-jdl app. jdlOnce the JHipster process is complete, you will see that we have our store gateway, invoice service and notification service created and ready for us. The process until this is explained in more detail in my previous post here and you can deploy the application locally using Docker as explained in that post. If you haven’t done that before I strongly suggest that step so that you get an idea of the application and you also can make sure it works locally on your machine. Generating the Kubernetes configuration: Now that our application is ready, let us create the required configurations for Kubernetes using JHipster. This can also be done using JDL by adding below snippet to the JDL file we used earlier. 123456789deployment { deploymentType kubernetes appsFolders [store, invoice, notification] serviceDiscoveryType eureka dockerRepositoryName  deepu105  // use your own docker repo username here kubernetesNamespace jhipster kubernetesServiceType LoadBalancer monitoring no}For now, let us use the JHipster CLI to do this. In the ecommerce folder, we created earlier, create a new directory, let’s call in k8s so that we get the below structure. 12345├── app. jdl├── invoice├── kubernetes├── notification└── storeCreate the kubernetes directory and navigate to it. Now run the JHipster Kubernetes command there. 12$ mkdir kubernetes &amp;&amp; cd kubernetes$ jhipster kubernetesThe generator will ask you a few questions and choose the answers as highlighted below, as you can see the questions are very similar to the ones asked by jhipster docker-compose command. For the “base Docker repository name” provide your own docker hub account id(For example, my Docker Hub id is deepu105). For real-world use cases, you could also use a private image repository like the Azure Container Registry and in that case, you would have to provide the ACR login server name here. For now, let us keep it simple. 12345678910111213141516171819202122232425262728⎈ Welcome to the JHipster Kubernetes Generator ⎈Files will be generated in folder: /home/deepu/workspace/temp/ecommerce/kubernetes✔ Docker is installed? Which *type* of application would you like to deploy? Microservice application? Enter the root directory where your gateway(s) and microservices are located . . /3 applications found at /home/deepu/workspace/temp/ecommerce/? Which applications do you want to include in your configuration? invoice, notification, store? Do you want to setup monitoring for your applications ? No? Which applications do you want to use with clustered databases (only available with MongoDB and Couchbase)? JHipster registry detected as the service discovery and configuration provider used by your apps? Enter the admin password used to secure the JHipster Registry admin? What should we use for the Kubernetes namespace? jhipster? What should we use for the base Docker repository name? &lt;your Docker hub account id&gt;? What command should we use for push Docker image to repository? docker push? Do you want to enable Istio? No? Choose the kubernetes service type for your edge services LoadBalancer - Let a kubernetes cloud provider automatically assign an IPThe generator will go to work with this and will create the following files and output. 123456789101112131415161718192021222324252627282930313233343536373839404142  create invoice/invoice-deployment. yml  create invoice/invoice-service. yml  create invoice/invoice-mysql. yml  create notification/notification-deployment. yml  create notification/notification-service. yml  create notification/notification-mongodb. yml  create store/store-deployment. yml  create store/store-service. yml  create store/store-mysql. yml  create README. md  create registry/jhipster-registry. yml  create registry/application-configmap. yml  create kubectl-apply. shWARNING! Kubernetes configuration generated with missing images!To generate the missing Docker image(s), please run: . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/invoice . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/notification . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/storeWARNING! You will need to push your image to a registry. If you have not done so, use the following commands to tag and push the images: docker image tag invoice deepu105/invoice docker push deepu105/invoice docker image tag notification deepu105/notification docker push deepu105/notification docker image tag store deepu105/store docker push deepu105/storeYou can deploy all your apps by running the following script: . /kubectl-apply. shUse these commands to find your application's IP addresses: kubectl get svc storeCongratulations, JHipster execution is complete!As you can see the generator creates all the required Kubernetes configuration files and prints out useful information to proceed further (Note that the docker hub id you provided will be in the instructions in place of deepu105 here). Go through the generated k8s files and familiarize yourself. Now we are ready. Let us build and push the docker images for our application. Follow the instructions above and build docker images in each of the application folders and then tag and push the images to your Docker hub account. Preparing AKS Cluster: Now that our applications are built and pushed its time for us to deploy them to AKS. But before that let’s make sure we have all the prerequisites ready. You will need the below tools.    kubectl: The command line tool to interact with Kubernetes. Install and configure it.     Azure CLI: The command line tool to interact with Azure. Install and log in with your Azure account(You can create a free account if you don’t have one already).  Once the tools are ready let us prepare our Kubernetes cluster. First, let us create a resource group. Run the below command. This will create a resource group named eCommerceCluster in US east location(You can use other Azure regions as well). 1$ az group create --name eCommerceCluster --location eastusNow let us create an AKS cluster on the resource group we just created. Run the below command to create a cluster named eCommerceCluster with two nodes(We would need some room to run all those containers). It also enables the Azure monitor on the cluster through the add-on specified. 123$ az aks create --resource-group eCommerceCluster \--name eCommerceCluster --node-count 2 \--enable-addons monitoring --generate-ssh-keysThis would take several minutes to complete hence be patient and have a coffee :) Did I emphasize on several minutes? Once it’s done you should see the cluster information printed out as JSON. Now, let us configure kubectl to connect to the AKS cluster we just created. This can be done automatically using the Azure CLI by running the below handy command. Note: Some Azure CLI commands might take a while to execute, especially if you are on a slow network, sometimes if the below commands seem stalled or if it is timed out, kill it and retry again. 1$ az aks get-credentials --resource-group eCommerceCluster --name eCommerceClusterVerify that we are able to connect to the cluster by running kubectl get nodes 1234$ kubectl get nodesNAME            STATUS  ROLES   AGE    VERSIONaks-nodepool1-34429729-0  Ready   agent   22m    v1. 9. 9aks-nodepool1-34429729-1  Ready   agent   22m    v1. 9. 9Deploying the application to AKS: Now that our cluster is ready, let us deploy our microservice stack to this cluster. We can deploy our application using the kubectl apply command for this we have to navigate to the k8s folder we created earlier and run the below commands in the same order 1234567$ kubectl apply -f registry$ kubectl apply -f invoice$ kubectl apply -f notification$ kubectl apply -f storeOr you could also just run the handy kubectl-apply. sh script generated which runs the above. So we are deploying the JHipster Registry first as it is required for other services, followed by the microservices and finally our gateway(store). If you get a timeout during any of these, as I did, just try the command again. Though the services get created fast, the actual applications might not be up and running yet, give the entire thing a minute or two to start. Now run kubectl get pods to see the status of our containers. 1234567891011$ kubectl get pods -wNAME                  READY STATUS invoice-5ffb46d944-h8x42        1/1  Runninginvoice-mysql-66bc4b7874-p7ghk     1/1  Runningjhipster-registry-0           1/1  Runningjhipster-registry-1           1/1  Runningnotification-76847b7667-d7xjb      1/1  Runningnotification-mongodb-6db986b556-8bw8z  1/1  Runningstore-8dc5cd6f7-s2dpx          1/1  Runningstore-mysql-779d66685d-tmkqd      1/1  RunningNote: I have removed some info for brevity in the above output. Wait until all the containers are in Running status. Once the containers are running we can run the kubectl get service command to get the external IP for the application. 1234$ kubectl get service storeNAME  TYPE     CLUSTER-IP  EXTERNAL-IP  PORT(S)     AGEstore LoadBalancer 10. 0. 189. 145 40. 117. 140. 228 8080:30143/TCP 18mIn this case, the external IP for our gateway application is 40. 117. 140. 228 running on port 8080. Let us open it up in a web browser. The Gateway application login page The JHipster registry is deployed as a headless service by default. If we need to access the registry we need to create a secondary service with a Load Balancer. Run the below command to expose the second service. 1$ kubectl expose service jhipster-registry --type=LoadBalancer --name=exposed-registryNow run the kubectl get service command to get the IP. 1234$ kubectl get service exposed-registryNAME       TYPE     CLUSTER-IP  EXTERNAL-IP  PORT(S)exposed-registry LoadBalancer 10. 0. 107. 121 104. 211. 15. 142 8761:32628/TCPVisit the URL in a browser to see the registry in action JHipster Registry home page We can now scale any of our services by simply running kubectl scale command. For example, let us scale our Invoice service. 1$ kubectl scale --replicas=2 deployment/invoiceNow we can visit the Eureka -&gt; Instances on our Registry and see that the Invoice service has two instances. JHipster Registry instances page Running kubectl get pods will also show you the new instance. 123456789101112$ kubectl get pods NAME                 READY STATUS  AGEinvoice-5ffb46d944-g8j6j       1/1  Running 4minvoice-5ffb46d944-h8x42       1/1  Running 2hinvoice-mysql-66bc4b7874-p7ghk    1/1  Running 2hjhipster-registry-0          1/1  Running 2hjhipster-registry-1          1/1  Running 2hnotification-76847b7667-d7xjb     1/1  Running 2hnotification-mongodb-6db986b556-8bw8z 1/1  Running 2hstore-8dc5cd6f7-s2dpx         1/1  Running 2hstore-mysql-779d66685d-tmkqd     1/1  Running 2hThat is it, we have successfully got our application deployed to AKS and scaled our service on demand. Cleanup: Once you are done its always a good idea to clean up especially since we don’t want to keep unnecessary resources that might eat up our free credits on Azure. Let us delete the cluster from AKS and related resources created by deleting the entire resource group. 1$ az group delete --name eCommerceCluster --yes --no-waitCluster related activities like creation/update/deletion could take several minutes on AKS so we have to be patient again here. Conclusion: Kubernetes is definitely the best way to deploy microservice applications to production but creating and managing Kubernetes clusters itself is not an easy task, but Kubernetes services like GKE and AKS makes it a cakewalk. In my personal experience, the Kubernetes service from Google(GKE) and Azure(AKS) are by far the best in terms of ease of use and available tooling. These services provide very handy command line tools which work nicely together with kubectl to provide a very nice experience. They also have nice UI portals if you are not a fan of the CLI. JHipster provides a great Kubernetes setup to start with which you can further tweak as per your needs and platform. In upcoming posts, we will look at more services like GKE(Google), EKS(Amazon) and Openshift(RedHat) To learn more about JHipster, check out my book “Full Stack Development with JHipster” on Amazon and Packt. If you like JHipster don’t forget to give it a star on Github. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. My other related posts:    Create full Microservice stack using JHipster Domain Language under 30 minutes     JHipster microservices with Istio service mesh on Kubernetes  Originally published in Medium on Oct 01, 2018 "
    }, {
    "id": 25,
    "url": "/create-full-microservice-stack-using-j-hipster-domain-language-under-30-minutes/",
    "title": "Create full Microservice stack using JHipster Domain Language under 30 minutes",
    "body": "2018/09/22 - It’s been quite a while since I wrote a blog, I did a few some years ago but never really continued writing. So when I decided to start writing again, I didn’t have to think a lot about a topic as it was very obvious — JHipster. JHipster is a development platform for Java web applications and microservices development. If you are a JVM developer you might have already heard about JHipster. If not, well, you are missing out on a lot and I highly recommend you check it out. You can also check out my book “Full Stack Development with JHipster” on Amazon and Packt to learn about JHipster. I have been working on JHipster from April 2015 and the coolest feature that I got to implement so far is definitely multiple applications generation using JDL. This feature is available in the latest version of JHipster. If you are not familiar with JDL, I recommend you to check out the docs at https://www. jhipster. tech/jdl/ The E-Commerce application: So let us see how we can create a microservice stack using JHipster. We will build an e-commerce store today. The stack includes-    Service discovery using JHipster Registry, a Spring boot application that packs Eureka server and Spring cloud config server.     API management and Gateway using Spring Boot, Netflix Zuul, ReactJS, and Swagger.     Microservices using Spring Boot.     Monitoring using JHipster Console which is made of the Elastic stack(ELK) and Zipkin.  Microservice application architecture The Gateway routes incoming requests to two microservices, Invoice application, and Notification application. Requirements: In order to follow this tutorial, you would need a recent version of Docker, Docker-compose, NodeJS and Java installed on your computer. The below are the versions I have installed(Update: With JHipster 6+ you can use Java 11 &amp; 12). 12345678910111213$ docker -v                                                            Docker version 18. 06. 1-ce, build e68fc7a$ docker-compose -v                docker-compose version 1. 20. 1, build 5d8c71b$ node -v        v8. 11. 4$ java -version     openjdk version  1. 8. 0_212 OpenJDK Runtime Environment (Zulu 8. 38. 0. 13-CA-linux64) (build 1. 8. 0_212-b04)OpenJDK 64-Bit Server VM (Zulu 8. 38. 0. 13-CA-linux64) (build 25. 212-b04, mixed mode)First, install the latest version of JHipster 1$ npm install generator-jhipster -gVerify that you have version 5. 3. 4 or above by running 1$ jhipster --versionCreating the JDL: Now let us create our JDL. Head over to the JDL Studio or your favorite IDE/Editor(You can use JHipster IDE plugin if you like). First, let us define our applications. We will start with the Gateway 123456789101112131415application { config {  baseName store,  applicationType gateway,  packageName com. jhipster. demo. store,  serviceDiscoveryType eureka,  authenticationType jwt,  prodDatabaseType mysql,  cacheProvider hazelcast,  buildTool gradle,  clientFramework react,  testFrameworks [protractor] } entities *}Most of the options are self-explanatory, we are building an application named Store of type Gateway with JWT authentication and Eureka-based service discovery. The application uses a MySQL database and Hazelcast for the cache. It’s built using Gradle. For the client-side, it uses React and Sass. It also has Protractor for end-to-end testing. At the end of the definition you can see entities *, we will come to this later. Now let us define our Invoice microservice 12345678910111213application { config {  baseName invoice,  applicationType microservice,  packageName com. jhipster. demo. invoice,  serviceDiscoveryType eureka,  authenticationType jwt,  prodDatabaseType mysql,  buildTool gradle,  serverPort 8081 } entities Invoice, Shipment}It follows similar options like our Gateway and since it is microservice it doesn’t define any client-side options and also skips user management as it will be handled by the Gateway. Additionally, we have also mentioned a custom port 8081 since we do not want this application to conflict with the default port 8080 used by the Gateway. Now let us define the second microservice, the Notification application 123456789101112131415application { config {  baseName notification,  applicationType microservice,  packageName com. jhipster. demo. notification,  serviceDiscoveryType eureka,  authenticationType jwt,  databaseType mongodb,  cacheProvider no,  enableHibernateCache false,  buildTool gradle,  serverPort 8082 } entities Notification}This application follows many options similar to the Gateway and Invoice application but instead of using MySQL it uses MongoDB as its database and also disables cache. Now that our application definitions are done, we will proceed to define our entity model. For our Gateway store application, let us define the below entities and enums 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** Product sold by the Online store */entity Product {  name String required  description String  price BigDecimal required min(0)  size Size required  image ImageBlob}enum Size {  S, M, L, XL, XXL}entity ProductCategory {  name String required  description String}entity Customer {  firstName String required  lastName String required  gender Gender required  email String required pattern(/^[^@\s]+@[^@\s]+\. [^@\s]+$/)  phone String required  addressLine1 String required  addressLine2 String  city String required  country String required}enum Gender {  MALE, FEMALE, OTHER}entity ProductOrder {  placedDate Instant required  status OrderStatus required  code String required  invoiceId Long}enum OrderStatus {  COMPLETED, PENDING, CANCELLED}entity OrderItem {  quantity Integer required min(0)  totalPrice BigDecimal required min(0)  status OrderItemStatus required}enum OrderItemStatus {  AVAILABLE, OUT_OF_STOCK, BACK_ORDER}relationship OneToOne {  Customer{user(login) required} to User}relationship ManyToOne {  OrderItem{product(name) required} to Product}relationship OneToMany {  Customer{order} to ProductOrder{customer(email) required},  ProductOrder{orderItem} to OrderItem{order(code) required},  ProductCategory{product} to Product{productCategory(name)}}service Product, ProductCategory, Customer, ProductOrder, OrderItem with serviceClasspaginate Product, Customer, ProductOrder, OrderItem with paginationThe JDL defines the entities, enums, the relationship between entities and options like pagination and service layer. The entity field definition follows the syntax 123entity &lt;entity name&gt; { &lt;field name&gt; &lt;type&gt; [&lt;validation&gt;*]}The relationship definition follows the syntax 12345relationship (OneToMany | ManyToOne | OneToOne | ManyToMany) {  &lt;from entity&gt;[{&lt;relationship name&gt;[(&lt;display field&gt;)]}]   to   &lt;to entity&gt;[{&lt;relationship name&gt;[(&lt;display field&gt;)]}]}Refer the JDL docs for full DSL reference. The Invoice microservice application has the following entities 12345678910111213141516171819202122232425262728293031entity Invoice {  code String required  date Instant required  details String  status InvoiceStatus required  paymentMethod PaymentMethod required  paymentDate Instant required  paymentAmount BigDecimal required}enum InvoiceStatus {  PAID, ISSUED, CANCELLED}entity Shipment {  trackingCode String  date Instant required  details String}enum PaymentMethod {  CREDIT_CARD, CASH_ON_DELIVERY, PAYPAL}relationship OneToMany {  Invoice{shipment} to Shipment{invoice(code) required}}service Invoice, Shipment with serviceClasspaginate Invoice, Shipment with paginationmicroservice Invoice, Shipment with invoicePay attention to the last microservice option declared here, it specifies that these entities belong to the microservice named invoice so that our Gateway knows where to route requests for these entities. Now let us see the entities for the Notification microservice application 1234567891011121314entity Notification {  date Instant required  details String  sentDate Instant required  format NotificationType required  userId Long required  productId Long required}enum NotificationType {  EMAIL, SMS, PARCEL}microservice Notification with notificationNow let us go back to the entities keyword we used in our application definitions. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061application { config {  . . .  } entities *}application { config {  . . .  } entities Invoice, Shipment}application { config {  . . .  } entities Notification}/* Entities for Store Gateway */entity Product {  . . . }entity ProductCategory {  . . . }entity Customer {  . . . }entity ProductOrder {  . . . }entity OrderItem {  . . . }microservice Invoice, Shipment with invoice/* Entities for Invoice microservice */entity Invoice {  . . . }entity Shipment {  . . . }/* Entities for notification microservice */entity Notification {  . . . }microservice Notification with notificationHere we instruct the store gateway application that it should contain all the entities defined in the JDL and the gateway will know to skip server-side code for the entities that belong to another microservice and hence will only generate the client-side code for those, here namely Invoice, Shipment, and Notification. We also instruct the Invoice application and Notification application to include its entities. Generating the applications: Create a folder where we want to create our microservice stack. 1$ mkdir ecommerce &amp;&amp; cd ecommerceNow, let us put everything together into a JDL file. Let us call it app. jdl and save it into this folder. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169application { config {  baseName store,  applicationType gateway,  packageName com. jhipster. demo. store,  serviceDiscoveryType eureka,  authenticationType jwt,  prodDatabaseType mysql,  cacheProvider hazelcast,  buildTool gradle,  clientFramework react,  testFrameworks [protractor] } entities *}application { config {  baseName invoice,  applicationType microservice,  packageName com. jhipster. demo. invoice,  serviceDiscoveryType eureka,  authenticationType jwt,  prodDatabaseType mysql,  buildTool gradle,  serverPort 8081 } entities Invoice, Shipment}application { config {  baseName notification,  applicationType microservice,  packageName com. jhipster. demo. notification,  serviceDiscoveryType eureka,  authenticationType jwt,  databaseType mongodb,  cacheProvider no,  enableHibernateCache false,  buildTool gradle,  serverPort 8082 } entities Notification}/* Entities for Store Gateway *//** Product sold by the Online store */entity Product {  name String required  description String  price BigDecimal required min(0)  size Size required  image ImageBlob}enum Size {  S, M, L, XL, XXL}entity ProductCategory {  name String required  description String}entity Customer {  firstName String required  lastName String required  gender Gender required  email String required pattern(/^[^@\s]+@[^@\s]+\. [^@\s]+$/)  phone String required  addressLine1 String required  addressLine2 String  city String required  country String required}enum Gender {  MALE, FEMALE, OTHER}entity ProductOrder {  placedDate Instant required  status OrderStatus required  code String required  invoiceId Long}enum OrderStatus {  COMPLETED, PENDING, CANCELLED}entity OrderItem {  quantity Integer required min(0)  totalPrice BigDecimal required min(0)  status OrderItemStatus required}enum OrderItemStatus {  AVAILABLE, OUT_OF_STOCK, BACK_ORDER}relationship OneToOne {  Customer{user(login) required} to User}relationship ManyToOne { OrderItem{product(name) required} to Product}relationship OneToMany {  Customer{order} to ProductOrder{customer(email) required},  ProductOrder{orderItem} to OrderItem{order(code) required} ,  ProductCategory{product} to Product{productCategory(name)}}service Product, ProductCategory, Customer, ProductOrder, OrderItem with serviceClasspaginate Product, Customer, ProductOrder, OrderItem with pagination/* Entities for Invoice microservice */entity Invoice {  code String required  date Instant required  details String  status InvoiceStatus required  paymentMethod PaymentMethod required  paymentDate Instant required  paymentAmount BigDecimal required}enum InvoiceStatus {  PAID, ISSUED, CANCELLED}entity Shipment {  trackingCode String  date Instant required  details String}enum PaymentMethod {  CREDIT_CARD, CASH_ON_DELIVERY, PAYPAL}relationship OneToMany {  Invoice{shipment} to Shipment{invoice(code) required}}service Invoice, Shipment with serviceClasspaginate Invoice, Shipment with paginationmicroservice Invoice, Shipment with invoice/* Entities for notification microservice */entity Notification {  date Instant required  details String  sentDate Instant required  format NotificationType required  userId Long required  productId Long required}enum NotificationType {  EMAIL, SMS, PARCEL}microservice Notification with notificationNow let us invoke JHipster CLI to import this file 1$ jhipster import-jdl app. jdlThis will create the store, invoice and notification folders and will do the below in each of the folders    Generate the appropriate application and entities configuration.     Generate the application and entities source code based on the configurations.     Install the NPM dependencies for the application.  Once the process is complete you should see the below on your console 123456789Entity Product generated successfully. Entity ProductCategory generated successfully. Entity Customer generated successfully. Entity ProductOrder generated successfully. Entity OrderItem generated successfully. Entity Invoice generated successfully. Entity Shipment generated successfully. Entity Notification generated successfully. Congratulations, JHipster execution is complete!Walk around the generated code to familiarize yourself. Running the applications with Docker: Now that our applications are created its time to test them locally using Docker. To do this first let us generate some docker compose configurations using JHipster. Create a new folder inside the ecommerce folder and run the JHipster docker-compose command 12$ mkdir docker-compose &amp;&amp; cd docker-compose$ jhipster docker-composeIt will prompt you with a few questions, choose the answers as highlighted below 12345678910111213141516171819202122🐳 Welcome to the JHipster Docker Compose Sub-Generator 🐳Files will be generated in folder: /home/deepu/workspace/temp/ecommerce/docker-compose✔ Docker is installed? Which *type* of application would you like to deploy? Microservice application? Which *type* of gateway would you like to use? JHipster gateway based on Netflix Zuul? Enter the root directory where your gateway(s) and microservices are located . . /3 applications found at /home/deepu/workspace/temp/ecommerce/? Which applications do you want to include in your configuration? invoice, notification, store? Which applications do you want to use with clustered databases (only available with MongoDB and Couchbase)? ? Do you want to setup monitoring for your applications ? Yes, for logs and metrics with the JHipster Console (based on ELK and Zipkin)? You have selected the JHipster Console which is based on the ELK stack and additional technologies, which one do you want to use ? Zipkin, for distributed tracing (only compatible with JHipster &gt;= v4. 2. 0)JHipster registry detected as the service discovery and configuration provider used by your apps? Enter the admin password used to secure the JHipster Registry? adminThis will generate all the required docker-compose configurations for the stack and will also print out further instructions to build the docker images. Note: In the latest JHipster versions we migrated to using Jib for creating Docker images. This is a huge improvement over the Docker Maven plugin that we were using, as a result the command to create an image has changed to . /gradlew -Pprod bootWar jibDockerBuild. 12345Docker Compose configuration generated with missing images!To generate the missing Docker image(s), please run: . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/invoice . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/notification . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/storeFollow the instructions and build the docker images. Once all 3 images are built run the below command from the docker-compose folder to fire everything up. 1$ docker-compose up -dOnce the containers start you can stream the logs using below command 1$ docker-compose logs -fNow point your favorite browser to http://localhost:8080/ and see the E-Commerce microservice application in action. Gateway application(Store) You can see the JHipster registry in action at http://localhost:8761/ JHipster Registry And finally the JHipster console at http://localhost:5601/ JHipster Console- Kibana dashboard Once you are done playing around, you can shut everything down by running the below command on the docker-compose folder 1docker-compose downHope you had fun creating microservices using JHipster. To learn how to convert a JHipster monolith to microservices check out my book “Full Stack Development with JHipster” on Amazon and Packt. In the coming weeks, I’ll write some posts about deploying this microservice stack to various cloud providers like GCP, Azure, AWS, Heroku and so on. If you like JHipster don’t forget to give it a star on Github. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. My other related posts:    Deploying JHipster Microservices on Azure Kubernetes Service (AKS)     JHipster microservices with Istio service mesh on Kubernetes  Originally published in Medium on Sep 22, 2018 "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}

function lunr_search(term) {
    $('#lunrsearchresults').show( 400 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-danger btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
    
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 5 );
        $( "body" ).removeClass( "modal-open" );
    });
});