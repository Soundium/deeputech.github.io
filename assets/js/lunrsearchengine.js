
var documents = [{
    "id": 0,
    "url": "/404.html",
    "title": "404",
    "body": "404 Page does not exist!Please use the search bar at the top or visit our homepage! "
    }, {
    "id": 1,
    "url": "/categories",
    "title": "Categories",
    "body": ""
    }, {
    "id": 2,
    "url": "/comment-policy",
    "title": "Comment policy",
    "body": "Keep it civil aka don’t be a jerk: We’re going to get into the thick of a lot of heated discussions and that’s okay. These discussions often entail topics that we all personally care a lot about and will passionately defend. But in order for discussions to thrive here, we need to remember to criticize ideas, not people.   So, remember to avoid:  name-calling ad hominem attacks Responding to a post’s tone instead of its actual content.  knee-jerk contradictionComments that we find to be hateful, inflammatory, or harassing may be removed. If you don’t have something nice to say about another user, don’t say it. Treat others the way you’d like to be treated. Always strive to add value to every interaction and discussion you participate in: There are a lot of discussions that happen every day on Disqus. Before joining in a discussion, browse through some of the most recent and active discussions happening in the community, especially if you’re new there.   If you are not sure your post adds to the conversation, think over what you want to say and try again later. Keep it tidy: Help make moderators’ lives easier by taking a moment to ensure that what you’re about to post is in the right place. That means:  don’t post off-topic comments or discussions don’t cross-post the same thing multiple times review any specific posting guidelines for the community check if another active discussion on your topic has already been postedIf you see something, say something: Moderators are at the forefront of combatting spam, mediating disputes and enforcing community guidelines and, so are you.   If you see an issue, contact the moderators if possible or flag any comments for review. If you believe someone has violated the Basic Rules, report it to Disqus by flagging the user’s profile. No Self-promotion A discussion or comment that contains only a link to your blog, a product, or your article on another site will almost always be removed. Choose Your (Curse) Words Wisely Comments that contain profanity are automatically held for moderator review before being posted. Depending on the context of the comment, it may be removed. Profanity used to insult, antagonize, or inflame will always be removed. Don’t Be a Jerk Personal attacks and harassment will not be tolerated. Sexist, racist, misogynist, homophobic, and broad, offensive generalizations about groups of people are simply not allowed. Comments or discussions written intentionally to provoke will also be removed. Don’t Copy and Paste If you didn’t write it, or haven’t properly cited the article you’re quoting, don’t post it. English Only We currently only support English-only discussions on Disqus channels. Non-English comments and discussions will be removed. Related: Guide to building community guidelines: "
    }, {
    "id": 3,
    "url": "/",
    "title": "Deepu K Sasidharan",
    "body": "                                             I'm a Software Designer by passion &amp; profession. I'm also the co-lead of JHipster.          My expertise includes solution ideation, visualization, and prototyping.          I code using various Languages like Java, JavaScript, TypeScript, Go, Python and so on.          I'm an open-source software aficionado and a technology advocate by passion.          I'm also passionate about developer experience and user experience.          I also love Astronomy, Quadcopters, and Robotics.          I have authored a book on JHipster and write frequently about Java, JavaScript, Go, CloudNative and so on.                                Book:                       Full Stack Development with JHipster.         Get it on        Packt,        Amazon and        Safari.                                               OSS projects:                                            JHipster Generator:                          A cool generator for Angular/React/VueJS + Spring stack                                                    Angular Clock:                          A beautiful responsive clock face and clock widget for angular JS.          Built in SVG                                                          JHipster Registry:                          Service Registry, based on Spring Cloud Netflix Eureka and Spring         Cloud Config                                                    JHipster Entity Audit Generator:                          A yeoman generator to enable entity audit in JHipster generated apps                                                          JDL Studio:                 An awesome online JDL editor and visualizer                                            JHipster Bootswatch Theme Generator:                          A yeoman generator to enable Bootswatch themes in JHipster generated         apps                                                          Angular Object Diff:                          An AngularJS plugin to generate and view object difference                                                    UML and Sequence Diagram Generator:                                  A sequence diagram generator using angularJS and an UML Diagram         Generator based on PlantUML. Experimental.                                                             Follow me on social media:                                                                                                                                                                              Featured posts:                                                                                                                                                                                                                                                                     My reflections on Golang                              :               Do I like Go? Yes. Would I use it for every use case I have? Definitely not. :                                                                                                                                                                       Deepu K Sasidharan                                12 Jul 2019 | 20 mins read                                                                                                                                                                                                                                                                                                                                                                                                My beautiful Linux development environment                              :               One of the questions that I get quite often after a conference talk is weirdly not about what I presented but about my Linux desktop. . . :                                                                                                                                                                       Deepu K Sasidharan                                16 Jun 2019 | 7 mins read                                                                                                                                                                                       "
    }, {
    "id": 4,
    "url": "/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ “sitemap. xml”   absolute_url }}   "
    }, {
    "id": 5,
    "url": "/blogs/index.html",
    "title": "Blogs",
    "body": "  {{ site. name }}      {{ site. description }}         Featured:       {% for post in site. posts %}    {% if post. featured == true %}            {% include featuredbox. html %}          {% endif %}  {% endfor %}        All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 6,
    "url": "/blogs/page/2/index.html",
    "title": " - page 2",
    "body": "  {{ site. name }}      {{ site. description }}         Featured:       {% for post in site. posts %}    {% if post. featured == true %}            {% include featuredbox. html %}          {% endif %}  {% endfor %}        All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 7,
    "url": "/make-the-most-out-of-vscode/",
    "title": "My VS Code setup - Making the most out of VS Code",
    "body": "2019/07/17 - Visual Studio Code(I like the sound of VS Code better), I just love it. It is my primary IDE. I always loved lightweight editors over IDEs. Many years ago I was using Eclipse for development and Notepad++ with some plugins for all other lightweight stuff. Then I discovered sublime text and was using it for a while. I still was finding Eclipse too heavyweight when I was doing web development. Then came Brackets from Adobe. It was a fairly nice editor especially for web development and I started using it heavily for web development. But Brackets was bit slow back then on a large codebase. Then came Atom which revolutionized the NodeJS desktop application landscape by introducing the Atom shell which ultimately became Electron. So I switched to Atom and loved its slick interface and nice pluggable features. It became my primary editor for all web development. So Electron paved the way for VS Code and though at first, I was skeptical dues to the association with Visual Studio, I tried it out and was amazed by its speed and user experience. There was no turning back now. I slowly started using VS Code for most of my day to day development, except for Java which I was using IntelliJ by now. Fast forward now below are the editor/IDE I use for development.  VS Code: JavaScript, TypeScript, EJS, HTML, CSS, Golang, Python, Ruby, Shell, Docker, Kubernetes, Terraform and everything in between including writing this blog post.  IntelliJ Idea: Java, Scala, Kotlin (Though I use VS Code for minor edits and to read the code, etc) VIM: For quick edits from the command line. PluginsOf course VS Code makes all this possible by allowing the use of plugins and there is a lot to choose from. Here are the plugins that I personally use to work on the above-said languages. You can use the code --install-extension command to install them from the terminal. Language support: Based on the Languages you work with you can add syntax, utility and language support plugins for those. I use the below JavaScript/TypeScript/Web:  EJS language support - Adds EJS template support.      code --install-extension DigitalBrainstem. javascript-ejs-support     Close HTML/XML tag - Auto close HTML/XML tags.      code --install-extension Compulim. compulim-vscode-closetag     ESLint - Adds support for ESLint rules.      code --install-extension dbaeumer. vscode-eslint     TSLint - Adds support for TSLint rules.      code --install-extension dbaeumer. vscode-eslint     Prettier - Adds support for Prettier formatter.      code --install-extension esbenp. prettier-vscode     es-beautifier - Formats JS according to Eslint rules.      code --install-extension dai-shi. vscode-es-beautifier    Go:  Go - Adds rich language support for Golang.      code --install-extension ms-vscode. Go    JVM:  Language Support for Java - Adds Java language support.      code --install-extension redhat. java     Debugger for Java - Adds lightweight Java debugging support.      code --install-extension vscjava. vscode-java-debug     JHipster JDL - Adds syntax support for JHipster JDL files.      code --install-extension jhipster-ide. jdl    The Java support indeed is getting better and better, so I hope one day I can completely switch to VS Code. Announcing the Visual Studio Code Installer for #Java https://t. co/u6lyKW0xFS &mdash; Markus Eisele (@myfear) June 16, 2019Python:  Language Support for Python - Adds Python language support, linting and debugging support.      code --install-extension ms-python. python    Cloud, Container &amp; others:  Docker - Adds Docker support(view and manage containers) and support for Docker, docker-compose files.      code --install-extension vscjava. vscode-java-debug     Jenkinsfile Support - Adds syntax highlighting support for Jenkinsfile’s.      code --install-extension secanis. jenkinsfile-support     Terraform - Adds support for Terraform files.      code --install-extension mauve. terraform     Markdown all in one - Full markdown support with live preview, keyboard shortcuts, etc.      code --install-extension yzhang. markdown-all-in-one     PlantUML - Rich PlantUML support with live preview.      code --install-extension jebbs. plantuml     Visual Studio IntelliCode - Adds AI assisted intellisense support for multiple languages.      code --install-extension VisualStudioExptTeam. vscodeintellicode     YAML - Adds YAML support.      code --install-extension redhat. vscode-yaml    Theme: Dark++ Italic: My default theme. Similar to VS Code default dark theme but has support for FiraCode and Operator Mono fonts. I personally use FiraCode.  code --install-extension idbartosz. darkpp-italic Material icon theme: A nice icon theme based on material icons.  code --install-extension PKief. material-icon-theme Peacock: Subtly changes the workspace color of your workspace. Helpful to identify when you have many windows open.  code --install-extension johnpapa. vscode-peacock Tools: Auto rename tag: Automatically rename paired HTML/XML tags  code --install-extension formulahendry. auto-rename-tag Bracket pair colorizer 2: Marks matching bracket pairs with unique colors. This really makes reading code nicer  code --install-extension CoenraadS. bracket-pair-colorizer-2 Change case: Convert between different case. Trust me this is so handy  code --install-extension wmaurer. change-case Code spell checker: Fairly useful for spell checking within code. Takes cameCase etc into account  code --install-extension streetsidesoftware. code-spell-checker Easy snippet maker: Useful to store re usable snippets.  code --install-extension tariky. easy-snippet-maker EditorConfig for VS Code: Add support for EditorConfig.  code --install-extension EditorConfig. EditorConfig Git History: Enable viewing Git history within VS Code.  code --install-extension donjayamanne. githistory Gitignore: Makes it easy to work with . gitignore files.  code --install-extension codezombiech. gitignore Hide gitignored: Hides patterns defined in . gitignore from the editors explorer.  code --install-extension npxms. hide-gitignored Mark as excluded: Exclude stuff right from the explorer tree.  code --install-extension jcmordan. mark-as-excluded Toggle Excluded Files: Easily toggle between showing and hiding excluded files/folders.  code --install-extension eamodio. toggle-excluded-files IntelliJ IDEA Keybindings: I have bad muscle memory so wanted to use the same keyboard shortcuts as IntelliJ. There are mappings available for Sublime, Atom and so on.  code --install-extension k--kato. intellij-idea-keybindings Sort JSON: Sorts JSON object keys.  code --install-extension richie5um2. vscode-sort-json Test Explorer UI: Adds an explorer panel for running tests. Supports multiple languages and testing frameworks.  code --install-extension hbenl. vscode-test-explorer Todo Tree: Aggregate TODO, FIXME, etc in a tree view in explorer.  code --install-extension Gruntfuggly. todo-tree Terminal setupIf you are using Zsh shell with Oh-my-zsh like me as explained here, you might want to do the below to get the same terminal experience in the integrated VSCode terminal as well.  Follow these steps  Download and install a patched font.  On Linux, run fc-cache -f -v to refresh font cache.  On VSCode, open Preferences → Settings and click on the {} icon to open JSON mode and set the below  123456  terminal. integrated. shell. linux :  /usr/bin/zsh ,  terminal. integrated. fontFamily :  'SauceCodePro Nerd Font Mono','Source Code Pro' ,  terminal. integrated. rightClickCopyPaste : true,  terminal. integrated. fontSize : 14,  terminal. integrated. cursorStyle :  underline ,  terminal. integrated. cursorBlinking : true    Replace linux with osx if you are on a Mac.  ConclusionThis might seem like too many plugins but on my configuration VS Code is lightning fast and loads up immediately and is faster then IntelliJ to load and work with. The beauty of VS Code is that you don’t need all the plugin all the time, you can disable the ones not required per workspace to make it even faster. Many people ask me why I use VS Code when I have IntelliJ and my answer have been always the same. IntelliJ is great but its also quite heavy. While all those advanced features are needed for Java, Scala or Kotlin development, VS Code is perfectly capable of giving a nice developer experience for lightweight languages like JS, TS, Go, Python, Rust, Ruby, etc. As a regular user of both IntelliJ and VS Code, I prefer VS Code as much as possible. The user experience is much nicer for my taste. In fact, I like the developer experience in VS Code better for JavaScript, TypeScript, Web, Python, and Golang. Also switching between them for JVM projects and others don’t feel weird for me as I have same keyboard mappings for both. The only time I fire up IntelliJ these days are when I want to do full-fledged Java development. For everything else, I use VS Code. I hope you find this useful. If you have any question or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. "
    }, {
    "id": 8,
    "url": "/react-done-right-with-typescript/",
    "title": "React components done right with TypeScript mapped and conditional types",
    "body": "2019/07/13 - You’ve probably heard about TypeScript, If not you should check it out. You may have heard someone claiming how great type safety is. TypeScript is great. As someone who hates to transpile his code, I would definitely do it with TypeScript if I had to. So much has been said about TypeScript, and there isn’t really anything new that I can add. But I do believe that type safety is not all about making your code ugly with type definitions everywhere. So how can we write type-safe code without having to litter type declarations everywhere? Type inference and advanced features like derived and dynamic types are the answer. Editors and IDEs we use are smart enough to handle code with inferred type gracefully without us having to see the types all the time visually. (Of course, they all usually show you the type when you hover over an inferred type. ) TypeScript has very good type inference. As a rule of thumb, you can always start without declaring the type for any variable and see if the compiler infers it. With modern editors like VSCode, you can see this immediately. So set your tsconfig to the strict mode. Then start declaring types when the compiler complains. Additionally, TypeScript 2. 1 and 2. 8 introduced a bunch of cool lookup types. Now you can dynamically infer types using different techniques like Intersection types, Union types, Index types, mapped types and conditional types. Index types: Index types enable us to check properties and types of an interface or type dynamically using the keyof T (index type query operator) and T[K] (indexed access operator). Let’s take the below interface for example. 123456  interface Person {   name: string;   age: number;   address: string;   sayHi: (msg: string) =&gt; string;  }The keyof T operator gets a union type of all the key names of the type T and hence keyof Person will give us 'name' | 'age' | 'address' | sayHi' as result. The T[K] operator gets the type for the provided key. Person['name'] will result in string and Person[*keyof* Person] will result in string | number | ((msg: string) =&gt; string). Mapped types: Let us see what mapped types are. Let us say we have the below interface for a Person. 123456  interface Person {   name: string;   age: number;   address: string;   sayHi: (msg: string) =&gt; string;  }Now in every project, it is almost always a common requirement to have variations of a certain interface. For example, let’s say we need a read-only version of the person as below. 123456  interface ReadonlyPerson {   readonly name: string;   readonly age: number;   readonly address: string;   readonly sayHi: (msg: string) =&gt; string;  }In this case, we would have to replicate the Person interface and we have to keep them in sync manually. This is where mapped types will come in handy, so let us use the builtin mapped type, Readonly, for this. 1  type ReadonlyPerson = Readonly&lt;Person&gt;If you hover over the ReadonlyPerson type you can see the inferred type as below. Inferred type view in VsCode That is cool, right? Now we can create types from existing types and don’t have to worry about keeping them in sync. How does it work, what does Readonly&lt;Person&gt; do? Let’s take a look at the mapped type. 123  type Readonly&lt;T&gt; = {    readonly [K in keyof T]: T[K];  }The in operator from TypeScript does the trick here. It maps all the declarations of the existing type into the new type. The keyof operator provides the keys from our type for the mapping. Let us build our own mapped type. Let us say we need a read-only Person interface where all the fields are nullable as well. We can build a mapped type as below for that. 123  type ReadonlyNullablePerson = {    readonly [P in keyof Person]: Person[P] | null;  }And it is inferred as below Let’s make it generic so that it can be used with any interface. 12345  type ReadonlyNullable&lt;T&gt; = {    readonly [K in keyof T]: T[K] | null;  }  type ReadonlyNullablePerson = ReadonlyNullable&lt;Person&gt;TypeScript includes Readonly&lt;T&gt;, Partial&lt;T&gt;, Pick&lt;T, K extends keyof T&gt; and Record&lt;K extends string, T&gt; as built-in mapped types. Pick and Record can be used as below, check them in your editor to see what types they produce. 123  type PersonMinimal = Pick&lt;Person, 'name' | 'age'&gt;  type RecordedPerson = Record&lt;'name' | 'address', string&gt;For every other use case, you can build your own mapped types. Conditional types:  A conditional type selects one of two possible types based on a condition expressed as a type relationship test. Let us look at an example. 1234567  type Foo&lt;T, U&gt; = T extends U ? string : boolean  interface Me {}  interface You extends Person {}  type FooBool = Foo&lt;Me, Person&gt; // will result in boolean  type FooString = Foo&lt;You, Person&gt; // will result in stringThe type dynamically inferred from Foo&lt;T, U&gt; will be either string or boolean depending on what the first generic is extended from. Let us see how we can mix conditional types with mapped types to infer a new type from Person which only includes the non-function properties. 123456789101112131415  type NonFunctionPropNames&lt;T&gt; = {   [K in keyof T]: T[K] extends Function ? never : K  }[keyof T];  type NonFunctionProps&lt;T&gt; = Pick&lt;T, NonFunctionPropNames&lt;T&gt;&gt;  type PersonProps = NonFunctionProps&lt;Person&gt;  /* Produces the below type  type PersonProps = {    name: string;    age: number;    address: string;  }  */We first get all the non-function property names from the interface. Then use the Pick mapped type to pick those from the interface to form the new interface. TypeScript provides the following inbuilt conditional types:    Exclude&lt;T, U&gt; – Exclude from T those types that are assignable to U.     Extract&lt;T, U&gt; – Extract from T those types that are assignable to U.     NonNullable&lt;T&gt; – Exclude null and undefined from T.     ReturnType&lt;T&gt; – Obtain the return type of a function type.     InstanceType&lt;T&gt; – Obtain the instance type of a constructor function type.  Let us put it into use: These advanced types become even more powerful when you combine them together. Let’s see some practical uses of this in React. React component and Redux reducer in ES6: Let see a simple React component with a reducer written in ES6. Take a look at index. jsx in the below code sandbox:                         As you can see, we use the prop-types library to define the component props. It is not the most efficient way, as it includes considerable overhead during development. It doesn’t provide full type safety anyway. React component and Redux reducer in TypeScript: Now let us convert this simple example to TypeScript so that it is type safe. Take a look at index. tsx in the below code sandbox:                         As you can see, the code is more type-safe now. It is also much more verbose even without PropTypes library and all the type inference. React component and Redux reducer in TypeScript with advanced types: Now let us apply the advanced types that we learned to make this example less verbose and even more type safe. Take a look at index. tsx in the below code sandbox:                         As you can see, we used Readonly and ReturnType mapping along with some other type inference techniques to write a more type-safe but less verbose version of the component. Conclusion: If you are using React with TypeScript, then these are some of the techniques you must apply. If you are considering a type system for React, then look no further than TypeScript. It has great features, great tooling, excellent IDE/Editor support and an awesome community. I gave a talk on TypeScript for Devoxx 2018, and you can see the video and slides if you like here.                                                                         Check out my book “Full Stack Development with JHipster” on Amazon and Packt if you like to learn about Full stack development with an awesome stack that includes TypeScript and React. If you like JHipster don’t forget to give it a star on Github. If you like this article, please like or comment. You can follow me on Twitter and LinkedIn. Originally published in Medium on November 19, 2018 "
    }, {
    "id": 9,
    "url": "/reflection-on-golang/",
    "title": "My reflections on Golang",
    "body": "2019/07/12 - Do I like Go? Yes. Would I use it for every use case I have? Definitely not. Having worked on most of these said languages I won&#39;t choose Go for general purpose atleast not current version of Go, may be 2. 0 has more potential. &mdash; 𝔻𝕖𝕖𝕡𝕦 𝕂 𝕊𝕒𝕤𝕚𝕕𝕙𝕒𝕣𝕒𝕟 (@deepu105) March 7, 2019Don’t get me wrong, I like Go for what it is but like every other programming language, it is always a love-hate relationship. No programming language is perfect and all of them have their own merits and use cases. I hate it when I see people overusing something and I see that pattern with Go these days. To be fair, I have done my fair share of overusing in my career as well (mostly with JavaScript) and I can see why people do it. This is not gonna be a blog bashing Go or praising Go, it is just what I think of it after using it for over 9 months. Before I start a rant on the good and bad of Go, here is some background. After being in the tech industry for over 10 years, I would like to think of myself as a pragmatic programmer or at least as someone getting closer to that - that should be a programmer’s Nirvana. I didn’t even plan to be a programmer, if you ask the 18-year-old self of me, he would say that he wanted to be an astrophysicist or a robotics engineer(Yes building space robots was my dream). Like most teenage dreams, it didn’t happen and I ended up in tech instead. Though landing an IT Job was an accident, programming wasn’t alien to me. I did learn some C/C++ when I was in high school to help my girlfriend with her project and did dabble in some PHP, JavaScript, HTML and Flash(ActionScript) during my early college years for personal projects and blogs. So when I got a real IT job without having an IT background, I did what many in that situation did, I started learning the language that I stumbled upon first based on the task I was given, which happened to be Java. Being a quick learner and having some idea of programming concepts from C/C++ Java wasn’t that hard to learn and I was a pretty decent Java programmer in a few months. Then I was tasked with building some Web UI and I dived deep into the world of HTML, CSS, and JavaScript and honestly fell in love with JavaScript due to its flexibility and ease. I mastered JQuery and soon become the go-to guy for front end stuff in the office. I was anything but pragmatic back then, I was preaching JavaScript to everyone and would vehemently debate anyone who thought JS was a bad language. Fast forward to now and if I look back I have done projects in C/C++, PHP, JavaScript, TypeScript, HTML, CSS, Java, Groovy, Scala, Python and recently Go. I think this exposure probably helped me become more pragmatic as I have started to look at programming languages as tools and each of them has their own strengths and weaknesses. Well, there is more to this story but that’s for another time, the point is to set a baseline for the below reflections so that I don’t sound like someone just trying Go and going on a rant. Go is the latest language I learned and worked with, I have worked on a CLI project built with Go for over 9 months now, building a powerful scaffolding engine with my team(Yes, pretty much like JHipster) that uses Go templates where you could create what we call blueprints at XebiaLabs. So yes I have done much more than a hello world app with Go. Without wasting more time on unrelated things here is what I like about Go and what I don’t like. What I like about Go: Simplicity: I like the fact that Go is a simple language(Going through the entire language features on the tour page literally takes 15 minutes unless you do the exercises) and unlike Scala, Rust or even JavaScript Go doesn’t have many ways of doing the same thing which is extremely valuable for people working in teams and companies wanting to write maintainable code where even a newly joined employee can read and understand the code without needing much help. I think this is one of the biggest reason that is driving Go adoption. If you have worked on large scale projects you know how difficult it is when the code is unreadable and every new team member have to spend so much time trying to understand what a piece of code does. So I was really happy when I saw that Go doesn’t have features that rely heavily on implicit and such. The language features and concepts are easy to grasp and you can start being productive in Go quite soon. The only concepts that might seem bit complex are the concurrency part and even that is simpler compared to other languages. Language provided code style and vetting: This is such a time saver. IMO every language should just do this so that you don’t waste time debating code style and setting up lint rules. Go provides opinionated formatting, linting &amp; vet tool as part of the package and the Go compiler even enforces things like unused variable and stuff. Most of the IDE/Editor plugins also use these tools for formatting and linting and hence helps to keep consistent code style across Go projects which again adds to readability and maintenance. Goroutines &amp; Channels: This is one of the biggest strength of Go. The native support for concurrency and parallelism. This makes Go an ideal candidate for applications that require heavy concurrent and/or parallel processing, networking and so on. Goroutines makes it so easy to start lightweight threads and channels provide a way to communicate between these threads acting like a message bus. 1234567891011func main() {	messages := make(chan string)	collected := make([]string, 2)	go func() { messages &lt;-  ping  }()	go func() { messages &lt;-  pong  }()	collected = append(collected, &lt;-messages)	collected = append(collected, &lt;-messages)	fmt. Println(collected) // [ pong ping ]}Closures &amp; callbacks: If you have used JavaScript you would know how useful closures and callbacks are. Go like JavaScript treats functions as objects and hence can be assigned to variables, stored in maps, passed as function parameters and returned from functions. It also supports creating nested closures and anonymous functions which helps to encapsulate context. The behavior is pretty much similar to JavaScript. So you can apply some functional programming concepts in Go as well. 123456789101112131415161718192021222324func main() {	// an unnecessarily complicated example	type fnType = func(a int, b int) int	fnMap := map[string]fnType{		 ADD : func(a int, b int) int {			return a + b		},		 SUB : func(a int, b int) int {			return a - b		},	}	// this is a closure	localFn := func(method string) fnType {		return fnMap[method] // returns a function	}	printer := func(fn func(method string) fnType, method string) {		fmt. Println(fn(method)(10, 5)) // callback	}	// function passed as parameter	printer(localFn,  ADD )	printer(localFn,  SUB )}Type assertion and switches: Go provides a nice way of asserting types and can be used with a switch statement which makes it easier to do reflection and such. Multiple returns: This is quite a handy feature like in Python, we are used to deconstructing objects/arrays to achieve this in JavaScript and using Tuples and such in some languages. The returns can also be named which is nice for readability. Tooling: The in-code test coverage highlight in VsCode for @golang is slick. This is the best way to ensure you have good coverage@code pic. twitter. com/nk8iMwenCz &mdash; 𝔻𝕖𝕖𝕡𝕦 𝕂 𝕊𝕒𝕤𝕚𝕕𝕙𝕒𝕣𝕒𝕟 (@deepu105) February 14, 2019As mentioned earlier Go provides standard tooling for formatting, linting and so on and the language design makes it easy to build tooling for Go and hence editors/IDE has nice features like test generation, code coverage and so on. For example, the VSCode integration for Go provides the below options which helps with consistency and less boilerplate to write by hand.  Doesn’t need a runtime: Go doesn’t need a runtime like JVM or NodeJS, Go applications can be compiled into an executable cross-platform binary using the standard Go tooling. This makes Go applications portable and platform-independent. What I don’t like about Go: Simplicity: This is where the love-hate relationship starts, Go is a simple language which is nice but at times it feels too simple &amp; verbose and coming from Java/JavaScript ecosystem you are spoiled with some nice features &amp; syntax sugars which IMO makes the code more expressive and helps to keep it DRY. The things that I miss the most are  Generics: This is currently being considered in the next major iteration of Go, but until then this just makes you repeat code unnecessarily. I have lost count of the number of times I had to repeat the same block of code for different types where Generics would have kept it nice and simple. This is also one reason you don’t see libraries like Lodash for Go.  Standard error handling: This also seems to be coming in the next major iteration of Go but until it lands I can complain. Anyone writing Go will remember doing if err != nil uncountable times in your code. Removing those might cut the codebase in size by at least 20% Default values: Would love to see this in Go, this is quite useful. Maybe I’m just spoiled by JS. Too much boilerplate(not suitable for DRY): Go being too simple means you would have to write a lot of code as the language doesn’t offer constructs like map, reduce, and so on, and add the lack of generic on top means you would end up writing a lot of utility code and a lot of that will be repeated to accommodate different types. Imagine writing a map function in Go, you would have to write one for every combination of Map that can be used. These factors don’t make it easy to do DRY programming in Go. Dependency management: The dependency management in the Go ecosystem feels immature and too basic compared to other mainstream languages. Importing packages from Git is nice but it also makes it more fragile. What can go wrong when you are depending on a Git branch on your production application right! There is no way to use relative dependencies(Can’t beat NPM link!). These problems are similar to the issues with dependency range in Node package managers. Glide seems to be a popular choice but still is not as mature as solutions in other languages. In the project, I work on we used Gradle along with Gogradle and though it works fine the developer experience is not as good as using Gradle/Maven for Java project or using NPM on a NodeJS project. Source code in GOPATH: Go recommends you to create your Go projects under the GOPATH. Maybe it is just me, but I hate this as I would normally like to organize my code. For example, I have a ~/workspace/ folder where I organize my projects by the organization. If I follow the Go recommendation I have to put the project under /home/deepu/go/src along with all the library source code that is downloaded. If you don’t follow this then most of the Go tooling just doesn’t work. Currently, I have a specific Gradle task that copies over all the vendor libs to my local Gopath inside ~/workspace/XL/&lt;project&gt; to workaround this. Confusing pointer behaviors: Go has pretty good pointer support and the default behavior is to pass an object by value. If you want to pass something by reference you have to mark it specifically. But this behavior is not very consistent as the content of Maps and Slices by default are passed by reference and hence this could be a bit surprising to beginners. Struct hell: This is more of a nitpick. Structs are what you would use to create data structures in Go. It might look like an object but they are not exactly objects. While structs are fine functionally, in many cases you will end up with structs that look like the ugly brother of JSON. In real-world projects, you always will end up creating complex structs, especially if the application is doing some generic json or yaml parsing and soon your code will start to look like this. This is not that big of a concern but it just hurts my eyes every time I debug something or write tests. 123456789101112131415161718192021222324252627282930313233343536373839	func main() {	type MyYamlDoc struct {		foo []map[interface{}][]map[interface{}]interface{}		bar interface{}	}	ohno := MyYamlDoc{		[]map[interface{}][]map[interface{}]interface{}{			{				 Foo : {					{ Bar : map[interface{}][]map[interface{}]interface{}{						 Foo : {							{ Bar : map[interface{}][]map[interface{}]interface{}{								 Foo : {									{ Bar : map[interface{}][]map[interface{}]interface{}{										 Foo : {											{ Bar : map[interface{}][]map[interface{}]interface{}{}},										},									}},								},							}},						},					}},				},			},			map[interface{}][]map[interface{}]interface{}{				 Foo : {					{ Bar : map[interface{}][]map[interface{}]interface{}{}},				},			},		},		map[interface{}][]map[interface{}]interface{}{			 Foo : {				{ Bar : map[interface{}][]map[interface{}]interface{}{}},			},		},	}	fmt. Println(ohno)}Weird interface construct: The interface concept in Go is weird. These are the only implicit construct in Go. If you come from other languages that have interfaces then this will feel weird. The fact that they are implicit means its really easy to mess things up. Refactoring is messy unless you have a smart IDE, and you can accidentally implement someone’s interface by just naming your method a certain way. While implicit interfaces certainly help with polymorphism and decoupling code I personally would still prefer interfaces that are explicit. Another interface Gotcha is nil value checks, in Go, an interface is made up of two parts a type and a value, so an interface is nil only when both type and value are nil, this means you can’t just simply do nil checks on interfaces. This is so confusing the Go has a specific FAQ for this. Below article explains this in more detail https://dev. to/pauljlucas/go-tcha-when-nil–nil-hic Single GC algorithm: Go implements a concurrent tri-color mark-sweep collector as its garbage collector. This specific GC implementation is optimized for better pause times while ignoring program throughput, pause frequency and many other parameters that are considered during GC. Some people in the Go community claims this as the best ever GC. Having some Java background I would have to disagree as most JVM implementations provide multiple GC algorithms you can choose from which includes a concurrent mark-sweep collector as well and most of these are balanced to take care of many more parameters than just pause times. This articles analyses this in detail. So some use cases that produce a high amount of garbage might actually be slower in Go compared to another language due to frequent GC. Developer experience: This is purely based on personal experience and hence will vary from others. Being a polyglot developer who has worked with many languages, the developer experience from Go is not the best I have experienced. The DX of the JavaScript ecosystem is the best I have experienced so far. It feels like there are things missing in the Go ecosystem. Dependency management and toolchains need improvement. A bit more sensible language features and some syntax sugar wouldn’t hurt as well. Conclusion: Having worked with many major languages I can’t just use Go for every use case but I can see why people would use Go for every use-case out there if they haven’t worked with other languages. So where would I use Go?:  I would definitely use Go when the use case requires a lot of parallel processing and/or concurrency(both are not the same thing but are closer to each other) as you can make use of Goroutines for this and is much simpler and efficient than managing threads like in a Java application or working around it in JavaScript using callback hell since JS is actually single-threaded. Here is a nice article explaining the advantage of Goroutines.  Simple microservices where boilerplate is not a concern Networking applications or web servers, especially with async workloads, can greatly benefit from Go. But to be fair you can do these in Java, Python, JS, etc as well but Go in the end will provide better efficiency and would be easier to implement.  System programming. While Rust or C is a much better choice for this but if those are not in your arsenal then Go is the next best thing. With decent support for pointers and its standard library its easier for system programs than other mainstream languages. Many popular system tools like Docker, Kubernetes, etc are indeed written in Go. Where I wouldn’t use Go?:  Complex web application: I would choose Java with a framework like Spring or Micronaut as its much more maintainable and battle-tested and you would focus more on business logic than writing boilerplate infrastructure code. One common argument against this stack is its memory footprint but it is possible to get lower memory footprint with Spring and frameworks like Micronaut and Quarkus actually promises that OOB.  After writing a high-level CLI tool in Go, I hate the experience, I kept thinking that doing it in JavaScript would have been 10 times more productive and a nicer experience. SO I would choose JavaScript or TypeScript running on NodeJS for CLI tool any day. Mainly due to the ecosystem and the sheer joy and speed of getting things done without spending all your time writing boilerplate code. But this wouldn’t be applicable if the CLI in question a system tool or a networking tool, in those cases Go could be a good option. I do hope Go evolves into a general-purpose language over time and many of these concerns are solved. In the meantime, I’ll try to follow this mantra. Remember this manthra &quot;right tools for the right job, right pattern for the use-case&quot; #engineering #development #architecture #microservices https://t. co/SA42jQ5TLH &mdash; 𝔻𝕖𝕖𝕡𝕦 𝕂 𝕊𝕒𝕤𝕚𝕕𝕙𝕒𝕣𝕒𝕟 (@deepu105) July 2, 2019But then you can always choose to fasten a screw using a hammer. Using the wrong tool for the job. #programming pic. twitter. com/5RdVqGuZoj &mdash; Rory Preddy🥑 (@rorypreddy) June 24, 2019If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Cover image credit: Unknown. Found here "
    }, {
    "id": 10,
    "url": "/configure-a-beautiful-terminal-on-unix/",
    "title": "Configure a beautiful terminal on Unix with Zsh",
    "body": "2019/07/01 - I was a long time Windows user, a fairly happy one, but as a developer, there were a lot of things that were missing for me and one of the main was the terminal experience. I’m not a fan of the closed ecosystem of Apple so Linux was an easy choice for me and I switched to Linux almost 3 years ago. I did start out with Ubuntu and later switched to Fedora which is my primary OS now. You can read about my setup here As a senior developer and open source community lead, I spent a lot of time on the terminal and a terminal with a nice developer experience instantly makes you happier and more productive. The default bash terminal is good for beginners but if you really want a powerful terminal you need something more than bash. Let’s see how to configure a powerful and productive terminal experience. The setup is based on what I have configured on my Fedora machine. The same setup can be recreated on any other Linux distribution, BSD or Mac as well. You just need to use the installation instruction from the tools for the given platform.  Below are the tools we would need for this. Zsh: Zsh is one of the most feature-rich shells for Unix. It works on Linux, Mac, WSL, and BSD. There are alternatives like Fish which also offers similar features but I personally like Zsh.  Check if Zsh is already installed by running zsh --version on your terminal. If not found, install it using your package manager.      Fedora: sudo dnf install zsh   Mac: brew install zsh zsh-completions   RHEL/CentOS: sudo yum update &amp;&amp; sudo yum -y install zsh   Ubuntu/Debian: sudo apt install zsh   For other platform refer this    Now make Zsh your default shell by running chsh -s $(which zsh).  Log out and log in back again to use your new default shell.  Test that it worked with echo $SHELL. Expected result: /bin/zsh or similar.  Test with $SHELL --version. Expected result: zsh 5. 6. 2 or similarNote: If you have installed Zsh for the first time and launch the shell it would prompt you to configure some settings. You can choose to ignore that by hitting q as we will configure it later on. Oh-My-Zsh: Oh-My-Zsh gives the Zsh shell superpowers. Its a framework to manage Zsh configuration. It has plugins and themes for Zsh(A lot of them). From their Github page:  Once installed, your terminal shell will become the talk of the town or your money back! With each keystroke in your command prompt, you’ll take advantage of the hundreds of powerful plugins and beautiful themes. Strangers will come up to you in cafés and ask you, “that is amazing! are you some sort of genius?” Just install it. You need it :) 1sh -c  $(curl -fsSL https://raw. githubusercontent. com/robbyrussell/oh-my-zsh/master/tools/install. sh) Terminal emulator/multiplexer: Optionally you can use a Terminal emulator that can manage windows and panes for you. For Linux I would recommend using Tilix, I have been using it for 3 years and its just amazing. For Mac, you can use iTerm2 which is very popular. Alternatively, you can also use tmux if you want something lighter on your existing Terminal app on Linux, BSD or Mac. Configuring Zsh: This is the fun part. Let us make the terminal awesome. Install plugins: First, let us install some additional plugins that are not bundled with Oh-My-Zsh. zsh-autosuggestions: Provides auto completion for shell commands. Run git clone https://github. com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/plugins/zsh-autosuggestions to install zsh-syntax-highlighting: Provides syntax highlighting on the shell. Run git clone https://github. com/zsh-users/zsh-syntax-highlighting. git ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/plugins/zsh-syntax-highlighting to install autojump: Provides a smarter directory navigation system. Install autojump for your OS following instructions here. Now let us configure the ~/. zshrc file with some settings. Here is my full . zshrc file. Your mileage may vary. Add exports: We will start with some exports. 1234567891011121314export TERM= xterm-256color  # This sets up colors properly# set shellexport SHELL=/usr/bin/zsh# If you come from bash you might have to change your $PATH. export NODE_PATH=$NODE_PATH:$HOME/. npm-global/lib/node_modulesexport JAVA_HOME=/usr/java/latestexport PATH=$JAVA_HOME/bin:~/. npm-global/bin:$HOME/bin:/usr/local/bin:$PATH# Add exports from your profilesource ~/. profile# Path to your oh-my-zsh installation. export ZSH=$HOME/. oh-my-zshZsh settings: Now we can configure some Zsh specific settings 1234DISABLE_MAGIC_FUNCTIONS=trueZSH_AUTOSUGGEST_MANUAL_REBIND=1COMPLETION_WAITING_DOTS=trueDISABLE_UNTRACKED_FILES_DIRTY=trueZsh theme: Now, Let’s set up a nice theme. I’m using powerlevel10k as my current theme and it’s fast and looks great. You can use the default or you can choose any theme you like from the list here. If you like my theme then follow these instructions. Thanks to Roman Perepelitsa for some cool tips Run git clone https://github. com/romkatv/powerlevel10k. git ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/themes/powerlevel10k to install the theme. Install a Powerline font. I use Adobe Source Code Pro Add the below configuration to the ~/. zshrc file. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182# Set name of the theme to load. Optionally, if you set this to  random # it'll load a random theme each time that oh-my-zsh is loaded. # See https://github. com/robbyrussell/oh-my-zsh/wiki/ThemesZSH_THEME= powerlevel10k/powerlevel10k ############ POWERLEVEL THEME SETTINGS ##############POWERLEVEL9K_MODE='awesome-fontconfig'POWERLEVEL9K_LEFT_PROMPT_ELEMENTS=(dir vcs nvm)POWERLEVEL9K_RIGHT_PROMPT_ELEMENTS=(disk_usage time)POWERLEVEL9K_PROMPT_ADD_NEWLINE=truePOWERLEVEL9K_PROMPT_ON_NEWLINE=truePOWERLEVEL9K_SHOW_RULER=truePOWERLEVEL9K_RULER_CHAR='─'POWERLEVEL9K_RULER_BACKGROUND=nonePOWERLEVEL9K_RULER_FOREGROUND=237POWERLEVEL9K_LEFT_SEGMENT_END_SEPARATOR=POWERLEVEL9K_LEFT_SEGMENT_SEPARATOR=POWERLEVEL9K_LEFT_SUBSEGMENT_SEPARATOR=' 'POWERLEVEL9K_RIGHT_SEGMENT_END_SEPARATOR=POWERLEVEL9K_RIGHT_SEGMENT_SEPARATOR=POWERLEVEL9K_RIGHT_SUBSEGMENT_SEPARATOR=POWERLEVEL9K_WHITESPACE_BETWEEN_LEFT_SEGMENTS=POWERLEVEL9K_SHORTEN_DIR_LENGTH=2POWERLEVEL9K_SHORTEN_STRATEGY= truncate_middle POWERLEVEL9K_DIR_SHOW_WRITABLE=truePOWERLEVEL9K_DISK_USAGE_NORMAL_BACKGROUND=nonePOWERLEVEL9K_DISK_USAGE_WARNING_BACKGROUND=magentaPOWERLEVEL9K_DISK_USAGE_CRITICAL_BACKGROUND=redPOWERLEVEL9K_TIME_BACKGROUND=nonePOWERLEVEL9K_TIME_FOREGROUND=whitePOWERLEVEL9K_DIR_HOME_BACKGROUND=nonePOWERLEVEL9K_DIR_HOME_SUBFOLDER_BACKGROUND=nonePOWERLEVEL9K_DIR_ETC_BACKGROUND=nonePOWERLEVEL9K_DIR_DEFAULT_BACKGROUND=nonePOWERLEVEL9K_DIR_NOT_WRITABLE_BACKGROUND=nonePOWERLEVEL9K_DIR_HOME_FOREGROUND=bluePOWERLEVEL9K_DIR_HOME_SUBFOLDER_FOREGROUND=bluePOWERLEVEL9K_DIR_ETC_FOREGROUND=bluePOWERLEVEL9K_DIR_DEFAULT_FOREGROUND=bluePOWERLEVEL9K_DIR_NOT_WRITABLE_FOREGROUND=redPOWERLEVEL9K_OS_ICON_BACKGROUND= white POWERLEVEL9K_OS_ICON_FOREGROUND= blue POWERLEVEL9K_VCS_GIT_ICON='%fon %F{040}\uf1d3 'POWERLEVEL9K_VCS_GIT_GITHUB_ICON='%fon %F{040}\uf09b 'POWERLEVEL9K_VCS_GIT_BITBUCKET_ICON='%fon %F{040}\uf171 'POWERLEVEL9K_VCS_GIT_GIT_GITLAB_ICON='%fon %F{040}\uf296 'POWERLEVEL9K_VCS_CLEAN_BACKGROUND=nonePOWERLEVEL9K_VCS_UNTRACKED_BACKGROUND=nonePOWERLEVEL9K_VCS_MODIFIED_BACKGROUND=nonePOWERLEVEL9K_VCS_LOADING_BACKGROUND=nonePOWERLEVEL9K_VCS_CLEAN_FOREGROUND= 040 POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND= red POWERLEVEL9K_VCS_MODIFIED_FOREGROUND= yellow POWERLEVEL9K_VCS_LOADING_FOREGROUND= grey POWERLEVEL9K_VCS_UNTRACKED_ICON=$'%{\b?%}'POWERLEVEL9K_VCS_UNSTAGED_ICON=$'%{\b!%}'POWERLEVEL9K_VCS_STAGED_ICON=$'%{\b+%}'POWERLEVEL9K_DIR_NOT_WRITABLE_VISUAL_IDENTIFIER_COLOR=redPOWERLEVEL9K_LOCK_ICON=$'\uf023'POWERLEVEL9K_MULTILINE_FIRST_PROMPT_PREFIX=''local p='%F{%(?. green. red)}${${${KEYMAP:-0}:#vicmd}:+❯}${${$((!${#${KEYMAP:-0}:#vicmd})):#0}:+❮}%f 'POWERLEVEL9K_MULTILINE_LAST_PROMPT_PREFIX= $p POWERLEVEL9K_NVM_BACKGROUND=nonePOWERLEVEL9K_NVM_FOREGROUND=greenPOWERLEVEL9K_NODE_ICON='%fvia %F{green}⬢'############ END- POWERLEVEL THEME SETTINGS ##############Enable plugins: We can finish off by enabling the plugins and some tweaks 1234plugins=(zsh-autosuggestions git docker docker-compose autojump zsh-syntax-highlighting dnf npm)source $ZSH/oh-my-zsh. shAnd that’s it we are ready. Start a new terminal session and enjoy. Issues &amp; workarounds: If you use Tilix as your terminal emulator, then this might be required for proper pane splitting. Add this to your ~/. zshrc 123if [[ $TILIX_ID ]]; then    source /etc/profile. d/vte. shfiIf you are getting errors from the zsh-completion plugin, you might want to add this to the beginning of your ~/. zshrc 1234# workaround as per https://superuser. com/questions/1222867/zsh-completion-functions-brokenFPATH=$HOME/. oh-my-zsh/plugins/git:$HOME/. oh-my-zsh/functions:$HOME/. oh-my-zsh/completions:/usr/share/zsh/site-functions:/usr/share/zsh/$ZSH_VERSION/functionsexport FPATHIf you encounter an error from Oh-My-Zsh saying [oh-my-zsh] Insecure completion-dependent directories detected, set ZSH_DISABLE_COMPFIX=true right before the line source $ZSH/oh-my-zsh. sh in your ~/. zshrc file and restart your session or run exec zsh Dockerized playground. : If you have Docker installed then you can use the below snippet to try this setup in a sandbox without installing anything or affecting your existing setup. 123456789docker run -e LANG=C. UTF-8 -e LC_ALL=C. UTF-8 -e TERM=$TERM -it --rm ubuntu bash -uexc ' apt update &amp;&amp; apt install -y git curl zsh autojump &amp;&amp; cd /root sh -c  $(curl -fsSL https://raw. githubusercontent. com/robbyrussell/oh-my-zsh/master/tools/install. sh)  --skip-chsh --unattended git clone https://github. com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/plugins/zsh-autosuggestions git clone https://github. com/zsh-users/zsh-syntax-highlighting. git ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/plugins/zsh-syntax-highlighting git clone https://github. com/romkatv/powerlevel10k. git ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/themes/powerlevel10k curl -fsSLO http://bit. ly/Spaceship10kTheme echo  source ~/Spaceship10kTheme  &gt;~/. zshrc exec zsh'VSCode Tip: If you are using VSCode like me, you might want to do the below to get the same terminal experience in the integrated VSCode terminal as well.  Follow these steps  Download and install a patched font.  On Linux, run fc-cache -f -v to refresh font cache.  On VSCode, open Preferences → Settings and click on the {} icon to open JSON mode and set the below  123456  terminal. integrated. shell. linux :  /usr/bin/zsh ,  terminal. integrated. fontFamily :  'SauceCodePro Nerd Font Mono','Source Code Pro' ,  terminal. integrated. rightClickCopyPaste : true,  terminal. integrated. fontSize : 14,  terminal. integrated. cursorStyle :  underline ,  terminal. integrated. cursorBlinking : true    Replace linux with osx if you are on a Mac.  I hope you like it. If you have any question or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. "
    }, {
    "id": 11,
    "url": "/must-have-gnome-plugins/",
    "title": "Must have GNOME extensions",
    "body": "2019/06/24 - I’m a sucker for nice polished UI and great UX. While there are a lot of Linux Desktop environments out there providing great UX and UI, I found GNOME to be the perfect one for my liking. Yes, I have seen/tried a few others. I also found some which are more polished and providing a better default UX out of the box than GNOME like Deepin and Elementary. But below plugins bridge that gap and hence I choose to stick with GNOME which is the default in Fedora, hence quite stable, unless I had a compelling reason to switch. So if you like me are a GNOME fan then below are some of the GNOME plugins you must try if you haven’t already. I have listed the plugins I use in my earlier post in the series. here I detail the ones that are a must-have. GNOME Tweaks: This nifty tool lets you tweak/configure a lot of GNOME configuration and should have been included by default in every distro shipping with GNOME. You can customize the appearance, install extensions, configure mouse &amp; keyboard and so on. It can be found in the software center of your distro. Search for “Tweaks”.  Gnome extensions: You can install below extensions by visiting the link in the title of the extension below and by clicking on the on switch on the top right corner. On Chrome, you would need the GNOME Shell integration plugin to enable the switch. On Firefox, it will prompt you to install the plugin if it doesn’t exist. Dash to Dock: GNOME without this plugin almost feels annoying. IMO this plugin also should be the default GNOME setting. This one moves your GNOME dash into a highly configurable dock which can be placed on the sides or top/bottom of the screen. I find it perfect on the left side of the screen in GNOME. It can be a floating dock or fixed to look like those on Mint or KDE.  Always Zoom Workspaces: By default, the GNOME launcher does not show the workspaces, you have to hover over the right edge to see it. I find it unnecessary given you have enough real estate on the full-screen launcher and the workspace view takes only a little bit. This plugin keeps it zoomed by default.  Steal My Focus/NoAnnoyance: This is another default in GNOME that is annoying. When something needs focus these plugins brings the window up instead of the default notification. You can use any one of the plugins as both do the same thing. AlternateTab: This replaces the default Alt+Tab with a more classical window-based switcher which IMO is more user-friendly as the default requires more keyboard navigation using the arrow keys.  Window List: This is a classic plugin that adds the window list to the bottom of the screen and is a must if you use multiple monitors as the windows are grouped and placed in the right monitor screen. Caffeine: This one adds the ability to temporarily disable screensaver/auto-suspend and automatically activates when you go full-screen. A must-have if you are using your computer for watching videos, presentations, screencast and so on. Clipboard Indicator: This is one my favorite. It adds a nifty clipboard manager to the top bar and provides shortcuts to cycle through clipboard entries. A real time saver.  Gistnotes: As a developer using GitHub gist a lot, this one is a very useful plugin. It lets you manage your Gists right from the desktop and you can use it like a notes app.  System-monitor: A nice system monitor plugin that sits on the top bar with a detailed view as a popup.  TopIcons Plus: This moves legacy icons form applications to the top bar for consistent UX. I hope you find this useful. If you have any question or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Cover image photo by Brigitta Schneiter on Unsplash "
    }, {
    "id": 12,
    "url": "/deploying-jhipster-microservices-on-azure-kubernetes-service-aks/",
    "title": "Deploying JHipster Microservices on Azure Kubernetes Service (AKS)",
    "body": "2019/06/23 - If you are developing and deploying applications to production, especially cloud, you would have heard about Kubernetes. Kubernetes(k8s) is a container orchestration platform originally developed by Google and makes deploying containerized/dockerized applications to production more manageable and scalable. Kubernetes has been crowned as the undeniable champion of container orchestration for a while now and every other K*S offering that we see sprouting up are testimonials for that. The K obviously stands for Kubernetes and S/E stands for Service/Engine and the first letter stands for the product offering it. So far we have AKS(Azure), GKE(Google), and EKS(Amazon ECS) and PKS(Pivotal) and also some flavors from Oracle and RedHat(read Openshift) One of my colleagues have written a nice article about it, I highly recommend you read it as well. In this article, we will see how we can deploy a microservice architecture created by JHipster to Azure Kubernetes Service. Azure Kubernetes Service(AKS) is the managed Kubernetes platform offering from Microsoft to host your containerized applications. Creating the microservice application: In one of my previous posts, I showcased how to create a full stack microservice architecture using JHipster and JDL, read the post here if you want to learn more details about it. For this exercise, we will use the same application. Let us recap the steps required. Create a JDL file, let’s say app. jdl, and copy the below content into it. 400: Invalid requestNow create a directory called ecommerce and navigate into it. Run the JHipster import-jdl command. It could take a few minutes, especially the NPM install step. 12$ mkdir ecommerce &amp;&amp; cd ecommerce$ jhipster import-jdl app. jdlOnce the JHipster process is complete, you will see that we have our store gateway, invoice service and notification service created and ready for us. The process until this is explained in more detail in my previous post here and you can deploy the application locally using Docker as explained in that post. If you haven’t done that before I strongly suggest that step so that you get an idea of the application and you also can make sure it works locally on your machine. Generating the Kubernetes configuration: Now that our application is ready, let us create the required configurations for Kubernetes using JHipster. This can also be done using JDL by adding below snippet to the JDL file we used earlier. 123456789deployment { deploymentType kubernetes appsFolders [store, invoice, notification] serviceDiscoveryType eureka dockerRepositoryName  deepu105  // use your own docker repo username here kubernetesNamespace jhipster kubernetesServiceType LoadBalancer monitoring no}For now, let us use the JHipster CLI to do this. In the ecommerce folder, we created earlier, create a new directory, let’s call in k8s so that we get the below structure. 12345├── app. jdl├── invoice├── kubernetes├── notification└── storeCreate the kubernetes directory and navigate to it. Now run the JHipster Kubernetes command there. 12$ mkdir kubernetes &amp;&amp; cd kubernetes$ jhipster kubernetesThe generator will ask you a few questions and choose the answers as highlighted below, as you can see the questions are very similar to the ones asked by jhipster docker-compose command. For the “base Docker repository name” provide your own docker hub account id(For example, my Docker Hub id is deepu105). For real-world use cases, you could also use a private image repository like the Azure Container Registry and in that case, you would have to provide the ACR login server name here. For now, let us keep it simple. 12345678910111213141516171819202122232425262728⎈ Welcome to the JHipster Kubernetes Generator ⎈Files will be generated in folder: /home/deepu/workspace/temp/ecommerce/kubernetes✔ Docker is installed? Which *type* of application would you like to deploy? Microservice application? Enter the root directory where your gateway(s) and microservices are located . . /3 applications found at /home/deepu/workspace/temp/ecommerce/? Which applications do you want to include in your configuration? invoice, notification, store? Do you want to setup monitoring for your applications ? No? Which applications do you want to use with clustered databases (only available with MongoDB and Couchbase)? JHipster registry detected as the service discovery and configuration provider used by your apps? Enter the admin password used to secure the JHipster Registry admin? What should we use for the Kubernetes namespace? jhipster? What should we use for the base Docker repository name? &lt;your Docker hub account id&gt;? What command should we use for push Docker image to repository? docker push? Do you want to enable Istio? No? Choose the kubernetes service type for your edge services LoadBalancer - Let a kubernetes cloud provider automatically assign an IPThe generator will go to work with this and will create the following files and output. 123456789101112131415161718192021222324252627282930313233343536373839404142  create invoice/invoice-deployment. yml  create invoice/invoice-service. yml  create invoice/invoice-mysql. yml  create notification/notification-deployment. yml  create notification/notification-service. yml  create notification/notification-mongodb. yml  create store/store-deployment. yml  create store/store-service. yml  create store/store-mysql. yml  create README. md  create registry/jhipster-registry. yml  create registry/application-configmap. yml  create kubectl-apply. shWARNING! Kubernetes configuration generated with missing images!To generate the missing Docker image(s), please run: . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/invoice . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/notification . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/storeWARNING! You will need to push your image to a registry. If you have not done so, use the following commands to tag and push the images: docker image tag invoice deepu105/invoice docker push deepu105/invoice docker image tag notification deepu105/notification docker push deepu105/notification docker image tag store deepu105/store docker push deepu105/storeYou can deploy all your apps by running the following script: . /kubectl-apply. shUse these commands to find your application's IP addresses: kubectl get svc storeCongratulations, JHipster execution is complete!As you can see the generator creates all the required Kubernetes configuration files and prints out useful information to proceed further (Note that the docker hub id you provided will be in the instructions in place of deepu105 here). Go through the generated k8s files and familiarize yourself. Now we are ready. Let us build and push the docker images for our application. Follow the instructions above and build docker images in each of the application folders and then tag and push the images to your Docker hub account. Preparing AKS Cluster: Now that our applications are built and pushed its time for us to deploy them to AKS. But before that let’s make sure we have all the prerequisites ready. You will need the below tools.    kubectl: The command line tool to interact with Kubernetes. Install and configure it.     Azure CLI: The command line tool to interact with Azure. Install and log in with your Azure account(You can create a free account if you don’t have one already).  Once the tools are ready let us prepare our Kubernetes cluster. First, let us create a resource group. Run the below command. This will create a resource group named eCommerceCluster in US east location(You can use other Azure regions as well). 1$ az group create --name eCommerceCluster --location eastusNow let us create an AKS cluster on the resource group we just created. Run the below command to create a cluster named eCommerceCluster with two nodes(We would need some room to run all those containers). It also enables the Azure monitor on the cluster through the add-on specified. 123$ az aks create --resource-group eCommerceCluster \--name eCommerceCluster --node-count 2 \--enable-addons monitoring --generate-ssh-keysThis would take several minutes to complete hence be patient and have a coffee :) Did I emphasize on several minutes? Once it’s done you should see the cluster information printed out as JSON. Now, let us configure kubectl to connect to the AKS cluster we just created. This can be done automatically using the Azure CLI by running the below handy command. Note: Some Azure CLI commands might take a while to execute, especially if you are on a slow network, sometimes if the below commands seem stalled or if it is timed out, kill it and retry again. 1$ az aks get-credentials --resource-group eCommerceCluster --name eCommerceClusterVerify that we are able to connect to the cluster by running kubectl get nodes 1234$ kubectl get nodesNAME            STATUS  ROLES   AGE    VERSIONaks-nodepool1-34429729-0  Ready   agent   22m    v1. 9. 9aks-nodepool1-34429729-1  Ready   agent   22m    v1. 9. 9Deploying the application to AKS: Now that our cluster is ready, let us deploy our microservice stack to this cluster. We can deploy our application using the kubectl apply command for this we have to navigate to the k8s folder we created earlier and run the below commands in the same order 1234567$ kubectl apply -f registry$ kubectl apply -f invoice$ kubectl apply -f notification$ kubectl apply -f storeOr you could also just run the handy kubectl-apply. sh script generated which runs the above. So we are deploying the JHipster Registry first as it is required for other services, followed by the microservices and finally our gateway(store). If you get a timeout during any of these, as I did, just try the command again. Though the services get created fast, the actual applications might not be up and running yet, give the entire thing a minute or two to start. Now run kubectl get pods to see the status of our containers. 1234567891011$ kubectl get pods -wNAME                  READY STATUS invoice-5ffb46d944-h8x42        1/1  Runninginvoice-mysql-66bc4b7874-p7ghk     1/1  Runningjhipster-registry-0           1/1  Runningjhipster-registry-1           1/1  Runningnotification-76847b7667-d7xjb      1/1  Runningnotification-mongodb-6db986b556-8bw8z  1/1  Runningstore-8dc5cd6f7-s2dpx          1/1  Runningstore-mysql-779d66685d-tmkqd      1/1  RunningNote: I have removed some info for brevity in the above output. Wait until all the containers are in Running status. Once the containers are running we can run the kubectl get service command to get the external IP for the application. 1234$ kubectl get service storeNAME  TYPE     CLUSTER-IP  EXTERNAL-IP  PORT(S)     AGEstore LoadBalancer 10. 0. 189. 145 40. 117. 140. 228 8080:30143/TCP 18mIn this case, the external IP for our gateway application is 40. 117. 140. 228 running on port 8080. Let us open it up in a web browser. The Gateway application login page The JHipster registry is deployed as a headless service by default. If we need to access the registry we need to create a secondary service with a Load Balancer. Run the below command to expose the second service. 1$ kubectl expose service jhipster-registry --type=LoadBalancer --name=exposed-registryNow run the kubectl get service command to get the IP. 1234$ kubectl get service exposed-registryNAME       TYPE     CLUSTER-IP  EXTERNAL-IP  PORT(S)exposed-registry LoadBalancer 10. 0. 107. 121 104. 211. 15. 142 8761:32628/TCPVisit the URL in a browser to see the registry in action JHipster Registry home page We can now scale any of our services by simply running kubectl scale command. For example, let us scale our Invoice service. 1$ kubectl scale --replicas=2 deployment/invoiceNow we can visit the Eureka -&gt; Instances on our Registry and see that the Invoice service has two instances. JHipster Registry instances page Running kubectl get pods will also show you the new instance. 123456789101112$ kubectl get pods NAME                 READY STATUS  AGEinvoice-5ffb46d944-g8j6j       1/1  Running 4minvoice-5ffb46d944-h8x42       1/1  Running 2hinvoice-mysql-66bc4b7874-p7ghk    1/1  Running 2hjhipster-registry-0          1/1  Running 2hjhipster-registry-1          1/1  Running 2hnotification-76847b7667-d7xjb     1/1  Running 2hnotification-mongodb-6db986b556-8bw8z 1/1  Running 2hstore-8dc5cd6f7-s2dpx         1/1  Running 2hstore-mysql-779d66685d-tmkqd     1/1  Running 2hThat is it, we have successfully got our application deployed to AKS and scaled our service on demand. Cleanup: Once you are done its always a good idea to clean up especially since we don’t want to keep unnecessary resources that might eat up our free credits on Azure. Let us delete the cluster from AKS and related resources created by deleting the entire resource group. 1$ az group delete --name eCommerceCluster --yes --no-waitCluster related activities like creation/update/deletion could take several minutes on AKS so we have to be patient again here. Conclusion: Kubernetes is definitely the best way to deploy microservice applications to production but creating and managing Kubernetes clusters itself is not an easy task, but Kubernetes services like GKE and AKS makes it a cakewalk. In my personal experience, the Kubernetes service from Google(GKE) and Azure(AKS) are by far the best in terms of ease of use and available tooling. These services provide very handy command line tools which work nicely together with kubectl to provide a very nice experience. They also have nice UI portals if you are not a fan of the CLI. JHipster provides a great Kubernetes setup to start with which you can further tweak as per your needs and platform. In upcoming posts, we will look at more services like GKE(Google), EKS(Amazon) and Openshift(RedHat) To learn more about JHipster, check out my book “Full Stack Development with JHipster” on Amazon and Packt. If you like JHipster don’t forget to give it a star on Github. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. My other related posts:    Create full Microservice stack using JHipster Domain Language under 30 minutes     JHipster microservices with Istio service mesh on Kubernetes  Originally published in Medium on Oct 01, 2018 "
    }, {
    "id": 13,
    "url": "/my-beautiful-linux-development-environment/",
    "title": "My beautiful Linux development environment",
    "body": "2019/06/16 - One of the questions that I get quite often after a conference talk is weirdly not about what I presented but about my Linux desktop environment. People are more curious about that beautiful distro rather than the awesome presentation I just did 😂 Not that I’m complaining, I love my desktop setup. I love it so much that I was afraid of getting a new PC when I was due for one. I was afraid that I would mess things up(I have done that many times in the past, I think Linux users can relate to me) So I decided to capture the most important aspects of my distro for anyone interested in using Linux as their primary OS for development.  This is not just my work laptop, it’s my primary machine which I use for all of the below  Java, JS, TS, Go, Python &amp; web development JHipster development Running multiple web applications locally Running Docker containers VirtualBox for Windows testing &amp; other VM stuff Kubernetes, Terraform, CloudFormation development and deployments Azure, AWS &amp; GCP deployments using required CLI tools Heavy browser usage Email, chat &amp; video conferencing Plex media server Blogging Youtube &amp; Social mediaMachine configuration: The configuration of the machine is also quite important for any development setup. So my laptop is a Dell Precision 5530 Mobile Workstation. I had the exact same setup with my old Dell 5510 as well, which is quite a similar configuration to 5530. I still have it as a backup Laptop, its 2 years old now but can still give most of the top end laptops today a run for its money. I used the custom configuration option from Dell to get the best possible setup at that time. it’s not cheap but my company, XebiaLabs, provided a handsome budget and I think it is worth every penny. This, in my opinion, is one of the best Laptop for developers. So here is what I have. Processor: Intel® Core™ i9-8950HK CPU @ 2. 90GHz × 12 Memory: 32GB, DDR4-2666MHz SDRAM, 2 DIMMS, Non-ECC HDD: M. 2 1TB NVMe PCIe SED class 40 SSD Graphics: NVIDIA Quadro P2000 with 4 GB GDDR5 memory &amp; Intel® UHD Graphics 630 (Coffeelake 3x8 GT2) Wireless: Intel Wifi Link 9260 2x2 802. 11AC + BT 4. 2 vPro wireless card Keyboard: English QWERTY US, backlit Display: 15. 6” FHD 1920x1080 Anti-Glare LED-backlit Non-touch IPS UltraSharp™ Battery: 6-cell (97Wh) Lithium Ion battery with ExpressCharge™ Operating system and desktop environment: The most important of course is the operating system, I’m running Fedora 30 at the moment with GNOME 3. 32. 2 as the Desktop and I’m very happy with it. I find Fedora more suitable for development machines than other distros as it has a short release cycle and is fairly stable so you get latest &amp; stable software all the time.  What good is a desktop without a nice theme right? GNOME is great when it comes to themes and I went with Arc-Flatabulous theme and never looked back. For icons, I use Paper as I like the material icon theme.  Of course, it won’t be complete without some nice GNOME plugins. Below are the plugins that I use.  Dash to Dock Always Zoom Workspaces Auto Move Windows Native Window Placement Launch new instance Steal My Focus AlternateTab Window List Applications Menu Caffeine Clipboard Indicator Gistnotes OpenWeather Places Status Indicator System-monitor Todo. txt TopIcons Plus User ThemesDevelopment tools: Now, these are mostly objective choices and really doesn’t matter as long as you are comfortable with the tools you choose. Below are my choices for some of the important categories for development. I’m not including obvious things like Vim, Git, NodeJS, Docker, Kubernetes, etc. Shell: This is one of the most important for a developer. I use ZSH along with the awesome Oh My ZSH as my shell. Now, this won’t be complete without some nice plugins and theme. I use powerlevel9k theme with some customizations. I also use zsh-autosuggestions, git, docker, docker-compose, autojump, zsh-syntax-highlighting, dnf, and npm plugins for Oh My ZSH. Here is my . zshrc with all the customizations. Update: A comment on this post suggested powerlevel10k as an alternative theme and I tried it and turns out it is really way faster than powerlevel9k. So I think I’m gonna use powerlevel10k as my shell theme. Terminal: What good is a nice shell without a good terminal. Fortunately, we have Tilix one of the best terminal application out there. It has workspaces, tabs, split windows, Quake mode and so on.  Integrated development environment(IDE): IntelliJ IDEA ultimate - I use this only for Java &amp; other JVM language Development Code Editors: Visual Studio Code - My go-to editor. I love it. I use VSCode for web development, Go, Python, JS development, DevOps and everything other than JVM languages. A VSCode setup is never complete without some good plugins. Here are the plugins that I’m using. You can run the script to install those. Other notable development tools I use are GitKraken for Git repo management, Beyond Compare for code comparisons, VirtualBox, NVM for NodeJS version management and SDKMan for JDK version management. Productivity tools: Productivity tools are also quite important and below are my choices. Browser: Google Chrome is my primary browser. I also use Firefox &amp; Opera sometimes. I do love Opera in terms of its UX, I would love to use it as my primary browser but I miss everything I have synchronized with my Google account in Chrome. Email: I use Mailspring as my e-mail client. Its a fairly decent mail client with nice themes and a simple UI. Office suite: I mostly use Google Docs &amp; Microsoft office online but when I have to work on something on my Desktop I use LibreOffice which is a good office suite and even handles Microsoft Office &amp; Keynote formats. Communication: Of course I use Slack and for video conference I use BlueJeans. Screen capture: I use this nifty tool called Peek for screen recording and Shutter for screenshots. Conclusion: There are many other small and nifty utilities that I use, most are command line utilities. There are some notable mentions like Timeshift which is nice for backing up your machine. Of course, not everything is perfect in the Linux world, but it is the same with every OS. I was a long time Windows user before switching to Linux. So like every Linux users I have from time to time messed things up(With great power comes great responsibility, Peter). There are many quirks in the Linux world but there is nothing that bothers me much. Some of the most annoying issues I had in the past are below and for now, I don’t have any noticeable issues.  Scroll position jumping when switching apps - Fixed after upgrading to Fedora 30 Hibernation was broken - Fixed after upgrading to Fedora 30 Audio output selection was broken when plugging in headphones- Fixed after Fedora 28 for meThis has been a good day, upgraded to #Fedora 30 and hibernate started to work again. Sweet. I was putting off tinkering that for a long time. #Linux &mdash; 𝔻𝕖𝕖𝕡𝕦 𝕂 𝕊𝕒𝕤𝕚𝕕𝕙𝕒𝕣𝕒𝕟 (@deepu105) June 14, 2019I hope you find this useful. If you have any question or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. "
    }, {
    "id": 14,
    "url": "/why-im-moving-away-from-medium/",
    "title": "Why I’m moving away from Medium",
    "body": "2019/06/13 - After much deliberation, I have decided to move my blogs away from Medium. I was considering setting up my own blog with Hugo but then decided to go with Dev. to. Below are the reasons why I decided to leave Medium and why I chose Dev. to. All considerations were purely from a technical writing perspective as I was using Medium for publishing technical content. The love-hate relationship with Medium: I loved Medium when I started writing here, reasons being;    A simple minimal &amp; clean UI — It still is one of the best     Ease of authoring and publishing     Community and visibility     Publications     Ease of customization  But there were also things I didn’t like much which slowly become quite annoying  The weird commenting mechanism(Every comment is a post, and they literally mess up your stories listing page)    Medium had a weird WYSIWYG editor interface which is great for normal content creation but not so great for technical content creation. It had some markdown like shortcuts, but it could never match the ease of using proper markdown editors.     Export only in HTML (Duh!!)  But these annoyances were not the main reason I decided to switch platforms. Below are the main reasons why I decided Medium isn’t a good fit for me. Medium has been aggressively pushing for content to be put behind a paywall and they have made it clear that content not opting in will not get any push inside the platform. This means the community and visibility part is applicable only if you opt-in for the paywall. I understand why Medium does and I think its a great monetary source for established authors but it doesn’t work for mere mortals like me.  As a result of the above, the traffic you get from Medium itself is very low compared to external sources. See one of my stories below for an example. For newer stories, it is even lower.  So writing in Medium seems to have no benefit over other platforms as I could get similar views from external sources and might get better writing experience elsewhere. UpdateSo after a week of moving to the Dev community below are my stats and its incredible, I have ~50k views, ~1k reactions and ~300 followers and one of my post was featured in top 7 of the week and all this in just 1 week. I didn’t get anything remotely close to this from Medium in a year.  Enter Dev. to: When I was trying to find a different platform, some of the most important aspects I considered were below    Community: A community without paywall and a community were your blogs get visibility and get traffic.     Ease of authoring: Authoring experience was important, hence at minimum Markdown support was a must. This way I can author posts in my favorite IDE(VsCode in this case) and doesn’t have to be restricted with the platform’s capability. Also, this ensures that I can easily move my posts to another platform in the future if needed.  Dev. to satisfied these needs and provided a nice and clean UI and descent publishing experience on top. Conclusion: I think Medium is still perfect for normal blogging and for content creators who have subscribers willing to pay even if they put articles behind a paywall. But for technical content creators who do not want their content behind a paywall, there are better platforms. I might still crosspost between Dev. to and Medium from time to time but Dev. to will be my primary blogging platform. Originally published in Medium on June 13, 2019 Cover image credit: Photo by MILKOVÍ on Unsplash "
    }, {
    "id": 15,
    "url": "/deploy-a-web-app-to-azure-app-service-using-terraform/",
    "title": "Deploy a web app to Azure App Service using Terraform",
    "body": "2019/06/12 - Deploying Java web applications to Azure is easy and has been tried, tested and explained many times by many people. My friend Julien Dubois has a nice series on it here. Azure makes it really easy to use its App Service as it provides many different ways of deploying a web app. If you are a modern full-stack Java developer there is a high chance that you are deploying your application as a Docker image. Hence today let’s see how we can deploy a Java web application to Azure App Service using Docker and Terraform in the true spirit of infrastructure as code. The approach is pretty much the same for any web application that is built as a docker image and not necessarily tied down to just Java. To try this out you would need to have Java, NodeJS, Terraform, Docker and Azure CLI installed. Follow the links to install them if needed. As one of the lead developer of JHipster (A handy development platform to generate, develop and deploy Spring Boot + Angular/React/Vue Web applications and Spring microservices), I would use a JHipster web application as the example here. So let’s get started. Let’s build a very simple web application using JHipster. We will use the JDL feature to scaffold our application. We will use the below JDL for our application. Save it to a file named app. jdl in a directory where you want to create the application. application {  config {    baseName helloJHipster,    applicationType monolith,    packageName tech. jhipster. demo,    authenticationType jwt,    buildTool gradle,    clientFramework react,    databaseType sql,    prodDatabaseType mysql,    languages [en, nl]  }}Now let us scaffold this using JHipster. Open your favorite console/terminal and run the below command in the directory where you saved the above JDL file, make sure it’s an empty directory. 1$ npx generator-jhipster import-jdl app. jdlIf you already have JHipster installed you can just run 1$ jhipster import-jdl app. jdlThis will scaffold the application and install the required client-side dependencies. It might take a few minutes(NPM!) so maybe its time for that coffee. You can see the application in action by running . /gradlew on the same terminal once the scaffolding is done. You can refer to the generated Readme. md for more instructions regarding the application. Now let’s move on to the focus of this post, deploying this to Azure App Service with Terraform. Let us first build and publish the docker image for our application. JHipster conveniently provides everything that is required to build docker images. Let us use the provided docker integration using JIB to build the images. Run the below Gradle command. 1$ . /gradlew bootJar -Pprod jibDockerBuildNow let us tag and push this to our docker registry, make sure you have logged into docker and run these commands. Use your own docker hub account name. 123$ docker tag hellojhipster:latest deepu105/hellojhipster:latest$ docker push deepu105/hellojhipster:latestYou can also push to Azure Container registry instead of Docker Hub if you like. Now that our application and Docker images are ready, let’s prepare the Terraform infrastructure for App Service and MySQL database. For other ways of deploying a JHipster web app to Azure check this out. First, create a folder for our terraform files. Let’s name the folder terraform. Now create three files called main. tf, outputs. tf, and variables. tf in this folder. Let us define the variables we will use. Save the below in variables. tf. 12345678910111213141516171819202122232425variable  prefix  { description =  The prefix used for all resources in this example  default   =  xl }variable  location  { description =  The Azure location where all resources in this example should be created }variable  subscription_id  { description =  Azure Subscription ID to be used for billing }variable  my_sql_master_password  { description =  MySql master password }variable  docker_image  { description =  Docker image name }variable  docker_image_tag  { description =  Docker image tag }Now let us define our main. tf First, let us add a configuration for Azure resource manager and create an Azure resource group to hold our resources. 123456789provider  azurerm  { version     =  =1. 24. 0  subscription_id =  ${var. subscription_id} }resource  azurerm_resource_group   main  { name   =  ${var. prefix}-resources  location =  ${var. location} }Now let us add the configuration to create a MySQL database server along with the required firewall rules to let App Service access the DB. If you want to add local access from your machine add a firewall rule block for your IP as well. 12345678910111213141516171819202122232425262728293031323334353637383940414243# This creates a MySQL serverresource  azurerm_mysql_server   main  { name        =  ${var. prefix}-mysql-server  location      =  ${azurerm_resource_group. main. location}  resource_group_name =  ${azurerm_resource_group. main. name}  sku {  name   =  B_Gen5_2   capacity = 2  tier   =  Basic   family  =  Gen5  } storage_profile {  storage_mb      = 5120  backup_retention_days = 7  geo_redundant_backup =  Disabled  } administrator_login     =  mysqladminun  administrator_login_password =  ${var. my_sql_master_password}  version           =  5. 7  ssl_enforcement       =  Disabled }# This is the database that our application will useresource  azurerm_mysql_database   main  { name        =  ${var. prefix}_mysql_db  resource_group_name =  ${azurerm_resource_group. main. name}  server_name     =  ${azurerm_mysql_server. main. name}  charset       =  utf8  collation      =  utf8_unicode_ci }# This rule is to enable the 'Allow access to Azure services' checkboxresource  azurerm_mysql_firewall_rule   main  { name        =  ${var. prefix}-mysql-firewall  resource_group_name =  ${azurerm_resource_group. main. name}  server_name     =  ${azurerm_mysql_server. main. name}  start_ip_address  =  0. 0. 0. 0  end_ip_address   =  0. 0. 0. 0 }This will create a MySQL server, a database for our app on the server and enable access from App Service. Now let us configure the App Service itself along with a service plan. 123456789101112131415161718192021222324252627282930313233343536373839# This creates the plan that the service useresource  azurerm_app_service_plan   main  { name        =  ${var. prefix}-asp  location      =  ${azurerm_resource_group. main. location}  resource_group_name =  ${azurerm_resource_group. main. name}  kind        =  Linux  reserved      = true sku {  tier =  Standard   size =  S1  }}# This creates the service definitionresource  azurerm_app_service   main  { name        =  ${var. prefix}-appservice  location      =  ${azurerm_resource_group. main. location}  resource_group_name =  ${azurerm_resource_group. main. name}  app_service_plan_id =  ${azurerm_app_service_plan. main. id}  site_config {  app_command_line =     linux_fx_version =  DOCKER|${var. docker_image}:${var. docker_image_tag}   always_on    = true } app_settings = {   WEBSITES_ENABLE_APP_SERVICE_STORAGE  =  false    DOCKER_REGISTRY_SERVER_URL      =  https://index. docker. io   # These are app specific environment variables   SPRING_PROFILES_ACTIVE    =  prod,swagger    SPRING_DATASOURCE_URL    =  jdbc:mysql://${azurerm_mysql_server. main. fqdn}:3306/${azurerm_mysql_database. main. name}?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false&amp;useLegacyDatetimeCode=false&amp;serverTimezone=UTC    SPRING_DATASOURCE_USERNAME  =  ${azurerm_mysql_server. main. administrator_login}@${azurerm_mysql_server. main. name}    SPRING_DATASOURCE_PASSWORD  =  ${var. my_sql_master_password}  }}In this configuration, under site_config we use linux_fx_version to declare our docker image and set always_on to true so that the application is not shut down when there is inactivity for some time. In the app_settings section we need to disable storage using the flag WEBSITES_ENABLE_APP_SERVICE_STORAGE and also specify DOCKER_REGISTRY_SERVER_URL. Everything else is specific to our app. The flags passed to the MySQL connection URL is important. Now that our main. tf is ready let us define some output properties that are handy. In the outputs. tf file add the below 1234567output  app_service_name  { value =  ${azurerm_app_service. main. name} }output  app_service_default_hostname  { value =  https://${azurerm_app_service. main. default_site_hostname} }Now we are ready to rock and roll! let us deploy the app. Make sure you have set up your Azure CLI and have logged in using az login. Now in a terminal/console navigate to the terraform folder we created and execute these commands. Please change the values for prefix, location &amp; docker_image accordingly. 1234567$ terraform init$ terraform apply \-var prefix=myAwesomeApp \-var location=northeurope \-var docker_image=deepu105/hellojhipster \-var docker_image_tag=latestThis will prompt you to enter a master password for MySQL server and your Azure subscription ID(You can find this from Azure portal or by running az account list- the id field is the subscription ID). Once you provide the values and confirm, Terraform will get to work and will start creating the resources. this could take a while since we are provisioning a Database server. Wait for it or go have that second coffee ;) Once the deployment is complete, Terraform will print out the outputs which include the app_service_default_hostname. Copy the URL and open it in your favorite browser. The first time could take a while since the app will be started(cold start) only during the first request.  I hope you found this useful. This is my first post in dev. to, I hope to migrate my blogs from Medium to dev. to soon. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. My other related posts:  Create full Microservice stack using JHipster Domain Language under 30 minutes Deploying JHipster Microservices on Azure Kubernetes Service (AKS) How to set up JHipster microservices with Istio service mesh on Kubernetes Continuous delivery of Microservices with XebiaLabs — a. k. a DevOps as Code"
    }, {
    "id": 16,
    "url": "/create-full-microservice-stack-using-j-hipster-domain-language-under-30-minutes/",
    "title": "Create full Microservice stack using JHipster Domain Language under 30 minutes",
    "body": "2019/06/12 - It’s been quite a while since I wrote a blog, I did a few some years ago but never really continued writing. So when I decided to start writing again, I didn’t have to think a lot about a topic as it was very obvious — JHipster. JHipster is a development platform for Java web applications and microservices development. If you are a JVM developer you might have already heard about JHipster. If not, well, you are missing out on a lot and I highly recommend you check it out. You can also check out my book “Full Stack Development with JHipster” on Amazon and Packt to learn about JHipster. I have been working on JHipster from April 2015 and the coolest feature that I got to implement so far is definitely multiple applications generation using JDL. This feature is available in the latest version of JHipster. If you are not familiar with JDL, I recommend you to check out the docs at https://www. jhipster. tech/jdl/ The E-Commerce application: So let us see how we can create a microservice stack using JHipster. We will build an e-commerce store today. The stack includes-    Service discovery using JHipster Registry, a Spring boot application that packs Eureka server and Spring cloud config server.     API management and Gateway using Spring Boot, Netflix Zuul, ReactJS, and Swagger.     Microservices using Spring Boot.     Monitoring using JHipster Console which is made of the Elastic stack(ELK) and Zipkin.  Microservice application architecture The Gateway routes incoming requests to two microservices, Invoice application, and Notification application. Requirements: In order to follow this tutorial, you would need a recent version of Docker, Docker-compose, NodeJS and Java installed on your computer. The below are the versions I have installed(Update: With JHipster 6+ you can use Java 11 &amp; 12). 12345678910111213$ docker -v                                                            Docker version 18. 06. 1-ce, build e68fc7a$ docker-compose -v                docker-compose version 1. 20. 1, build 5d8c71b$ node -v        v8. 11. 4$ java -version     openjdk version  1. 8. 0_212 OpenJDK Runtime Environment (Zulu 8. 38. 0. 13-CA-linux64) (build 1. 8. 0_212-b04)OpenJDK 64-Bit Server VM (Zulu 8. 38. 0. 13-CA-linux64) (build 25. 212-b04, mixed mode)First, install the latest version of JHipster 1$ npm install generator-jhipster -gVerify that you have version 5. 3. 4 or above by running 1$ jhipster --versionCreating the JDL: Now let us create our JDL. Head over to the JDL Studio or your favorite IDE/Editor(You can use JHipster IDE plugin if you like). First, let us define our applications. We will start with the Gateway 123456789101112131415application { config {  baseName store,  applicationType gateway,  packageName com. jhipster. demo. store,  serviceDiscoveryType eureka,  authenticationType jwt,  prodDatabaseType mysql,  cacheProvider hazelcast,  buildTool gradle,  clientFramework react,  testFrameworks [protractor] } entities *}Most of the options are self-explanatory, we are building an application named Store of type Gateway with JWT authentication and Eureka-based service discovery. The application uses a MySQL database and Hazelcast for the cache. It’s built using Gradle. For the client-side, it uses React and Sass. It also has Protractor for end-to-end testing. At the end of the definition you can see entities *, we will come to this later. Now let us define our Invoice microservice 12345678910111213application { config {  baseName invoice,  applicationType microservice,  packageName com. jhipster. demo. invoice,  serviceDiscoveryType eureka,  authenticationType jwt,  prodDatabaseType mysql,  buildTool gradle,  serverPort 8081 } entities Invoice, Shipment}It follows similar options like our Gateway and since it is microservice it doesn’t define any client-side options and also skips user management as it will be handled by the Gateway. Additionally, we have also mentioned a custom port 8081 since we do not want this application to conflict with the default port 8080 used by the Gateway. Now let us define the second microservice, the Notification application 123456789101112131415application { config {  baseName notification,  applicationType microservice,  packageName com. jhipster. demo. notification,  serviceDiscoveryType eureka,  authenticationType jwt,  databaseType mongodb,  cacheProvider no,  enableHibernateCache false,  buildTool gradle,  serverPort 8082 } entities Notification}This application follows many options similar to the Gateway and Invoice application but instead of using MySQL it uses MongoDB as its database and also disables cache. Now that our application definitions are done, we will proceed to define our entity model. For our Gateway store application, let us define the below entities and enums 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** Product sold by the Online store */entity Product {  name String required  description String  price BigDecimal required min(0)  size Size required  image ImageBlob}enum Size {  S, M, L, XL, XXL}entity ProductCategory {  name String required  description String}entity Customer {  firstName String required  lastName String required  gender Gender required  email String required pattern(/^[^@\s]+@[^@\s]+\. [^@\s]+$/)  phone String required  addressLine1 String required  addressLine2 String  city String required  country String required}enum Gender {  MALE, FEMALE, OTHER}entity ProductOrder {  placedDate Instant required  status OrderStatus required  code String required  invoiceId Long}enum OrderStatus {  COMPLETED, PENDING, CANCELLED}entity OrderItem {  quantity Integer required min(0)  totalPrice BigDecimal required min(0)  status OrderItemStatus required}enum OrderItemStatus {  AVAILABLE, OUT_OF_STOCK, BACK_ORDER}relationship OneToOne {  Customer{user(login) required} to User}relationship ManyToOne {  OrderItem{product(name) required} to Product}relationship OneToMany {  Customer{order} to ProductOrder{customer(email) required},  ProductOrder{orderItem} to OrderItem{order(code) required},  ProductCategory{product} to Product{productCategory(name)}}service Product, ProductCategory, Customer, ProductOrder, OrderItem with serviceClasspaginate Product, Customer, ProductOrder, OrderItem with paginationThe JDL defines the entities, enums, the relationship between entities and options like pagination and service layer. The entity field definition follows the syntax 123entity &lt;entity name&gt; { &lt;field name&gt; &lt;type&gt; [&lt;validation&gt;*]}The relationship definition follows the syntax 12345relationship (OneToMany | ManyToOne | OneToOne | ManyToMany) {  &lt;from entity&gt;[{&lt;relationship name&gt;[(&lt;display field&gt;)]}]   to   &lt;to entity&gt;[{&lt;relationship name&gt;[(&lt;display field&gt;)]}]}Refer the JDL docs for full DSL reference. The Invoice microservice application has the following entities 12345678910111213141516171819202122232425262728293031entity Invoice {  code String required  date Instant required  details String  status InvoiceStatus required  paymentMethod PaymentMethod required  paymentDate Instant required  paymentAmount BigDecimal required}enum InvoiceStatus {  PAID, ISSUED, CANCELLED}entity Shipment {  trackingCode String  date Instant required  details String}enum PaymentMethod {  CREDIT_CARD, CASH_ON_DELIVERY, PAYPAL}relationship OneToMany {  Invoice{shipment} to Shipment{invoice(code) required}}service Invoice, Shipment with serviceClasspaginate Invoice, Shipment with paginationmicroservice Invoice, Shipment with invoicePay attention to the last microservice option declared here, it specifies that these entities belong to the microservice named invoice so that our Gateway knows where to route requests for these entities. Now let us see the entities for the Notification microservice application 1234567891011121314entity Notification {  date Instant required  details String  sentDate Instant required  format NotificationType required  userId Long required  productId Long required}enum NotificationType {  EMAIL, SMS, PARCEL}microservice Notification with notificationNow let us go back to the entities keyword we used in our application definitions. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061application { config {  . . .  } entities *}application { config {  . . .  } entities Invoice, Shipment}application { config {  . . .  } entities Notification}/* Entities for Store Gateway */entity Product {  . . . }entity ProductCategory {  . . . }entity Customer {  . . . }entity ProductOrder {  . . . }entity OrderItem {  . . . }microservice Invoice, Shipment with invoice/* Entities for Invoice microservice */entity Invoice {  . . . }entity Shipment {  . . . }/* Entities for notification microservice */entity Notification {  . . . }microservice Notification with notificationHere we instruct the store gateway application that it should contain all the entities defined in the JDL and the gateway will know to skip server-side code for the entities that belong to another microservice and hence will only generate the client-side code for those, here namely Invoice, Shipment, and Notification. We also instruct the Invoice application and Notification application to include its entities. Generating the applications: Create a folder where we want to create our microservice stack. 1$ mkdir ecommerce &amp;&amp; cd ecommerceNow, let us put everything together into a JDL file. Let us call it app. jdl and save it into this folder. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169application { config {  baseName store,  applicationType gateway,  packageName com. jhipster. demo. store,  serviceDiscoveryType eureka,  authenticationType jwt,  prodDatabaseType mysql,  cacheProvider hazelcast,  buildTool gradle,  clientFramework react,  testFrameworks [protractor] } entities *}application { config {  baseName invoice,  applicationType microservice,  packageName com. jhipster. demo. invoice,  serviceDiscoveryType eureka,  authenticationType jwt,  prodDatabaseType mysql,  buildTool gradle,  serverPort 8081 } entities Invoice, Shipment}application { config {  baseName notification,  applicationType microservice,  packageName com. jhipster. demo. notification,  serviceDiscoveryType eureka,  authenticationType jwt,  databaseType mongodb,  cacheProvider no,  enableHibernateCache false,  buildTool gradle,  serverPort 8082 } entities Notification}/* Entities for Store Gateway *//** Product sold by the Online store */entity Product {  name String required  description String  price BigDecimal required min(0)  size Size required  image ImageBlob}enum Size {  S, M, L, XL, XXL}entity ProductCategory {  name String required  description String}entity Customer {  firstName String required  lastName String required  gender Gender required  email String required pattern(/^[^@\s]+@[^@\s]+\. [^@\s]+$/)  phone String required  addressLine1 String required  addressLine2 String  city String required  country String required}enum Gender {  MALE, FEMALE, OTHER}entity ProductOrder {  placedDate Instant required  status OrderStatus required  code String required  invoiceId Long}enum OrderStatus {  COMPLETED, PENDING, CANCELLED}entity OrderItem {  quantity Integer required min(0)  totalPrice BigDecimal required min(0)  status OrderItemStatus required}enum OrderItemStatus {  AVAILABLE, OUT_OF_STOCK, BACK_ORDER}relationship OneToOne {  Customer{user(login) required} to User}relationship ManyToOne { OrderItem{product(name) required} to Product}relationship OneToMany {  Customer{order} to ProductOrder{customer(email) required},  ProductOrder{orderItem} to OrderItem{order(code) required} ,  ProductCategory{product} to Product{productCategory(name)}}service Product, ProductCategory, Customer, ProductOrder, OrderItem with serviceClasspaginate Product, Customer, ProductOrder, OrderItem with pagination/* Entities for Invoice microservice */entity Invoice {  code String required  date Instant required  details String  status InvoiceStatus required  paymentMethod PaymentMethod required  paymentDate Instant required  paymentAmount BigDecimal required}enum InvoiceStatus {  PAID, ISSUED, CANCELLED}entity Shipment {  trackingCode String  date Instant required  details String}enum PaymentMethod {  CREDIT_CARD, CASH_ON_DELIVERY, PAYPAL}relationship OneToMany {  Invoice{shipment} to Shipment{invoice(code) required}}service Invoice, Shipment with serviceClasspaginate Invoice, Shipment with paginationmicroservice Invoice, Shipment with invoice/* Entities for notification microservice */entity Notification {  date Instant required  details String  sentDate Instant required  format NotificationType required  userId Long required  productId Long required}enum NotificationType {  EMAIL, SMS, PARCEL}microservice Notification with notificationNow let us invoke JHipster CLI to import this file 1$ jhipster import-jdl app. jdlThis will create the store, invoice and notification folders and will do the below in each of the folders    Generate the appropriate application and entities configuration.     Generate the application and entities source code based on the configurations.     Install the NPM dependencies for the application.  Once the process is complete you should see the below on your console 123456789Entity Product generated successfully. Entity ProductCategory generated successfully. Entity Customer generated successfully. Entity ProductOrder generated successfully. Entity OrderItem generated successfully. Entity Invoice generated successfully. Entity Shipment generated successfully. Entity Notification generated successfully. Congratulations, JHipster execution is complete!Walk around the generated code to familiarize yourself. Running the applications with Docker: Now that our applications are created its time to test them locally using Docker. To do this first let us generate some docker compose configurations using JHipster. Create a new folder inside the ecommerce folder and run the JHipster docker-compose command 12$ mkdir docker-compose &amp;&amp; cd docker-compose$ jhipster docker-composeIt will prompt you with a few questions, choose the answers as highlighted below 12345678910111213141516171819202122🐳 Welcome to the JHipster Docker Compose Sub-Generator 🐳Files will be generated in folder: /home/deepu/workspace/temp/ecommerce/docker-compose✔ Docker is installed? Which *type* of application would you like to deploy? Microservice application? Which *type* of gateway would you like to use? JHipster gateway based on Netflix Zuul? Enter the root directory where your gateway(s) and microservices are located . . /3 applications found at /home/deepu/workspace/temp/ecommerce/? Which applications do you want to include in your configuration? invoice, notification, store? Which applications do you want to use with clustered databases (only available with MongoDB and Couchbase)? ? Do you want to setup monitoring for your applications ? Yes, for logs and metrics with the JHipster Console (based on ELK and Zipkin)? You have selected the JHipster Console which is based on the ELK stack and additional technologies, which one do you want to use ? Zipkin, for distributed tracing (only compatible with JHipster &gt;= v4. 2. 0)JHipster registry detected as the service discovery and configuration provider used by your apps? Enter the admin password used to secure the JHipster Registry? adminThis will generate all the required docker-compose configurations for the stack and will also print out further instructions to build the docker images. Note: In the latest JHipster versions we migrated to using Jib for creating Docker images. This is a huge improvement over the Docker Maven plugin that we were using, as a result the command to create an image has changed to . /gradlew -Pprod bootWar jibDockerBuild. 12345Docker Compose configuration generated with missing images!To generate the missing Docker image(s), please run: . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/invoice . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/notification . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/storeFollow the instructions and build the docker images. Once all 3 images are built run the below command from the docker-compose folder to fire everything up. 1$ docker-compose up -dOnce the containers start you can stream the logs using below command 1$ docker-compose logs -fNow point your favorite browser to http://localhost:8080/ and see the E-Commerce microservice application in action. Gateway application(Store) You can see the JHipster registry in action at http://localhost:8761/ JHipster Registry And finally the JHipster console at http://localhost:5601/ JHipster Console- Kibana dashboard Once you are done playing around, you can shut everything down by running the below command on the docker-compose folder 1docker-compose downHope you had fun creating microservices using JHipster. To learn how to convert a JHipster monolith to microservices check out my book “Full Stack Development with JHipster” on Amazon and Packt. In the coming weeks, I’ll write some posts about deploying this microservice stack to various cloud providers like GCP, Azure, AWS, Heroku and so on. If you like JHipster don’t forget to give it a star on Github. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. My other related posts:    Deploying JHipster Microservices on Azure Kubernetes Service (AKS)     JHipster microservices with Istio service mesh on Kubernetes  Originally published in Medium on Sep 22, 2018 "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}

function lunr_search(term) {
    $('#lunrsearchresults').show( 400 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-danger btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
    
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 5 );
        $( "body" ).removeClass( "modal-open" );
    });
});